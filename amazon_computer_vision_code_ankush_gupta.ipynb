{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a184fd2",
   "metadata": {},
   "source": [
    "## TABLE OF CONTENTS:\n",
    "* [Imports](#zero-bullet)\n",
    "* [Parameters](#zero2-bullet)\n",
    "* [Extracting Data + Pre-Processing](#first-bullet)\n",
    "    * [Reading Images](#section_1_1)\n",
    "    * [Cleaning & Pooling Data](#section_1_2)\n",
    "    * [Splitting Data](#section_1_3)\n",
    "* [Generating Deep Learning Models + Training On Data](#second-bullet)\n",
    "    * [Initialize Autoencoder & Classifier](#section_2_1)\n",
    "    * [Training Model & Classifying Encoded Images](#section_2_2)\n",
    "* [Plot Training Metrics + Downstream Classification Results](#third-bullet)\n",
    "    * [Plotting Autoencoder Train/Val Loss & Classifier Loss/Acc](#section_3_1)\n",
    "    * [Plotting Confusion Matrices](#section_3_2)\n",
    "* [Visualizing Decoded Images + Compressed Latent Space](#fourth-bullet)\n",
    "    * [Plotting Decoded Images For Train/Test](#section_4_1)\n",
    "    * [Plotting Train/Test Latent with TSNE and Isomap](#section_4_2)\n",
    "* [Finding Similar Images Based On Input](#fifth-bullet)\n",
    "    * [Computing KNN & Cosine Similarity In Latent Space](#section_5_1)\n",
    "    * [Plotting Similar Images](#section_5_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4ce811",
   "metadata": {},
   "source": [
    "## Imports <a class=\"anchor\" id=\"zero-bullet\"></a> </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c66059a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle imports\n",
    "import os\n",
    "os. chdir('/Users/ankushgupta/Documents/amazon_case_study/code')\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, UpSampling2D, Flatten, Dense, Reshape, Conv2DTranspose, InputLayer, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Model, Sequential\n",
    "import os\n",
    "import cv2\n",
    "import io\n",
    "import random as rd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn.manifold import TSNE, Isomap\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import sys\n",
    "from skimage import io \n",
    "import argparse\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from sklearn.experimental import enable_halving_search_cv  \n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9257422c",
   "metadata": {},
   "source": [
    "## Parameters <a class=\"anchor\" id=\"zero2-bullet\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf0a6b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in parameters \n",
    "\n",
    "# for loading the data \n",
    "data_directory = \"/Users/ankushgupta/Documents/amazon_case_study/data\"\n",
    "# for the pre-processing of the data\n",
    "training_split = 0.6\n",
    "validation_split = 0.2\n",
    "test_split = 0.2\n",
    "# for the convolutional autoencoder model \n",
    "latent_dim = 20\n",
    "conv_autoencoder_lr = 0.00005\n",
    "conv_autoencoder_epochs = 100\n",
    "conv_autoencoder_batch = 10\n",
    "# for the simple classifier model \n",
    "classifier_lr = 0.0005\n",
    "classifier_epochs = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8204eb5",
   "metadata": {},
   "source": [
    "<h1><center> Extracting Data + Pre-Processing <a class=\"anchor\" id=\"first-bullet\"></a> </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1123e4b8",
   "metadata": {},
   "source": [
    "## Reading Images <a class=\"anchor\" id=\"section_1_1\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8032bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data in \n",
    "image_data_holder = {}\n",
    "for directory in os.listdir(data_directory):\n",
    "    sub_directory = os.path.join(data_directory, directory)\n",
    "    if sub_directory.split('/')[-1].isalpha() == True:\n",
    "        image_data_holder[sub_directory.split('/')[-1]] = {}\n",
    "        path_to_jpgs = [os.path.join(sub_directory, _) for _ in os.listdir(sub_directory) if _.endswith(r\".jpg\")]\n",
    "        for path in path_to_jpgs:\n",
    "            image = io.imread(path)\n",
    "            # try BGR2GRAY and RGB2GRAY\n",
    "            # grey_scale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)[:, :, np.newaxis]\n",
    "            image_data_holder[sub_directory.split('/')[-1]][path.split('/')[-1].split('.')[-2]] = image\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbc9d0e",
   "metadata": {},
   "source": [
    "## Cleaning & Pooling Data  <a class=\"anchor\" id=\"section_1_2\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6120af08",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m pooled_image_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# utilize the shape of the first image for the first folder as reference (for ease)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m ref_image_dim \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mshape(image_data_holder[\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m][\u001b[38;5;28mlist\u001b[39m(image_data_holder[\u001b[38;5;28mlist\u001b[39m(labels)[\u001b[38;5;241m0\u001b[39m]])[\u001b[38;5;241m0\u001b[39m]])\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m global_key \u001b[38;5;129;01min\u001b[39;00m labels:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m local_key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(image_data_holder[global_key]\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;66;03m# normalize the image between 0 and 1 \u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# intialize some information and structures\n",
    "labels = list(image_data_holder.keys())\n",
    "pooled_image_data = []\n",
    "pooled_image_labels = []\n",
    "# utilize the shape of the first image for the first folder as reference (for ease)\n",
    "ref_image_dim = np.shape(image_data_holder[list(labels)[0]][list(image_data_holder[list(labels)[0]])[0]])\n",
    "for global_key in labels:\n",
    "    for local_key in list(image_data_holder[global_key].keys()):\n",
    "        # normalize the image between 0 and 1 \n",
    "        image_data_holder[global_key][local_key] = image_data_holder[global_key][local_key] / np.max(image_data_holder[global_key][local_key])\n",
    "        # making sure that all of the images are the same size \n",
    "        dims_check = image_data_holder[global_key][local_key].shape\n",
    "        if dims_check != ref_image_dim:\n",
    "            print('Resized Image: [' + global_key + '][' + local_key + ']')\n",
    "            image_data_holder[global_key][local_key] = cv2.resize(image_data_holder[global_key][local_key], ref_image_dim[:2], interpolation=cv2.INTER_LINEAR)\n",
    "        # pool data together for downstream tasks \n",
    "        pooled_image_data.append(image_data_holder[global_key][local_key])\n",
    "        pooled_image_labels.append(np.where(np.asarray(labels) == np.asarray(global_key))[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb099fe",
   "metadata": {},
   "source": [
    "## Splitting Data <a class=\"anchor\" id=\"section_1_3\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "059ad850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training/validation/test and reshape to input into model\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(np.asarray(pooled_image_data), np.asarray(pooled_image_labels), test_size=1-training_split, random_state=42)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_temp, y_temp, test_size=1 / ((1-training_split) / test_split), random_state=42)\n",
    "\n",
    "training_data = np.array(x_train.reshape(-1, x_train.shape[1], x_train.shape[2], x_train.shape[-1]))\n",
    "validation_data = np.array(x_val.reshape(-1, x_val.shape[1], x_val.shape[2], x_val.shape[-1]))\n",
    "test_data = np.array(x_test.reshape(-1, x_test.shape[1], x_test.shape[2], x_test.shape[-1]))\n",
    "full_data = np.array(np.asarray(pooled_image_data).reshape(-1, np.asarray(pooled_image_data).shape[1], np.asarray(pooled_image_data).shape[2], np.asarray(pooled_image_data).shape[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165124ff",
   "metadata": {},
   "source": [
    "<h1><center> Generating Deep Learning Models + Training On Data <a class=\"anchor\" id=\"second-bullet\"></a> </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69906d2f",
   "metadata": {},
   "source": [
    "## Initialize Autoencoder & Classifier <a class=\"anchor\" id=\"section_2_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92f6b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_convolutional_autoencoder():\n",
    "    # initialize the convolutional autoencoder for image compression ---------> \n",
    "    encoder_input = Input(shape= ref_image_dim, name='Input Layer')\n",
    "    encoder_1 = Conv2D(filters=32, kernel_size=3, strides=(2, 2), activation='relu')(encoder_input)\n",
    "    encoder_2 = Conv2D(filters=64, kernel_size=3, strides=(2, 2), activation='relu')(encoder_1)\n",
    "    encoder_3 = Flatten()(encoder_2)\n",
    "    encoder_4 = Dense(latent_dim)(encoder_3)\n",
    "    encoder = Model(encoder_input, encoder_4, name='encoder')\n",
    "    encoder.summary()\n",
    "\n",
    "    decoder_input = Input(shape=(latent_dim,))\n",
    "    decoder_1 = Dense(units=7*7*32, activation=tf.nn.relu)(decoder_input)\n",
    "    decoder_2 = Reshape(target_shape=(7, 7, 32))(decoder_1)\n",
    "    decoder_3 = Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same', activation='relu')(decoder_2)\n",
    "    decoder_4 = Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='same', activation='relu')(decoder_3)\n",
    "    decoder_5 = Conv2DTranspose(filters=ref_image_dim[-1], kernel_size=3, strides=1, padding='same')(decoder_4)\n",
    "    decoder = Model(decoder_input, decoder_5, name='decoder')\n",
    "    decoder.summary()\n",
    "\n",
    "    encoded = encoder(encoder_input)\n",
    "    decoded = decoder(encoded)\n",
    "    convolutional_autoencoder = Model(inputs=encoder_input, outputs=decoded, name='autoencoder')\n",
    "    \n",
    "    if optimizer == 'SGD': \n",
    "        optimizer = tf.keras.optimizers.SGD(lr=learning_rate)\n",
    "    elif optimizer == 'Adam': \n",
    "        optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
    "    convolutional_autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=conv_autoencoder_lr), loss='mse')\n",
    "    # convolutional_autoencoder.summary()\n",
    "    return convolutional_autoencoder\n",
    "\n",
    "def create_classifier():\n",
    "    # downstream classifier for gauging how well the encoded representation of original input can classify for the different labels\n",
    "    classifier_input = Input(shape=(latent_dim,))\n",
    "    classifier_1 = Dense(np.round(latent_dim/2), activation='relu')(classifier_input)\n",
    "    classifier_2 = Dense(np.round(latent_dim/4), activation='relu')(classifier_1)\n",
    "    classifier_3 = Dense(6, activation='softmax')(classifier_2)\n",
    "    downstream_classifier = Model(classifier_input, classifier_3)\n",
    "    downstream_classifier.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=classifier_lr), loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                             metrics=['accuracy'])\n",
    "    downstream_classifier.summary()\n",
    "    return downstream_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "808b0f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d6/6myqdq356m3__krcnz6h3wbm0000gn/T/ipykernel_6473/2423895376.py:5: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  model = KerasRegressor(build_fn=create_convolutional_autoencoder, verbose=1)\n",
      "2022-03-30 16:19:41.533171: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-30 16:19:41.533209: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-30 16:19:41.533261: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-30 16:19:41.533404: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-30 16:19:41.533441: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-30 16:19:41.533888: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-30 16:19:41.534722: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-30 16:19:41.533169: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-30 16:19:41.534791: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-30 16:19:41.534831: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-30 16:19:41.535060: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-30 16:19:41.539116: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input Layer (InputLayer)    [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 13, 13, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                46100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,492\n",
      "Trainable params: 65,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1568)              32928     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       18496     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 3)        867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "  1/134 [..............................] - ETA: 2:05 - loss: 0.4134Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input Layer (InputLayer)    [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 13, 13, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                46100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,492\n",
      "Trainable params: 65,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1568)              32928     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       18496     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 3)        867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "  1/134 [..............................] - ETA: 2:06 - loss: 0.4222Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input Layer (InputLayer)    [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 13, 13, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                46100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,492\n",
      "Trainable params: 65,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1568)              32928     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       18496     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 3)        867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "  1/134 [..............................] - ETA: 2:05 - loss: 0.5540Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input Layer (InputLayer)    [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 13, 13, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                46100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,492\n",
      "Trainable params: 65,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1568)              32928     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       18496     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 3)        867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " 1/67 [..............................] - ETA: 1:02 - loss: 0.4177Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input Layer (InputLayer)    [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 13, 13, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                46100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,492\n",
      "Trainable params: 65,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1568)              32928     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       18496     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 3)        867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "  1/134 [..............................] - ETA: 2:05 - loss: 0.4357Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input Layer (InputLayer)    [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 13, 13, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                46100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,492\n",
      "Trainable params: 65,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1568)              32928     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       18496     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 3)        867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "  1/134 [..............................] - ETA: 2:05 - loss: 0.4898Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input Layer (InputLayer)    [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 13, 13, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                46100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,492\n",
      "Trainable params: 65,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1568)              32928     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       18496     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 3)        867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "  1/134 [..............................] - ETA: 2:06 - loss: 0.3793Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input Layer (InputLayer)    [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 13, 13, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                46100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,492\n",
      "Trainable params: 65,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1568)              32928     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       18496     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 3)        867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " 1/67 [..............................] - ETA: 1:02 - loss: 0.4563Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input Layer (InputLayer)    [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 13, 13, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                46100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,492\n",
      "Trainable params: 65,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1568)              32928     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       18496     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 3)        867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/67 [..............................] - ETA: 1:03 - loss: 0.4259Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input Layer (InputLayer)    [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 13, 13, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                46100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,492\n",
      "Trainable params: 65,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1568)              32928     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       18496     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 3)        867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "  1/134 [..............................] - ETA: 2:09 - loss: 0.3866Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input Layer (InputLayer)    [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 13, 13, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                46100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,492\n",
      "Trainable params: 65,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1568)              32928     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       18496     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 3)        867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "  7/134 [>.............................] - ETA: 6s - loss: 0.4275Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input Layer (InputLayer)    [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 13, 13, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                46100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,492\n",
      "Trainable params: 65,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1568)              32928     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       18496     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 3)        867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "67/67 [==============================] - 6s 81ms/step - loss: 0.394144...............] - ETA: 4s - loss: 0.4TA: 3s - loss: 09/134 [==============>...............] - ETA: 3s - loss: 0.422.3s - loss: 0.3 loss: 0.438\n",
      "67/67 [==============================] - 6s 81ms/step - loss: 0.4321\n",
      "110/134 [=======================>......] - ETA: 1s - loss: 0.2790Epoch 2/10\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.2917Epoch 2/10\n",
      "67/67 [==============================] - 7s 86ms/step - loss: 0.4362\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.3101Epoch 2/10\n",
      "134/134 [==============================] - 7s 46ms/step - loss: 0.2332\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.2465Epoch 2/10==>..] - ETA: 0s - loss: 0.290\n",
      "134/134 [==============================] - 7s 48ms/step - loss: 0.2590\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.3182Epoch 2/50\n",
      "134/134 [==============================] - 8s 49ms/step - loss: 0.2375\n",
      "134/134 [==============================] - 8s 49ms/step - loss: 0.3160\n",
      "134/134 [==============================] - 8s 49ms/step - loss: 0.2770\n",
      "134/134 [==============================] - 8s 50ms/step - loss: 0.2386\n",
      "  7/134 [>.............................] - ETA: 6s - loss: 0.0438Epoch 2/100\n",
      "12/67 [====>.........................] - ETA: 4s - loss: 0.3920Epoch 2/10\n",
      "134/134 [..............................] - ETA: 3s - loss: 0.074[==============================] - 8s 50ms/step - loss: 0.2886\n",
      "Epoch 2/100\n",
      "  1/134 [..............................] - ETA: 7s - loss: 0.0508Epoch 2/50\n",
      "134/134 [==============================] - 8s 48ms/step - loss: 0.2467\n",
      "  2/134 [..............................] - ETA: 8s - loss: 0.0515Epoch 2/10\n",
      "  4/134 [..............................] - ETA: 6s - loss: 0.0756 Epoch 2/50\n",
      "134/134 [==============================] - 8s 51ms/step - loss: 0.2614\n",
      "14/67 [=====>........................] - ETA: 4s - loss: 0.3847Epoch 2/100\n",
      "67/67 [==============================] - 5s 82ms/step - loss: 0.2522] - ETA: 5s - loss: 0.04[=====>........................] - ETA: 5s - loss: 0. 0.042..........] - ETA: 3s - loss: 0.04oss: 0.226======>...............] - ETA: 3s - loss: 0.\n",
      " 80/134 [================>.............] - ETA: 2s - loss: 0.0395Epoch 3/10\n",
      "67/67 [==============================] - 6s 84ms/step - loss: 0.0948\n",
      "65/67 [============================>.] - ETA: 0s - loss: 0.2012Epoch 3/10\n",
      "67/67 [==============================] - 5s 82ms/step - loss: 0.1976\n",
      "Epoch 3/10\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 0.0352==>...........] - ETA: 2s - loss: 0.0 1s - loss: 0.0374/134 [========================>.....] - ETA: 1s - loss: 0.036 loss: 0.0\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 0.0358\n",
      "Epoch 3/10\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.0341Epoch 3/50\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 0.0396\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 0.0347\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.0397Epoch 3/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 0.0396\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.0338Epoch 3/10\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.0364Epoch 3/10\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 0.0357\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 0.0336\n",
      "  5/134 [>.............................] - ETA: 3s - loss: 0.0282Epoch 3/100\n",
      "29/67 [===========>..................] - ETA: 3s - loss: 0.0481Epoch 3/50\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 0.0337\n",
      "  9/134 [=>............................] - ETA: 6s - loss: 0.0273Epoch 3/50\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 0.0363==>.] - ETA: 0s - loss: 0.036\n",
      " 10/134 [=>............................] - ETA: 5s - loss: 0.0284Epoch 3/100\n",
      "67/67 [==============================] - 6s 84ms/step - loss: 0.0421TA: 5s - loss: 0.02========>............] - ETA: 2s - loss: 0.0] - ETA: 4s - loss:ss: 0.027\n",
      "67/67 [==============================] - 6s 87ms/step - loss: 0.0423\n",
      " 69/134 [==============>...............] - ETA: 3s - loss: 0.0285Epoch 4/10\n",
      " 71/134 [==============>...............] - ETA: 3s - loss: 0.0268Epoch 4/10\n",
      "67/67 [==============================] - 6s 88ms/step - loss: 0.0379\n",
      " 64/134 [=============>................] - ETA: 3s - loss: 0.0266Epoch 4/10\n",
      "134/134 [==============================] - 7s 48ms/step - loss: 0.0265.........] - ETA: 2s - loss: 0===>........] - ETA: 1s - loss: 0.02134 [=======================>......] - ETA: 1s - loss: 0.0===============>......] - ETA: 1s - loss: 0.027===============>...] - ETA: 0s - loss: 0.025\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.0253Epoch 4/10\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 0.0259\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0254\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.0254Epoch 4/50\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0270\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 0.0251\n",
      "  5/134 [>.............................] - ETA: 3s - loss: 0.0251Epoch 4/10\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.0268Epoch 4/50\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0262.] - ETA: 4s - loss: 0.024\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0268\n",
      " 10/134 [=>............................] - ETA: 7s - loss: 0.0244Epoch 4/10\n",
      "  8/134 [>.............................] - ETA: 5s - loss: 0.0265Epoch 4/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 0.0253\n",
      "  9/134 [=>............................] - ETA: 7s - loss: 0.0235Epoch 4/50\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0267\n",
      "  4/134 [..............................] - ETA: 12s - loss: 0.0256Epoch 4/100\n",
      "67/67 [==============================] - 5s 80ms/step - loss: 0.03243...] - ETA: 6s - loss: 0.0032\n",
      " 40/134 [=======>......................] - ETA: 4s - loss: 0.0235Epoch 5/10\n",
      "67/67 [==============================] - 6s 85ms/step - loss: 0.0317\n",
      " 38/134 [=======>......................] - ETA: 4s - loss: 0.0230Epoch 5/10\n",
      "67/67 [==============================] - 6s 87ms/step - loss: 0.0304 [===========>..................] - ETA: 4s - loss: 0.023\n",
      " 42/134 [========>.....................] - ETA: 5s - loss: 0.0240Epoch 5/10\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 0.0229====>...................] - ETA: 4s - loss: 0.023..] - ETA: 1s - loss: 0.022134 [=====================>........] - ETA: 1s - loss: 0.0===========>..] - ETA: 0s - loss: 0.022\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.0224Epoch 5/10\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 0.0219\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 0.0225\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.0228Epoch 5/50\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.0231Epoch 5/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 0.0227===>...] - ETA: 0s - loss: 0.022\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 0.0221\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.0222Epoch 5/10\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.0226Epoch 5/50\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 0.0230\n",
      "  9/134 [=>............................] - ETA: 5s - loss: 0.0217Epoch 5/100\n",
      "134/134 [==============================] - 6s 49ms/step - loss: 0.0230\n",
      " 11/134 [=>............................] - ETA: 6s - loss: 0.0216Epoch 5/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0226\n",
      "  6/134 [>.............................] - ETA: 7s - loss: 0.0213Epoch 5/10\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0222\n",
      "  4/134 [..............................] - ETA: 12s - loss: 0.0252Epoch 5/50\n",
      "67/67 [==============================] - 6s 85ms/step - loss: 0.0277\n",
      " 17/134 [==>...........................] - ETA: 5s - loss: 0.0205Epoch 6/10\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 0.0271\n",
      "67/67 [==============================] - 6s 86ms/step - loss: 0.0264- loss: 0.020\n",
      " 26/134 [====>.........................] - ETA: 5s - loss: 0.0214Epoch 6/10\n",
      " 28/134 [=====>........................] - ETA: 4s - loss: 0.0204Epoch 6/10\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 0.0212.........] - ETA: 5s - loss: 0.034 [========>.....................] - ETA: 4s - loss: 0.0210.0: 2s - loss:- ETA: 0s - loss: 0.020134 [===========================>..] - ETA: 0s - loss: 0.020\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.0213Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 6s 48ms/step - loss: 0.0209\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 0.0208\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.0212Epoch 6/10\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.0208Epoch 6/50\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 0.0212\n",
      "  4/134 [..............................] - ETA: 2s - loss: 0.0194Epoch 6/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 0.0211\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0205\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0209\n",
      "Epoch 6/100\n",
      "  7/134 [>.............................] - ETA: 5s - loss: 0.0186Epoch 6/50\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 0.0209\n",
      "  8/134 [>.............................] - ETA: 6s - loss: 0.0187Epoch 6/100\n",
      "  1/134 [..............................] - ETA: 14s - loss: 0.0237Epoch 6/10\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0248\n",
      "65/67 [============================>.] - ETA: 0s - loss: 0.0239Epoch 7/10.......................] - ETA: 16s - loss: 0.022\n",
      "67/67 [==============================] - 6s 85ms/step - loss: 0.0243\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 0.0207\n",
      "67/67 [==============================] - 6s 86ms/step - loss: 0.0240\n",
      "  5/134 [>.............................] - ETA: 11s - loss: 0.0232Epoch 6/50\n",
      " 15/134 [==>...........................] - ETA: 6s - loss: 0.0217Epoch 7/10\n",
      " 1/67 [..............................] - ETA: 4s - loss: 0.0179Epoch 7/10\n",
      "67/67 [==============================] - 6s 87ms/step - loss: 0.0230 5s - loss: 0TA: 4s - loss: 0.02120..............] - ETA: 4s - loss: 0.02oss: 0.0............] - ETA: 3s - loss: 0.02 - ETA: 2s - loss: 0.019 [==================>...........] - ETA: 2s - loss: 0.........] - ETA: 1s - loss: 0.\n",
      "67/67 [==============================] - 6s 85ms/step - loss: 0.0226\n",
      "67/67 [==============================] - 6s 85ms/step - loss: 0.0224\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.0199Epoch 8/10\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.0203Epoch 8/10\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 0.0200\n",
      "Epoch 7/10\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.0203Epoch 8/10\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 0.0203\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 0.0200\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.0198Epoch 7/10\n",
      " 4/67 [>.............................] - ETA: 4s - loss: 0.0200Epoch 7/50\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 0.0198\n",
      "  2/134 [..............................] - ETA: 7s - loss: 0.0146Epoch 7/50=>....] - ETA: 0s - loss: 0.02\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0202\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.0200Epoch 7/100\n",
      "112/134 [=>............................] - ETA: 4s - loss: 0.01734/134 [==============================] - 7s 52ms/step - loss: 0.0201\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0200\n",
      "  4/134 [..............................] - ETA: 4s - loss: 0.0221Epoch 7/100\n",
      "  1/134 [..............................] - ETA: 2s - loss: 0.0229Epoch 7/10\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 0.0203\n",
      " 14/134 [==>...........................] - ETA: 6s - loss: 0.0188Epoch 7/100......] - ETA: 4s - loss: 0.021\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0199\n",
      "  7/134 [>.............................] - ETA: 8s - loss: 0.0203Epoch 7/50\n",
      "67/67 [===========================>..] - ETA: 0s - loss: 0.021194s - loss: 0.0022...............] - ETA: 4s - loss: 0ss: 0.] - ETA: 2s - loss: 0134 [====================>.........] - ETA: 1s - loss: 0.019====================] - 6s 83ms/step - loss: 0.0218\n",
      "101/134 [=====================>........] - ETA: 1s - loss: 0.0193Epoch 9/10\n",
      "67/67 [==============================] - 6s 88ms/step - loss: 0.0215.......] - ETA: 1s - loss: 0.019\n",
      " 96/134 [====================>.........] - ETA: 1s - loss: 0.0193Epoch 9/10\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0214loss: 0.019\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.0194Epoch 9/10\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 0.0195..] - ETA: 5s - loss: 0.02 ETA: 0s - loss: 0.019\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.0199Epoch 8/10\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0197\n",
      "  2/134 [..............................] - ETA: 15s - loss: 0.0162Epoch 8/10\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0196\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.0199Epoch 8/50\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 0.0194\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.0197Epoch 8/50\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 0.0196\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 0.0195\n",
      " 14/134 [==>...........................] - ETA: 6s - loss: 0.0167Epoch 8/100\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.0194Epoch 8/10\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 0.0194\n",
      " 16/134 [==>...........................] - ETA: 5s - loss: 0.0195Epoch 8/50\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 0.0197\n",
      " 18/134 [===>..........................] - ETA: 6s - loss: 0.0168Epoch 8/100\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0196\n",
      "  6/134 [>.............................] - ETA: 6s - loss: 0.0204Epoch 8/100\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 0.0210ss: 03/67 [==================>...........] - ETA: 2s - loss: 0.020020...............] - ETA: 5s - loss: 0. loss: 0.019===========>................] - ETA: 3s - loss: 0.019================>.] - ETA: 0s - loss: 0.020\n",
      " 68/134 [==============>...............] - ETA: 3s - loss: 0.0196Epoch 10/10\n",
      "67/67 [==============================] - 5s 82ms/step - loss: 0.0207\n",
      "67/67 [==============================] - 6s 87ms/step - loss: 0.0208] - ETA: 2s - loss: 0.019\n",
      " 74/134 [===============>..............] - ETA: 2s - loss: 0.0197Epoch 10/10\n",
      " 2/67 [..............................] - ETA: 14s - loss: 0.0203Epoch 10/10\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 0.0194======>............] - ETA: 2s - loss: 0. ETA: 1s - loss: 0.019\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.0193Epoch 9/10\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0193\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.0191Epoch 9/50\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 0.0191\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.0195Epoch 9/50\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0191\n",
      "  4/134 [..............................] - ETA: 2s - loss: 0.0188Epoch 9/10\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 0.0192\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.0192Epoch 9/100\n",
      "134/134 [==============================] - 7s 50ms/step - loss: 0.0194\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 0.0191\n",
      "Epoch 9/100\n",
      "38/67 [================>.............] - ETA: 2s - loss: 0.0199Epoch 9/50\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 0.0191==>.] - ETA: 0s - loss: 0.019\n",
      "  3/134 [..............................] - ETA: 9s - loss: 0.0189Epoch 9/10\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 0.0193\n",
      "  6/134 [>.............................] - ETA: 6s - loss: 0.0197Epoch 9/100\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 0.0202 - ETA: 3s - loss: 0.02.......................] - ETA: 5s - loss: 0.0A: 5s - loss: \n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0204\n",
      "67//134 [===============>..............] - ETA: 2s - loss: 0.01867 [==============================] - 6s 91ms/step - loss: 0.0204\n",
      "34/34 [==============================] - 3s 44ms/step - loss: 0.0195===============>.............] - ETA: 2s - loss: 0.0==============>..........] - ETA: 2s - loss: 0.0190s - loss: 0.018\n",
      "34/34 [==============================] - 3s 45ms/step - loss: 0.0200] - ETA: 1s - loss: 0.018\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 0.0191\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.0190Epoch 10/10\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 0.0189========>.....] - ETA: 0s - loss: 0.018\n",
      "34/34 [==============================] - 3s 48ms/step - loss: 0.0209\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0190Epoch 10/50\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 0.0190\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 0.0188\n",
      "116/134 [==========....................] - ETA: 8s - loss: 0.0196==============>.....] - ETA: 0s - loss: 0.0192Epoch 10/50\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.0188Epoch 10/10\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 0.0189.............] - ETA: 4s - loss: 0.016\n",
      "Epoch 10/10\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 0.0189\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.0189Epoch 10/100\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 0.0190\n",
      "18/67 [=======>......................] - ETA: 1s - loss: 0.0189Epoch 10/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 0.0189\n",
      " 4/67 [>.............................] - ETA: 4s - loss: 0.0200Epoch 10/50\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 0.0192\n",
      "25/67 [==========>...................] - ETA: 1s - loss: 0.0192Epoch 10/100ss: 0.019\n",
      "67/67 [==============================] - 3s 33ms/step - loss: 0.0200\n",
      "67/67 [==============================] - 3s 37ms/step - loss: 0.0202s: 0.020- loss: 0.018oss: 0.019\n",
      "67/67 [==============================] - 3s 37ms/step - loss: 0.0201\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 0.018901==============>........] - ETA: 1s - loss: 0.0========>.....] - ETA: 0s - loss: 0.01.....] - ETA: 1s - loss: 0.019\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 0.0187\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.0186Epoch 11/50s: 0.018\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 0.0188\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.0187Epoch 11/50\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 0.0185\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.0187\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.0186\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 6s 41ms/step - loss: 0.0190\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.0187\n",
      "Epoch 11/100\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.0188Epoch 11/50\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 0.0188\n",
      " 22/134 [===>..........................] - ETA: 3s - loss: 0.0183Epoch 11/100\n",
      "67/67 [==============================] - 3s 18ms/step - loss: 0.0194 ETA: 2s - loss: \n",
      "67/67 [==============================] - 3s 16ms/step - loss: 0.0183\n",
      "67/67 [==============================] - 3s 19ms/step - loss: 0.0179\n",
      "134/134 [==============================] - 4s 29ms/step - loss: 0.0186====================>.......] - ETA: 0s - loss: 0.018\n",
      "  1/134 [..............................] - ETA: 38s - loss: 0.0189Epoch 12/50\n",
      " 18/134 [===>..........................] - ETA: 2s - loss: 0.0186Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 0.0186\n",
      " 51/134 [==========>...................] - ETA: 1s - loss: 0.0183)                Output Shape              Param #   \n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.0188Epoch 12/50\n",
      " 27/134 [=====>........................] - ETA: 2s - loss: 0.0182=====================================\n",
      " 29/134 [=====>........................] - ETA: 2s - loss: 0.01813)]       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 13, 32)        896       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                46100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,492\n",
      "Trainable params: 65,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1568)              32928     \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 14, 14, 64)       18496     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.0185  [============================>.] - ETA: 0s - loss: 0.018\n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 28, 28, 3)        867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 0.0185\n",
      " 4/67 [>.............................] - ETA: 7s - loss: 0.4589 Epoch 12/100 ETA: 1s - loss: 0.01\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 0.0185\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.0186Epoch 12/50\n",
      "134/134 [==============================] - 4s 31ms/step - loss: 0.0186\n",
      " 54/134 [===========>..................] - ETA: 1s - loss: 0.0185Epoch 12/100\n",
      "134/134 [==============================] - 4s 33ms/step - loss: 0.0188\n",
      "  5/134 [>.............................] - ETA: 4s - loss: 0.0164Epoch 12/100\n",
      " 23/134 [====>.........................] - ETA: 3s - loss: 0.0179: \"encoder\"\n",
      "_________________________________________________________________\n",
      " 77/134 [================>.............] - ETA: 1s - loss: 0.0184(type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input Layer (InputLayer)    [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 13, 32)        896       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2304)              0         \n",
      " 31/134 [=====>........................] - ETA: 3s - loss: 0.0191                                             \n",
      " dense_2 (Dense)             (None, 20)                46100     \n",
      "                                                                 \n",
      " 14/134 [==>...........................] - ETA: 4s - loss: 0.0184==========================\n",
      "Total params: 65,492\n",
      "Trainable params: 65,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1568)              32928     \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 7, 7, 32)          0         \n",
      "111/134 [=======================>......] - ETA: 0s - loss: 0.0189                                   \n",
      " conv2d_transpose_3 (Conv2DT  (None, 14, 14, 64)       18496     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 28, 28, 3)        867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      " 18/134 [===>..........................] - ETA: 4s - loss: 0.0189Model: \"encoder\"\n",
      " 28/134 [=====>........................] - ETA: 4s - loss: 0.0180__________________________________________\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.0189           Param #   \n",
      "=================================================================\n",
      " Input Layer (InputLayer)    [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 13, 32)        896       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      " 44/134 [========>.....................] - ETA: 3s - loss: 0.0187   \n",
      " flatten_1 (Flatten)         (None, 2304)              0         \n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.0189                                                \n",
      " dense_2 (Dense)             (None, 20)                46100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,492\n",
      "Trainable params: 65,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1568)              32928     \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " 35/134 [======>.......................] - ETA: 3s - loss: 0.018364)       18496     \n",
      " ranspose)                                                       \n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.0187                                                             \n",
      " conv2d_transpose_4 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 28, 28, 3)        867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "134/134 [========>.....................] - ETA: 3s - loss: 0.018=========================] - 3s 20ms/step - loss: 0.0187\n",
      "134/134 [==============================] - 3s 23ms/step - loss: 0.0185 0.018....................] - ETA: 5s - loss: 0.\n",
      "134/134 [==============================] - 3s 23ms/step - loss: 0.01840.439\n",
      "67/67 [==============================] - 9s 70ms/step - loss: 0.3573s - loss: 0.018===========>...........] - ETA: 2s - loss: 0.018\n",
      " 92/134 [===================>..........] - ETA: 1s - loss: 0.0183Epoch 2/50\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.0184====================>...] - ETA: 0s - loss: 0.01\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.0183\n",
      "Epoch 13/50\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.0184Epoch 13/50\n",
      "67/67 [==============================] - 10s 69ms/step - loss: 0.3933 0.018=============>.....] - ETA: 0s - loss: 0.018\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.0185Epoch 2/50\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.0183\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.0185Epoch 13/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.0183s: 0.017\n",
      "Epoch 13/50\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.0184\n",
      "27/67 [===========>..................] - ETA: 2s - loss: 0.0770Epoch 13/100\n",
      "134/134 [==============================] - 5s 41ms/step - loss: 0.0187\n",
      "67/67 [==============================] - 10s 74ms/step - loss: 0.4034\n",
      "Epoch 13/100\n",
      " 30/134 [=====>........................] - ETA: 3s - loss: 0.0184Epoch 2/50\n",
      "67/67 [==============================] - 4s 64ms/step - loss: 0.0585.0>.........] - ETA: 1s - loss: 0.127- loss: 0.018\n",
      " 77/134 [================>.............] - ETA: 2s - loss: 0.0180Epoch 3/50\n",
      "67/67 [==============================] - 4s 63ms/step - loss: 0.1069=======>.....] - ETA: 0s - loss: 0.0\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.0183Epoch 3/50\n",
      "134/134 [==============================] - 5s 38ms/step - loss: 0.0179=======>...] - ETA: 0s - loss: 0.0\n",
      "108/134 [=======================>......] - ETA: 1s - loss: 0.0183Epoch 14/50\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.0182\n",
      "115/134 [========================>.....] - ETA: 0s - loss: 0.0178Epoch 14/50\n",
      "67/67 [==============================] - 4s 65ms/step - loss: 0.0974\n",
      "Epoch 3/50\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.0180Model: \"encoder\"018\n",
      "_________________________________________________________________\n",
      " 17/134 [==>...........................] - ETA: 3s - loss: 0.0180pe              Param #   \n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.0184=\n",
      " Input Layer (InputLayer)    [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.0184       896       =====>..] - ETA: 0s - loss: 0.018\n",
      "                                                                 \n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.0179\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.0180_3 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                46100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,492\n",
      "Trainable params: 65,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " 20/134 [===>..........................] - ETA: 4s - loss: 0.0181             (None, 1568)              32928     \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 14, 14, 64)       18496     \n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.0180\n",
      "22/67 [========>.....................] - ETA: 3s - loss: 0.0429                          =========>.] - ETA: 0s - loss: 0.018\n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 28, 28, 3)        867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      " 1/67 [..............................] - ETA: 5:45 - loss: 0.3915Epoch 14/100\n",
      "12/67 [====>.........................] - ETA: 3s - loss: 0.0462Epoch 14/50\n",
      "134/134 [==============================] - 5s 39ms/step - loss: 0.0181\n",
      "  2/134 [..............................] - ETA: 22s - loss: 0.0191Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/134 [..............................] - ETA: 10s - loss: 0.0191Model: \"encoder\"............] - ETA: 6s - loss: 0.434\n",
      "_________________________________________________________________\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.0185              Output Shape             \n",
      " 11/134 [=>............................] - ETA: 5s - loss: 0.0193Param #   \n",
      "=================================================================\n",
      " 12/134 [=>............................] - ETA: 5s - loss: 0.0190Epoch 14/100\n",
      " 31/134 [=====>........................] - ETA: 4s - loss: 0.0178one, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 13, 32)        896       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                46100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,492\n",
      " 32/134 [======>.......................] - ETA: 4s - loss: 0.01782\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1568)              32928     \n",
      "                                                                 \n",
      " 9/67 [===>..........................] - ETA: 6s - loss: 0.44637, 7, 32)          0         \n",
      "                                                                 \n",
      " 15/134 [==>...........................] - ETA: 5s - loss: 0.0181nv2d_transpose_3 (Conv2DT  (None, 14, 14, 64)       18496     \n",
      " 11/134 [=>............................] - ETA: 6s - loss: 0.0173                             \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 28, 28, 3)        867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "  4/134 [..............................] - ETA: 8s - loss: 0.0178Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      " 17/134 [==>...........................] - ETA: 5s - loss: 0.0181==============================\n",
      " Input Layer (InputLayer)    [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      "43/67 [==================>...........] - ETA: 1s - loss: 0.0376  \n",
      "                                                                 \n",
      "  7/134 [>.............................] - ETA: 8s - loss: 0.0182     (None, 6, 6, 64)          18496     \n",
      " 19/134 [===>..........................] - ETA: 5s - loss: 0.0170              .....] - ETA: 4s - loss: 0.017\n",
      " flatten_1 (Flatten)         (None, 2304)              0         \n",
      "34/67 [==============>...............] - ETA: 2s - loss: 0.0413                                                   \n",
      " dense_2 (Dense)             (None, 20)                46100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,492\n",
      "Trainable params: 65,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1568)              32928     \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 14, 14, 64)       18496     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 28, 28, 3)        867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "67/67 [==============================] - 5s 77ms/step - loss: 0.0364loss: 0.017TA: 0s - loss: 0.\n",
      "56/67 [========================>.....] - ETA: 0s - loss: 0.0394Epoch 4/50\n",
      "67/67 [==============================] - 6s 84ms/step - loss: 0.0387] - ETA: 4s - loss: 0.018=====>...........] - ETA: 2s - loss: 0.018..........] - ETA: 2s - loss: 0.432=====>.........] - ETA: 1s - loss: 0.017\n",
      "51/67 [=====================>........] - ETA: 1s - loss: 0.4338Epoch 4/50\n",
      "67/67 [==============================] - 6s 86ms/step - loss: 0.0403===>...] - ETA: 0s - loss: 0.040....] - ETA: 4s - loss: 0.032====>........] - ETA: 1s - loss: 0.422\n",
      " 97/134 [====================>.........] - ETA: 1s - loss: 0.0173Epoch 4/50\n",
      "67/67 [==============================] - 11s 91ms/step - loss: 0.4188\n",
      "54/67 [=======================>......] - ETA: 1s - loss: 0.4242Epoch 2/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0175\n",
      "107/134 [======================>.......] - ETA: 1s - loss: 0.0176Epoch 15/50\n",
      "67/67 [==============================] - 11s 93ms/step - loss: 0.4036=======>.......] - ETA: 1s - loss: 0.018\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 0.0179\n",
      "109/134 [=======================>......] - ETA: 1s - loss: 0.0180Epoch 2/100\n",
      " 1/67 [..............................] - ETA: 3s - loss: 0.2749Epoch 15/50\n",
      "67/67 [==============================] - 11s 96ms/step - loss: 0.4128\n",
      "42/67 [=================>............] - ETA: 2s - loss: 0.0316Epoch 2/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0176\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.0176Epoch 15/50\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0176\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0177\n",
      " 28/134 [=====>........................] - ETA: 5s - loss: 0.0184Epoch 15/100\n",
      " 29/134 [=====>........................] - ETA: 5s - loss: 0.0181Epoch 15/100 ETA: 5s - loss: 0.244\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0183: 5s - loss: 0.232\n",
      "32/67 [=============>................] - ETA: 3s - loss: 0.0334Epoch 15/100\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 0.0304s: 0.030\n",
      "25/67 [==========>...................] - ETA: 3s - loss: 0.1973Epoch 5/50\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0301] - ETA: 5s - loss: 0.0====>.............] - ETA: 2s - loss: 0.168\n",
      "16/67 [======>.......................] - ETA: 4s - loss: 0.0279Epoch 5/50\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0321.] - ETA: 2s - loss: 0.161=>.................] - ETA: 4s - loss: 0.016========>...] - ETA: 0s - loss: 0.149\n",
      " 68/134 [==============>...............] - ETA: 3s - loss: 0.0170Epoch 5/50\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 0.1414...] - ETA: 1s - loss: 0.133............] - ETA: 5s - loss: 0.026\n",
      "62/67 [==========================>...] - ETA: 0s - loss: 0.1361Epoch 3/100\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 0.1308\n",
      "40/67 [================>.............] - ETA: 2s - loss: 0.0273Epoch 3/100\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.1164\n",
      "22/67 [========>.....................] - ETA: 3s - loss: 0.0285Epoch 3/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 0.0170=======>........] - ETA: 1s - loss: 0.017===================>.......] - ETA: 1s - loss: 0.017 [========================>.....] - ETA: 1s - loss: 0.01\n",
      "108/134 [=======================>......] - ETA: 1s - loss: 0.0181Epoch 16/50\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0175==============>..........] - ETA: 1s - loss: 0.026\n",
      "27/67 [===========>..................] - ETA: 3s - loss: 0.0459Epoch 16/50\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0170\n",
      "42/67 [=================>............] - ETA: 2s - loss: 0.0283Epoch 16/50\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0172\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0267\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.0181Epoch 16/100\n",
      "53/67 [======================>.......] - ETA: 1s - loss: 0.0265Epoch 6/50\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0171\n",
      " 2/67 [..............................] - ETA: 4s - loss: 0.0243Epoch 16/100\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0180\n",
      "  9/134 [=>............................] - ETA: 5s - loss: 0.0150Epoch 16/100\n",
      "67/67 [==============================] - 6s 87ms/step - loss: 0.0260loss: 0.018\n",
      "43/67 [==================>...........] - ETA: 2s - loss: 0.0451Epoch 6/50\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0274loss: 0.017 3s - loss: 0.025\n",
      " 57/134 [===========>..................] - ETA: 4s - loss: 0.0169Epoch 6/50\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0411.\n",
      " 52/134 [==========>...................] - ETA: 4s - loss: 0.0175Epoch 4/100\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0415 0.016\n",
      "Epoch 4/100\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0413==========>..........] - ETA: 2s - loss: 0.016===========>..............] - ETA: 3s - loss: 0.017\n",
      "36/67 [===============>..............] - ETA: 2s - loss: 0.0235Epoch 4/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 0.0166ss: 0.018======>............] - ETA: 3s - loss: 0.016................] - ETA: 2s - loss: 0\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0242\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.0170Epoch 7/50\n",
      " 1/67 [..............................] - ETA: 4s - loss: 0.0194Epoch 17/50\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0170\n",
      "53/67 [======================>.......] - ETA: 1s - loss: 0.0244Epoch 17/50\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0165\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.0176Epoch 17/50\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0236\n",
      " 11/134 [=>............................] - ETA: 4s - loss: 0.0173Epoch 7/50\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0166\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.0244Epoch 17/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 0.0176\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0166\n",
      "Epoch 17/100\n",
      "49/67 [====================>.........] - ETA: 1s - loss: 0.0310Epoch 17/100\n",
      "67/67 [==============================] - 6s 85ms/step - loss: 0.0245\n",
      " 16/134 [==>...........................] - ETA: 6s - loss: 0.0162Epoch 7/50\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0303===>..........................] - ETA: 5s - loss: 0.023030s: 0.032 5s - loss: 0.016\n",
      "36/67 [===============>..............] - ETA: 2s - loss: 0.0230Epoch 5/100\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0310017 - loss: 0.031\n",
      "40/67 [================>.............] - ETA: 2s - loss: 0.0229Epoch 5/100\n",
      "67/67 [==============================] - 6s 86ms/step - loss: 0.032116\n",
      " 56/134 [===========>..................] - ETA: 4s - loss: 0.0161Epoch 5/100\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0226=>...........] - ETA: 2s - loss: \n",
      " 92/134 [===================>..........] - ETA: 2s - loss: 0.0163Epoch 8/50\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0163oss: 0.016\n",
      "37/67 [===============>..............] - ETA: 2s - loss: 0.0278Epoch 18/50\n",
      "67/67 [==============================] - 7s 99ms/step - loss: 0.0222\n",
      "  9/134 [=>............................] - ETA: 7s - loss: 0.0181Epoch 8/50\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0165\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.0162Epoch 18/50\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0228\n",
      "  6/134 [>.............................] - ETA: 5s - loss: 0.0164Epoch 8/50.....................] - ETA: 5s - loss: 0.020\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0161\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.0170Epoch 18/50\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0163\n",
      " 6/67 [=>............................] - ETA: 4s - loss: 0.0221Epoch 18/100\n",
      "67/67 [==============================] - 6s 88ms/step - loss: 0.0256\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 0.0171\n",
      "  9/134 [=>............................] - ETA: 6s - loss: 0.0152Epoch 18/100\n",
      " 31/134 [=====>........................] - ETA: 5s - loss: 0.0167Epoch 6/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.01624\n",
      "Epoch 18/100\n",
      "67/67 [==============================] - 6s 87ms/step - loss: 0.0275\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0272\n",
      " 36/134 [=======>......................] - ETA: 5s - loss: 0.0155Epoch 6/100\n",
      " 14/134 [==>...........................] - ETA: 6s - loss: 0.0156Epoch 6/100\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0216..............] - ETA: 3s - loss: 0.0218/67 [===========>..................] - ETA: 3s - loss: 0.02.......] - ETA: 4s - loss: 0.025....................] - ETA: 4s - loss: 0.025.................] - ETA: 4s - loss: 0.026==========>...............] - ETA: 3s - loss: 0\n",
      " 92/134 [===================>..........] - ETA: 2s - loss: 0.0162Epoch 9/50\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 0.0213................] - ETA: 3s - loss: 0.0164 [=================>............] - ETA: 2s - loss: 0.\n",
      "107/134 [======================>.......] - ETA: 1s - loss: 0.0162Epoch 9/50\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0217\n",
      "106/134 [======================>.......] - ETA: 1s - loss: 0.0160Epoch 9/50\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 0.0159\n",
      "22/67 [========>.....................] - ETA: 5s - loss: 0.0207Epoch 19/50oss: 0.016\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0231\n",
      "10/67 [===>..........................] - ETA: 5s - loss: 0.0229Epoch 7/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0161\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.0157Epoch 19/50\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0157 6s - loss: 0.023\n",
      " 10/134 [=>............................] - ETA: 5s - loss: 0.0165Epoch 19/50\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0160loss: 0.024\n",
      "67/67 [==============================] - 6 ETA: 0s - loss: 0.016s 92ms/step - loss: 0.0249\n",
      "16/67 [======>.......................] - ETA: 5s - loss: 0.0226Epoch 19/100\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.0166Epoch 7/100\n",
      "67/67 [==============================] - 7s 96ms/step - loss: 0.0247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 29/134 [=====>........................] - ETA: 4s - loss: 0.0146Epoch 7/100........................] - ETA: 6s - loss: 0.016\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0167\n",
      " 16/134 [==>...........................] - ETA: 6s - loss: 0.0161Epoch 19/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0158\n",
      " 9/67 [===>..........................] - ETA: 5s - loss: 0.0225Epoch 19/100\n",
      "67/67 [==============================] - 7s 99ms/step - loss: 0.0209...........] - ETA: 6s - loss: 0.016....................] - ETA: 5s - loss: 0.015.................] - ETA: 4s - loss: 0.02334 [========>.....................] - ETA: 4s - loss: 0.1s - loss: 0.020\n",
      " 56/134 [===========>..................] - ETA: 4s - loss: 0.0157Epoch 10/50\n",
      "67/67 [==============================] - 7s 100ms/step - loss: 0.0206loss: 0.023] - ETA: 2s - loss: 0.0210/134 [==============>...............] - ETA: 3s - loss: 0.0\n",
      "16/67 [======>.......................] - ETA: 4s - loss: 0.0205Epoch 10/50\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.02091s - loss: 0.023\n",
      " 89/134 [==================>...........] - ETA: 2s - loss: 0.0156Epoch 10/50\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0217............] - ETA: 6s - loss: 0.018 - loss: 0.019\n",
      "108/134 [=======================>......] - ETA: 1s - loss: 0.0155Epoch 8/100 4s - loss: 0.020\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 0.0156\n",
      " 88/134 [==================>...........] - ETA: 2s - loss: 0.0154Epoch 20/50\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0233........] - ETA: 2s - loss: 0.020\n",
      "37/67 [===============>..............] - ETA: 2s - loss: 0.0201Epoch 8/100\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0229\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.0155Epoch 8/100......] - ETA: 3s - loss: 0.019\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0159\n",
      "14/67 [=====>........................] - ETA: 4s - loss: 0.0217Epoch 20/50\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0154\n",
      "108/134 [=======================>......] - ETA: 1s - loss: 0.0155Epoch 20/50\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0157................] - ETA: 4s - loss: 0.0178\n",
      "114/134 [========================>.....] - ETA: 1s - loss: 0.0154Epoch 20/100\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0163\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.0154Epoch 20/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0155\n",
      "Epoch 20/100\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0204] - ETA: 6s - loss: \n",
      "58/67 [========================>.....] - ETA: 0s - loss: 0.0201Epoch 11/50\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 0.0202\n",
      " 34/134 [======>.......................] - ETA: 6s - loss: 0.0153Epoch 11/50\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 0.0204==============>............] - ETA: 2s - loss: 0.015\n",
      " 64/134 [=============>................] - ETA: 4s - loss: 0.0156Epoch 11/50\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0208ETA: 2s - loss: 0.015 ETA: 1s - loss: 0.021......] - ETA: 5s - loss: 0.015\n",
      "101/134 [=====================>........] - ETA: 1s - loss: 0.0152Epoch 9/100\n",
      "67/67 [==============================] - 6s 88ms/step - loss: 0.0223s - loss: 0.016s - loss: 0.021\n",
      "110/134 [=======================>......] - ETA: 1s - loss: 0.0153Epoch 9/100\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0217===================>....] - ETA: 0s - loss: 0.015\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.0153Epoch 9/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.01530s - loss: 0.0155s - loss: 0.020\n",
      "Epoch 21/50\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0156loss: 0.015\n",
      " 13/134 [=>............................] - ETA: 6s - loss: 0.0145Epoch 21/50\n",
      "134/134 [==============================] - 8s 61ms/step - loss: 0.0151\n",
      "Epoch 21/50\n",
      "134/134 [==============================] - 8s 61ms/step - loss: 0.0154\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.0159Epoch 21/100\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0200\n",
      "40/67 [================>.............] - ETA: 2s - loss: 0.0203Epoch 12/50\n",
      "67/67 [==============================] - 6s 86ms/step - loss: 0.0198\n",
      " 14/134 [==>...........................] - ETA: 5s - loss: 0.0162Epoch 12/50.......] - ETA: 2s - loss: 0.021\n",
      "134/134 [==============================] - 8s 61ms/step - loss: 0.0160\n",
      " 31/134 [=====>........................] - ETA: 6s - loss: 0.0150Epoch 21/100\n",
      "134/134 [==============================] - 8s 61ms/step - loss: 0.0152\n",
      "  5/134 [>.............................] - ETA: 6s - loss: 0.0149Epoch 21/100\n",
      "67/67 [==============================] - 7s 100ms/step - loss: 0.0201\n",
      " 46/134 [=========>....................] - ETA: 4s - loss: 0.0144Epoch 12/50\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.020234 [===========>..................] - ETA: 4s - loss: 0.014\n",
      "63/67 [===========================>..] - ETA: 0s - loss: 0.0216Epoch 10/100\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0215\n",
      " 68/134 [==============>...............] - ETA: 4s - loss: 0.0156Epoch 10/100\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0209\n",
      "102/134 [=====================>........] - ETA: 1s - loss: 0.0150Epoch 10/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0150.................] - ETA: 4s - loss: 0....] - ETA: 1s - loss: 0.014........] - ETA: 4s - loss: 0.021===================>.] - ETA: 0s - loss: 0.014\n",
      "58/67 [========================>.....] - ETA: 0s - loss: 0.0198Epoch 22/50\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0197.014ETA: 1s - loss: 0.\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.0148Epoch 13/50\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0196\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.0153Epoch 13/50\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.015] - 8s 58ms/step - loss: 0.0153\n",
      "113/134 [========================>.....] - ETA: 1s - loss: 0.0155Epoch 22/50\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0149\n",
      " 24/134 [====>.........................] - ETA: 5s - loss: 0.0154Epoch 22/50\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0151....] - ETA: 1s - loss: 0.019.......] - ETA: 2s - loss: 0.020\n",
      "40/67 [================>.............] - ETA: 2s - loss: 0.0201Epoch 22/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0156....] - ETA: 1s - loss: 0.0\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.0196Epoch 22/100\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0198\n",
      "  6/134 [>.............................] - ETA: 2s - loss: 0.0151Epoch 13/50..............] - ETA: 4s - loss: 0.015\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0150\n",
      "51/67 [=====================>........] - ETA: 1s - loss: 0.0202Epoch 22/100\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0198\n",
      "64/67 [===========================>..] - ETA: 0s - loss: 0.0211Epoch 11/100\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0209 0.020] - ETA: 5s - loss: 0.014\n",
      " 64/134 [=============>................] - ETA: 3s - loss: 0.0149Epoch 11/100\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 0.0204- ETA: 4s - loss: 0.014\n",
      " 61/134 [============>.................] - ETA: 3s - loss: 0.0154Epoch 11/100\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0194\n",
      "114/134 [========================>.....] - ETA: 1s - loss: 0.0151Epoch 14/50\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0194\n",
      "45/67 [===================>..........] - ETA: 1s - loss: 0.0202Epoch 14/50\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 0.0147\n",
      "Epoch 23/50\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 0.0150 ETA: 1s - loss: 0.0\n",
      " 12/134 [=>............................] - ETA: 5s - loss: 0.0141Epoch 23/50\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 0.0146....] - ETA: 1s - loss: 0.019............] - ETA: 4s - loss: 0.018\n",
      "66/67 [============================>.] - ETA: 0s - loss: 0.0196Epoch 23/50\n",
      "67/67 [==============================] - 6s 97ms/step - loss: 0.01959\n",
      " 17/134 [==>...........................] - ETA: 6s - loss: 0.0143Epoch 14/50\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0148\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0196Epoch 23/100\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0196\n",
      "20/67 [=======>......................] - ETA: 4s - loss: 0.0182Epoch 12/100==============>......] - ETA: 1s - loss: 0.014\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0205========================>....] - ETA: 0s - loss: 0.01\n",
      " 7/67 [==>...........................] - ETA: 5s - loss: 0.0195Epoch 12/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0153 - loss: 0.014\n",
      "Epoch 23/100\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 0.0200\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.0147Epoch 12/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0147\n",
      " 40/134 [=======>......................] - ETA: 5s - loss: 0.0142Epoch 23/100\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.01924 [========>.....................] - ETA: 5s - loss: 0.01434 [===>..........................] - ETA: 5s - loss: 0.01534 [======>.......................] - ETA: 5s - los014 2s - loss: 0.014\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0192\n",
      " 68/134 [==============>...............] - ETA: 3s - loss: 0.0149Epoch 15/50\n",
      " 83/134 [=================>............] - ETA: 2s - loss: 0.0146Epoch 15/50\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0145- ETA: 3s - loss: 0.014\n",
      " 95/134 [====================>.........] - ETA: 2s - loss: 0.0150Epoch 24/50\n",
      "67/67 [==============================] - 6s 88ms/step - loss: 0.0193\n",
      " 80/134 [================>.............] - ETA: 3s - loss: 0.0144Epoch 13/100\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0193\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 0.0201\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.0147Epoch 15/50\n",
      "109/134 [=======================>......] - ETA: 1s - loss: 0.0150Epoch 13/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0148 - loss: 0.015\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.0144Epoch 24/50- ETA: 0s - loss: 0.019\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0144\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0197\n",
      "125/134 [==========================>...] - ETA: 0s - loss: 0.0150Epoch 24/50\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.0145Epoch 13/100\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0145\n",
      "35/67 [==============>...............] - ETA: 2s - loss: 0.0186Epoch 24/100\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0150\n",
      " 13/134 [=>............................] - ETA: 8s - loss: 0.0144Epoch 24/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0145 ETA: 1s - loss: 0.019\n",
      "30/67 [============>.................] - ETA: 3s - loss: 0.0195Epoch 24/100\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0191 loss: 0.014s: 0.014 6s - loss: 0.015\n",
      " 45/134 [=========>....................] - ETA: 5s - loss: 0.0143Epoch 16/50 loss: 0.019\n",
      "67/67 [==============================] - 7s 99ms/step - loss: 0.0191\n",
      "50/67 [=====================>........] - ETA: 1s - loss: 0.0197Epoch 16/50\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0192\n",
      " 98/134 [====================>.........] - ETA: 2s - loss: 0.014oss: 0.0149Epoch 16/50\n",
      "67/67 [==============================] - 7s 100ms/step - loss: 0.0192\n",
      " 79/134 [================>.............] - ETA: 3s - loss: 0.0148Epoch 14/100\n",
      "67/67 [==============================] - 7s 98ms/step - loss: 0.0198...................] - ETA: 5s - loss: 0.020\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.0196Epoch 14/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0143\n",
      " 4/67 [>.............................] - ETA: 4s - loss: 0.0198Epoch 25/50\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0194==================>.......] - ETA: 1s - loss: 0.014\n",
      "114/134 [========================>.....] - ETA: 1s - loss: 0.0144Epoch 14/100...............] - ETA: 4s - loss: 0.018\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0146========================>.] - ETA: 0s - loss: 0.014\n",
      "20/67 [=======>......................] - ETA: 4s - loss: 0.0191Epoch 25/50\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0142 0.0\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.0147Epoch 25/50\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0143\n",
      "30/67 [============>.................] - ETA: 3s - loss: 0.0187Epoch 25/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0148.......] - ETA: 6s - loss: 0.016========================>..] - ETA: 0s - loss: 0.014\n",
      " 16/134 [==>...........................] - ETA: 6s - loss: 0.0140Epoch 25/100\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.01890s - loss: 0.018...........] - ETA: 4s - loss: 0.0\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0143\n",
      "41/67 [=================>............] - ETA: 2s - loss: 0.0198Epoch 25/100\n",
      "  1/134 [..............................] - ETA: 3s - loss: 0.0142Epoch 17/50\n",
      "67/67 [==============================] - 6s 97ms/step - loss: 0.0189......................] - ETA: 1s - loss: 0.0\n",
      " 42/134 [========>.....................] - ETA: 5s - loss: 0.0137Epoch 17/50\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0190=>....................] - ETA: 4s - loss: 0.01........................] - ETA: 5s - loss: 0.014.....................] - ETA: 5s - loss: 0.014\n",
      "15/67 [=====>........................] - ETA: 4s - loss: 0.0195Epoch 17/50\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0190\n",
      " 56/134 [===========>..................] - ETA: 4s - loss: 0.0142Epoch 15/100\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0196\n",
      " 79/134 [================>.............] - ETA: 2s - loss: 0.0142Epoch 15/100=====>.................] - ETA: 4s - loss: 0.014\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0192 - ETA: 1s - loss: 0.014\n",
      " 70/134 [==============>...............] - ETA: 3s - loss: 0.0146Epoch 15/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0141A: 3s - loss: 0.018=====>........................] - ETA: 4s - loss: 0.018\n",
      " 66/134 [=============>................] - ETA: 3s - loss: 0.0145Epoch 26/50\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0145..................] - ETA: 6s - loss: 0.019 - loss: 0.014- ETA: 1s - loss: 0.018========>..........] - ETA: 2s - loss: 0.014................] - ETA: 4s - loss: 0.020\n",
      "29/67 [===========>..................] - ETA: 3s - loss: 0.0185Epoch 26/50\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0140............] - ETA: 4s - loss: 0.015>..................] - ETA: 3s - loss: 0.018==============>.....] - ETA: 1s - loss: 0.014=========>...............] - ETA: 3s - loss: 0.019\n",
      "65/67 [============================>.] - ETA: 0s - loss: 0.0189Epoch 26/50\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0141\n",
      "  2/134 [..............................] - ETA: 13s - loss: 0.0144Epoch 26/100\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0188\n",
      "Epoch 18/50\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0188\n",
      " 53/134 [==========>...................] - ETA: 4s - loss: 0.0146Epoch 18/50\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.014==============================] - 8s 58ms/step - loss: 0.0146\n",
      " 57/134 [===========>..................] - ETA: 4s - loss: 0.0143Epoch 26/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0141.014: 0.0147s - loss: 0.014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22/134 [===>..........................] - ETA: 3s - loss: 0.014- ETA: 4s - loss: 0.0147Epoch 26/100\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0189\n",
      " 56/134 [===========>..................] - ETA: 4s - loss: 0.0144Epoch 18/50\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0189\n",
      " 61/134 [============>.................] - ETA: 4s - loss: 0.0142Epoch 16/100\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0194\n",
      "24/67 [=========>....................] - ETA: 3s - loss: 0.0182Epoch 16/100\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0191ETA: 4s - loss: 0.018\n",
      "103/134 [======================>.......] - ETA: 1s - loss: 0.0139Epoch 16/100..........] - ETA: 5s - loss: 0.017\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0140ETA: 5s - loss: 0.014=========>.....] - ETA: 1s - loss: 0.013==>.....] - ETA: 0s - loss: 0.013.........] - ETA: 5s - loss: 0.019..............] - ETA: 3s - loss: 0.018======================>.] - ETA: 0s - loss: 0.014\n",
      " 91/134 [===================>..........] - ETA: 2s - loss: 0.0140Epoch 27/50\n",
      "67/67 [==============================] - 6s 85ms/step - loss: 0.0187\n",
      " 95/134 [====================>.........] - ETA: 2s - loss: 0.0145Epoch 19/50\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0144\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.0139Epoch 27/50\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0187\n",
      " 9/67 [===>..........................] - ETA: 7s - loss: 0.0200Epoch 19/50\n",
      "134/134=====>........................] - ETA: 5s - loss: 0.01913===============>......] - ETA: 1s - loss: 0.014========================>..] - ETA: 0s - loss: 0.014 [==============================] - 7s 56ms/step - loss: 0.0139\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0139\n",
      " 47/134 [=========>....................] - ETA: 4s - loss: 0.0135Epoch 27/50\n",
      "  1/134 [..............................] - ETA: 3s - loss: 0.0150Epoch 27/100\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0188 - loss: 0.013\n",
      " 29/134 [=====>........................] - ETA: 5s - loss: 0.0143Epoch 19/50\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 0.0145\n",
      " 31/134 [=====>........................] - ETA: 5s - loss: 0.0142Epoch 27/100\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0188\n",
      "64/67 [===========================>..] - ETA: 0s - loss: 0.0194Epoch 17/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 0.0139- ETA: 5s - loss: 0.014\n",
      "Epoch 27/100\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0193\n",
      " 8/67 [==>...........................] - ETA: 6s - loss: 0.0186Epoch 17/100\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0189\n",
      " 57/134 [===========>..................] - ETA: 3s - loss: 0.0145Epoch 17/100\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0186......] - ETA: 4s - loss: 0.014..........] - ETA: 2s - loss: 0.018\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0138\n",
      "Epoch 20/50\n",
      " 84/134 [=================>............] - ETA: 2s - loss: 0.0138Epoch 28/50\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0185.......] - ETA: 2s - loss: 0.019...........] - ETA: 2s - loss: 0.018\n",
      "12/67 [====>.........................] - ETA: 5s - loss: 0.0187Epoch 20/50\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0142\n",
      "102/134 [=====================>........] - ETA: 1s - loss: 0.0141Epoch 28/50\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0187\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.0142Epoch 18/100\n",
      "67/67 [==============================] - 7s 102ms/step - loss: 0.0187\n",
      " 46/134 [=========>....................] - ETA: 5s - loss: 0.0139Epoch 20/50=================>..] - ETA: 0s - loss: 0.013\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0137\n",
      " 23/134 [====>.........................] - ETA: 6s - loss: 0.0145Epoch 28/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 0.0137====>.] - ETA: 0s - loss: 0.013\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.0142Epoch 28/50\n",
      "67/67 [==============================] - 7s 98ms/step - loss: 0.0192\n",
      "  7/134 [>.............................] - ETA: 6s - loss: 0.0142Epoch 18/100\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0188\n",
      " 8/67 [==>...........................] - ETA: 5s - loss: 0.0188Epoch 18/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0143ETA: 0s - loss: 0.014\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 8s 61ms/step - loss: 0.0138..............] - ETA: 6s - loss: 0.01\n",
      "18/67 [=======>......................] - ETA: 3s - loss: 0.0191Epoch 28/100\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0185\n",
      " 50/134 [==========>...................] - ETA: 4s - loss: 0.0145Epoch 21/50\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0184\n",
      " 46/134 [=========>....................] - ETA: 4s - loss: 0.0136Epoch 21/50\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0136\n",
      " 54/134 [===========>..................] - ETA: 4s - loss: 0.0135Epoch 29/50\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0186 - ETA: 5s - loss: 0.018=====>......] - ETA: 1s - loss: 0.014====>............] - ETA: 2s - loss: 0.\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0186\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.0142Epoch 19/100=========>.........] - ETA: 2s - loss: 0.013\n",
      " 99/134 [=====================>........] - ETA: 1s - loss: 0.0141Epoch 21/50\n",
      "67/67 [==============================] - 6s 87ms/step - loss: 0.0187\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0141\n",
      "112/134 [========================>.....] - ETA: 1s - loss: 0.0136Epoch 29/50\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 0.0190\n",
      "103/134 [======================>.......] - ETA: 1s - loss: 0.0142Epoch 19/100\n",
      " 28/134 [=====>........................] - ETA: 6s - loss: 0.0139Epoch 19/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0135....] - ETA: 2s - loss: 0.018=================>...] - ETA: 0s - loss: 0.013\n",
      "14/67 [=====>........................] - ETA: 4s - loss: 0.0183Epoch 29/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0141\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0135\n",
      " 31/134 [=====>........................] - ETA: 6s - loss: 0.0145Epoch 29/100\n",
      "24/67 [=========>....................] - ETA: 3s - loss: 0.0194Epoch 29/50\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0136.....................] - ETA: 5s - loss: 0\n",
      "34/67 [==============>...............] - ETA: 3s - loss: 0.0185Epoch 29/100\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0183 ETA: 2s - loss: 0.013\n",
      "  7/134 [>.............................] - ETA: 8s - loss: 0.0149Epoch 22/50\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0182\n",
      " 19/134 [===>..........................] - ETA: 7s - loss: 0.0144Epoch 22/50\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0185\n",
      " 77/134 [================>.............] - ETA: 3s - loss: 0.0139Epoch 22/50\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0186\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0185\n",
      "Epoch 20/100\n",
      " 5/67 [=>............................] - ETA: 3s - loss: 0.0171Epoch 20/100==========>......] - ETA: 1s - loss: 0.014\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0135\n",
      " 81/134 [=================>............] - ETA: 2s - loss: 0.0138Epoch 30/50\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0190\n",
      " 92/134 [===================>..........] - ETA: 2s - loss: 0.0131Epoch 20/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0140....] - ETA: 2s - loss: 0.013................] - ETA: 6s - loss: 0.013\n",
      "Epoch 30/50\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.013418ss: 0.013oss: 0.0\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.0140Epoch 30/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0140\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0134\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 56/134 [===========>..................] - ETA: 4s - loss: 0.0134Epoch 30/50............] - ETA: 3s - loss: 0.019\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0181\n",
      "  7/134 [>.............................] - ETA: 3s - loss: 0.0146Epoch 23/50\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0135s: 0.013loss: 0.018\n",
      " 49/134 [=========>....................] - ETA: 4s - loss: 0.0140Epoch 30/100\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0180\n",
      "14/67 [=====>........................] - ETA: 4s - loss: 0.0179Epoch 23/50\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0183oss: 0.013\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.0188Epoch 23/50\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0185\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0184\n",
      " 57/134 [===========>..................] - ETA: 4s - loss: 0.0139Epoch 21/100\n",
      " 59/134 [============>.................] - ETA: 4s - loss: 0.0133Epoch 21/100\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0188TA: 5s - loss: 0.013==============] - ETA: 0s - loss: 0.018\n",
      " 89/134 [==================>...........] - ETA: 2s - loss: 0.0140Epoch 21/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0134 0.014- loss: 0.013: 4s - loss: 0.01\n",
      " 79/134 [================>.............] - ETA: 3s - loss: 0.0136Epoch 31/50\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0139\n",
      "106/134 [======================>.......] - ETA: 1s - loss: 0.0133Epoch 31/50\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 0.0179\n",
      "51/67 [=====================>........] - ETA: 1s - loss: 0.0179Epoch 24/50\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0132 5s - loss: 0.012 - ETA: 3s - loss: 0.\n",
      "44/67 [==================>...........] - ETA: 2s - loss: 0.0181Epoch 31/100\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 0.0137\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.0132Epoch 31/100\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0178\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0132\n",
      "50/67 [=====================>........] - ETA: 1s - loss: 0.0182Epoch 24/50\n",
      " 58/134 [===========>..................] - ETA: 4s - loss: 0.0131Epoch 31/50\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0133oss: 0.018s - loss: 0.013\n",
      " 26/134 [====>.........................] - ETA: 6s - loss: 0.0133Epoch 31/100\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0184\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0182\n",
      "64/67 [===========================>..] - ETA: 0s - loss: 0.0187Epoch 22/100\n",
      " 33/134 [======>.......................] - ETA: 5s - loss: 0.0139Epoch 24/50\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0182\n",
      " 31/134 [=====>........................] - ETA: 5s - loss: 0.0120Epoch 22/100loss: 0.013\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0187\n",
      " 35/134 [======>.......................] - ETA: 5s - loss: 0.0121Epoch 22/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0132- loss: 0.013TA: 3s - loss: 0.017....] - ETA: 6s - loss: 0.0.] - ETA: 3s - loss: 0.01\n",
      "29/67 [===========>..................] - ETA: 3s - loss: 0.0178Epoch 32/50\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0176\n",
      " 87/134 [==================>...........] - ETA: 2s - loss: 0.0137Epoch 25/50\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0137\n",
      "100/134 [=====================>........] - ETA: 2s - loss: 0.0130Epoch 32/50\n",
      "67/67 [==============================] - 6s 97ms/step - loss: 0.0175\n",
      "45/67 [===================>..........] - ETA: 2s - loss: 0.0186Epoch 25/50\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0131] - ETA: 1s - loss: 0.017...................] - ETA: 3s - loss: 0.017/134 [=========>....................] - ETA: 5s - loss: 0.013\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0131\n",
      "Epoch 32/100\n",
      " 55/134 [===========>..................] - ETA: 4s - loss: 0.0131Epoch 32/50\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 0.0183\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0135\n",
      "108/134 [=======================>......] - ETA: 1s - loss: 0.0134Epoch 32/100\n",
      "  3/134 [..............................] - ETA: 18s - loss: 0.0122Epoch 23/100s - loss: 0.01\n",
      "67/67 [==============================] - 6s 97ms/step - loss: 0.0180=====>..] - ETA: 0s - loss: 0.018\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0181Epoch 25/50\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0181\n",
      " 2/67 [..............................] - ETA: 13s - loss: 0.0165Epoch 23/100\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0186\n",
      " 4/67 [>.............................] - ETA: 8s - loss: 0.0170 Epoch 23/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 0.0131] - ETA: 6s - loss: 0.014==========================>..] - ETA: 0s - loss: 0.013================>.............] - ETA: 3s - loss: 0.013\n",
      " 31/134 [=====>........................] - ETA: 6s - loss: 0.0131Epoch 32/100\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0173TA: 4s - loss: 0.017] - ETA: 5s - loss: 0.012.............] - ETA: 5s - loss: 0.014..............] - ETA: 4s - loss: 0.012========>..................] - ETA: 4s - loss: 0.012\n",
      " 62/134 [============>.................] - ETA: 4s - loss: 0.0122Epoch 26/50>.................] - ETA: 4s - loss: 0.013\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0131\n",
      " 79/134 [================>.............] - ETA: 3s - loss: 0.0125Epoch 33/50\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0172===>....] - ETA: 0s - loss: 0.\n",
      " 14/134 [==>...........................] - ETA: 6s - loss: 0.0124Epoch 26/50=>.....] - ETA: 0s - loss: 0.018\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0136\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.0184Epoch 33/50\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0182.] - ETA: 5s - loss: 0.015===>.....] - ETA: 1s - loss: 0.012\n",
      "109/134 [=======================>......] - ETA: 1s - loss: 0.0129Epoch 24/100\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0177\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.0128Epoch 26/50\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0178\n",
      "37/67 [===============>..............] - ETA: 2s - loss: 0.0177Epoch 24/100\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0185====>.........] - ETA: 2s - loss: 0.013\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0129\n",
      " 49/134 [=========>....................] - ETA: 4s - loss: 0.0131Epoch 33/50\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.0134Epoch 24/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0129..] - ETA: 3s - loss: 0.016\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0134\n",
      "110/134 [=======================>......] - ETA: 1s - loss: 0.0131Epoch 33/100\n",
      "16/67 [======>.......................] - ETA: 5s - loss: 0.0178Epoch 33/100\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0129loss: 0.012 5s - loss: 0.018 - loss: 0.017\n",
      " 22/134 [===>..........................] - ETA: 7s - loss: 0.0123Epoch 33/100s: 0.017\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0170\n",
      "30/67 [============>.................] - ETA: 3s - loss: 0.0172Epoch 27/50\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0168......] - ETA: 2s - loss: 0.016.............] - ETA: 2s - loss: 0.017================>.........] - ETA: 2s - loss: 0.012TA: 2s - loss: 0.017........] - ETA: 3s - loss: 0.018.....] - ETA: 2s - loss: 0.013: 0.013...................] - ETA: 4s - loss: 0.012\n",
      "101/134 [=====================>........] - ETA: 1s - loss: 0.0137Epoch 27/50\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0130013\n",
      "26/67 [==========>...................] - ETA: 3s - loss: 0.0163Epoch 34/50\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0182\n",
      " 80/134 [================>.............] - ETA: 3s - loss: 0.0127Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 6s 88ms/step - loss: 0.0175\n",
      "Epoch 25/100\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0174\n",
      " 4/67 [>.............................] - ETA: 5s - loss: 0.0158Epoch 27/50\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 0.0135\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0183\n",
      "Epoch 34/50\n",
      " 8/67 [==>...........................] - ETA: 5s - loss: 0.0167Epoch 25/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0128\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.0131Epoch 34/50\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0131\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0128\n",
      "26/67 [==========>...................] - ETA: 3s - loss: 0.0169Epoch 34/100\n",
      "21/67 [========>.....................] - ETA: 4s - loss: 0.0185Epoch 34/100\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0167\n",
      " 44/134 [========>.....................] - ETA: 4s - loss: 0.0134Epoch 28/50\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0128ETA: 2s - loss: 0.017..............] - ETA: 3s - loss: 0.018========================>..] - ETA: 0s - loss: 0.012======>.................] - ETA: 3s - loss: 0.013\n",
      "48/67 [====================>.........] - ETA: 1s - loss: 0.0182Epoch 34/100\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0165] - ETA: 6s - loss: 0.012 ETA: 6s - loss: 0.012loss: 0.017\n",
      " 79/134 [================>.............] - ETA: 2s - loss: 0.0134Epoch 28/50\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0181 loss: 0.013=================>..........] - ETA: 2s - loss: 0.013\n",
      " 96/134 [====================>.........] - ETA: 2s - loss: 0.0133Epoch 26/100\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0172>................] - ETA: 3s - loss: 0.01667 [===========================>..] - ETA: 0s - loss: 0.017\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.0129Epoch 26/100\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0170\n",
      " 63/134 [=============>................] - ETA: 4s - loss: 0.0134Epoch 28/50\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.01292\n",
      " 89/134 [==================>...........] - ETA: 2s - loss: 0.0128Epoch 35/50\n",
      "67/67 [==============================] - 6s 97ms/step - loss: 0.0181\n",
      " 77/134 [================>.............] - ETA: 3s - loss: 0.0129Epoch 26/100\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 0.0133...] - ETA: 2s - loss: 0.012......] - ETA: 4s - loss: 0.017\n",
      " 89/134 [==================>...........] - ETA: 2s - loss: 0.0128Epoch 35/50\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0165==================>.........] - ETA: 2s - loss: 0.0124/67 [=========>....................] - ETA: 4s - loss: 0.0181/134 [=>............................] - ETA: 9s - loss: 0.011 - loss: 0.012\n",
      " 25/134 [====>.........................] - ETA: 6s - loss: 0.0125Epoch 29/50\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 0.0127\n",
      "35/67 [==============>...............] - ETA: 2s - loss: 0.0167Epoch 35/50\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0129 - loss: 0.012...........] - ETA: 2s - loss: 0.016\n",
      " 43/134 [========>.....................] - ETA: 5s - loss: 0.0128Epoch 35/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0127\n",
      "110/134 [=======================>......] - ETA: 1s - loss: 0.0126Epoch 35/100\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0162A: 0s - loss: 0.01\n",
      "45/67 [===================>..........] - ETA: 2s - loss: 0.0180Epoch 29/50\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0125..] - ETA: 0s - loss: 0.012 - ETA: 0s - loss: 0.016\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.0170Epoch 35/100\n",
      "67/67 [==============================] - 6s 95ms/stloss: 0.017138ep - loss: 0.0179\n",
      "  4/134 [..............................] - ETA: 8s - loss: 0.0107Epoch 27/100\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0170\n",
      "16/67 [======>.......................] - ETA: 4s - loss: 0.0155Epoch 27/100\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0167\n",
      " 60/134 [============>.................] - ETA: 3s - loss: 0.0124Epoch 29/50\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0178\n",
      "46/67 [===================>..........] - ETA: 1s - loss: 0.0166Epoch 27/100\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0127......] - ETA: 5s - loss: 0.012....................] - ETA: 5s - loss: 0.016=========>...............] - ETA: 3s - loss: 0.012\n",
      "20/67 [=======>......................] - ETA: 4s - loss: 0.0170Epoch 36/50\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0132 loss: 0.013..........] - ETA: 3s - loss: 0.012...........] - ETA: 3s - loss: 0.016\n",
      "46/67 [===================>..........] - ETA: 1s - loss: 0.0159Epoch 36/50\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0163\n",
      "35/67 [==============>...............] - ETA: 2s - loss: 0.0174Epoch 30/50\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.012613................] - ETA: 4s - loss: 0.012.................] - ETA: 6s - loss: 0.014\n",
      " 78/134 [================>.............] - ETA: 3s - loss: 0.0126Epoch 36/50\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0160\n",
      " 39/134 [=======>......................] - ETA: 5s - loss: 0.0136Epoch 30/50\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.012/134 [==============================] - 8s 57ms/step - loss: 0.0126\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.0125Epoch 36/100\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 0.0177========================>..] - ETA: 0s - loss: 0.017\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0126\n",
      " 28/134 [=====>........................] - ETA: 5s - loss: 0.0117Epoch 28/100\n",
      " 74/134 [===============>..............] - ETA: 3s - loss: 0.0126Epoch 36/100\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0167s: 0.011\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 0.0164\n",
      "58/67 [========================>.....] - ETA: 0s - loss: 0.0175Epoch 30/50\n",
      " 1/67 [..............................] - ETA: 3s - loss: 0.0140Epoch 28/100\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0176\n",
      " 50/134 [==========>...................] - ETA: 4s - loss: 0.0120Epoch 28/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0123\n",
      "30/67 [============>.................] - ETA: 3s - loss: 0.0164Epoch 36/100\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0161................] - ETA: 4s - loss: 0.0124 [=>............................] - ETA: 5s - loss: 0.012..] - ETA: 4s - loss: 0\n",
      "112/134 [========================>.....] - ETA: 1s - loss: 0.0132Epoch 31/50\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 0.0126\n",
      " 35/134 [======>.......................] - ETA: 5s - loss: 0.0125Epoch 37/50\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0131: 5s - loss: 0.017....] - ETA: 4s - loss: 0.016.........] - ETA: 2s - loss: 0.016=============>....] - ETA: 0s - loss: 0.015\n",
      "Epoch 37/50\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 0.015812\n",
      " 12/134 [=>............................] - ETA: 5s - loss: 0.0124Epoch 31/50\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 0.0125 loss: 0.01770/134 [==============>...............] - ETA: 3s - loss: 0.01: 0s - loss: 0.012\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0175\n",
      "64/67 [===========================>..] - ETA: 0s - loss: 0.0163Epoch 29/100\n",
      " 59/134 [============>.................] - ETA: 3s - loss: 0.0130Epoch 37/50\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0162\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.0123Epoch 31/50\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0123: 1s - loss: 0.017\n",
      "22/67 [========>.....................] - ETA: 3s - loss: 0.0163Epoch 37/100: 5s - loss: 0.017\n",
      "67/67 [==============================] - 7s 97ms/step - loss: 0.0166\n",
      " 72/134 [===============>..............] - ETA: 3s - loss: 0.0129Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0125\n",
      " 79/134 [================>.............] - ETA: 2s - loss: 0.0128Epoch 37/100\n",
      "67/67 [==============================] - 6s 97ms/step - loss: 0.0172\n",
      "19/67 [=======>......................] - ETA: 4s - loss: 0.0185Epoch 29/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0120\n",
      " 52/134 [==========>...................] - ETA: 4s - lo: 0.01812ss: 0.0123Epoch 37/100\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0159\n",
      "50/67 [=====================>........] - ETA: 1s - loss: 0.0158Epoch 32/50\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 0.0125===============>.............] - ETA: 2s - loss: 0.01\n",
      "41/67 [=================>............] - ETA: 2s - loss: 0.0167Epoch 38/50\n",
      "67/67 [==============================] - 6s 84ms/step - loss: 0.0156\n",
      "116/134 [========================>.....] - ETA: 0s - loss: 0.0129Epoch 32/50- loss: 0.012\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0130- ETA: 3s - loss: 0.016==>..] - ETA: 0s - loss: 0.013\n",
      "55/67 [=======================>......] - ETA: 1s - loss: 0.0159Epoch 38/50\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0173] - ETA: 3s - loss: 0.012============>...] - ETA: 0s - loss: 0.016=====================] - ETA: 0s - loss: 0.017\n",
      "63/67 [===========================>..] - ETA: 0s - loss: 0.0164Epoch 30/100\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0160>.........................] - ETA: 5s - loss: 0.012\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0164\n",
      "25/67 [==========>...................] - ETA: 4s - loss: 0.0154Epoch 30/100\n",
      " 1/67 [..............................] - ETA: 2s - loss: 0.0159Epoch 32/50\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0123............................] - ETA: 5s - loss: 0.01\n",
      " 65/134 [=============>................] - ETA: 3s - loss: 0.0127Epoch 38/50\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0121[==============================] - ETA: 0s - loss: 0.012\n",
      " 67/134 [==============>...............] - ETA: 3s - loss: 0.0128Epoch 38/100\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0169\n",
      "38/67 [================>.............] - ETA: 2s - loss: 0.0153Epoch 30/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0124.0110153s - loss: 0.017\n",
      " 69/134 [==============>...............] - ETA: 3s - loss: 0.0128Epoch 38/100\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0157\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.0116Epoch 33/50\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0117\n",
      "41/67 [=================>............] - ETA: 2s - loss: 0.0164Epoch 38/100\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0154\n",
      "34/67 [==============>...............] - ETA: 2s - loss: 0.0169Epoch 33/50loss: 0.012\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0124\n",
      "Epoch 39/50\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0169=======================>.....] - ETA: 0s - loss: 0.\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0129......] - ETA: 6s - loss: 0.012\n",
      " 45/134 [=========>....................] - ETA: 4s - loss: 0.0117Epoch 39/50=========>.........] - ETA: 1s - loss: 0.012\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0163\n",
      "Epoch 31/100\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0158\n",
      " 99/134 [=====================>........] - ETA: 1s - loss: 0.0117Epoch 33/50\n",
      "67/67 [==============================] - ETA: 3s - loss: 0.01512: 0.015 loss: 0.0156s 87ms/step - loss: 0.0166\n",
      "113/134 [========================>.....] - ETA: 1s - loss: 0.0119Epoch 31/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0123======================>....] - ETA: 0s - loss: 0.012......] - ETA: 5s - loss: 0.015...........] - ETA: 4s - loss: 0.012........] - ETA: 5s - loss: 0.012\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0118\n",
      "104/134 [======================>.......] - ETA: 1s - loss: 0.0124Epoch 39/50\n",
      "105/134 [======================>.......] - ETA: 1s - loss: 0.0123Epoch 39/100\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0155\n",
      " 13/134 [=>............................] - ETA: 5s - loss: 0.0119Epoch 34/50\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0123\n",
      "42/67 [=================>............] - ETA: 2s - loss: 0.0165Epoch 39/100\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0152 loss: 0.012\n",
      "18/67 [=======>......................] - ETA: 4s - loss: 0.0156Epoch 34/50\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0114\n",
      " 54/134 [===========>..................] - ETA: 4s - loss: 0.0119Epoch 39/100\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.01660\n",
      " 17/134 [==>...........................] - ETA: 7s - loss: 0.0120Epoch 32/100\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0162\n",
      " 68/134 [==============>...............] - ETA: 3s - loss: 0.0120Epoch 32/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0122\n",
      "115/134 [========================>.....] - ETA: 1s - loss: 0.0127Epoch 40/50] - ETA: 2s - loss: 0.016\n",
      "67/67 [==============================] - 7s 98ms/step - loss: 0.01572\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.0162Epoch 34/50\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0164\n",
      "49/67 [====================>.........] - ETA: 1s - loss: 0.0151Epoch 32/100\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 0.0128\n",
      " 94/134 [====================>.........] - ETA: 2s - loss: 0.0116Epoch 40/50......................] - ETA: 6s - loss: 0.015\n",
      "67/67 [==============================] - 6s 98ms/step - loss: 0.0153.....] - ETA: 1s - loss: 0.012..........] - ETA: 4s - loss: 0.015...] - ETA: 1s - loss: 0.015\n",
      "37/67 [===============>..............] - ETA: 2s - loss: 0.0167Epoch 35/50\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0122\n",
      "33/67 [=============>................] - ETA: 3s - loss: 0.0159Epoch 40/50\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0116\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.0151Epoch 40/100\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0151=>...............] - ETA: 3s - loss: 0.\n",
      "52/67 [======================>.......] - ETA: 1s - loss: 0.0164Epoch 35/50\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0122\n",
      " 26/134 [====>.........................] - ETA: 7s - loss: 0.0123Epoch 40/100\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0163\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.0112Epoch 33/100\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0160\n",
      " 3/67 [>.............................] - ETA: 6s - loss: 0.0150Epoch 33/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0112...........] - ETA: 8s - loss: 0.012..........] - ETA: 4s - loss: 0.014\n",
      "56/67 [========================>.....] - ETA: 1s - loss: 0.0162Epoch 40/100\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.015515\n",
      " 27/134 [=====>........................] - ETA: 6s - loss: 0.0128Epoch 35/50\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 0.0119\n",
      "67/67 [==============================] - 7s 97ms/step - loss: 0.0162\n",
      "17/67 [======>.......................] - ETA: 4s - loss: 0.0155Epoch 41/50\n",
      "  1/134 [..............................] - ETA: 2s - loss: 0.0133Epoch 33/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0126A: 9s - loss: 0.01 0\n",
      " 63/134 [=============>................] - ETA: 4s - loss: 0.0125Epoch 41/50\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0151\n",
      " 54/134 [===========>..................] - ETA: 4s - loss: 0.0111Epoch 36/50\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0149======>.................] - ETA: 3s - loss: 0.011/134 [========================>.....] - ETA: 1s - loss: 0.\n",
      "53/67 [======================>.......] - ETA: 1s - loss: 0.0159Epoch 36/50\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0114\n",
      " 59/134 [============>.................] - ETA: 4s - loss: 0.0119Epoch 41/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0121\n",
      " 61/134 [============>.................] - ETA: 4s - loss: 0.0119Epoch 41/50\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 0.01613s - loss: 0.010\n",
      " 48/134 [=========>....................] - ETA: 4s - loss: 0.0122Epoch 34/100\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0159\n",
      "67/67 [==============================] - 6s 84ms/step - loss: 0.0153\n",
      " 8/67 [==>...........................] - ETA: 4s - loss: 0.0166Epoch 34/100\n",
      " 59/134 [============>.................] - ETA: 4s - loss: 0.0123Epoch 36/50\n",
      "134/134 [==============================] - 8s 63ms/step - loss: 0.0122s: 0.016s - loss: 0.017=======================>...] - ETA: 0s - loss: 0.0\n",
      " 38/134 [=======>......................] - ETA: 5s - loss: 0.0118Epoch 41/100\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0110A: 6s - loss: 0.010\n",
      "  8/134 [>.............................] - ETA: 4s - loss: 0.0110Epoch 41/100\n",
      "67/67 [==============================] - 6s 98ms/step - loss: 0.0160\n",
      "Epoch 34/100\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0150..] - ETA: 3s - loss: 0.011\n",
      " 73/134 [===============>..............] - ETA: 3s - loss: 0.0117Epoch 37/50\n",
      "134/134 [==============================] - 8s 62ms/step - loss: 0.0117....................] - ETA: 4s - loss: 0.012\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.0126Epoch 42/50\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0126...] - ETA: 1s - loss: 0.011\n",
      " 50/134 [==========>...................] - ETA: 4s - loss: 0.0109Epoch 42/50\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0147\n",
      "35/67 [==============>...............] - ETA: 2s - loss: 0.0160Epoch 37/50\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 0.0159\n",
      " 23/134 [====>.........................] - ETA: 5s - loss: 0.0118Epoch 35/100 ETA: 3s - loss: 0.010\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0113] - ETA: 2s - loss: 0.012\n",
      " 37/134 [=======>......................] - ETA: 6s - loss: 0.0123Epoch 42/100\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0157\n",
      "67/67 [==============================] - 6s 87ms/step - loss: 0.0151\n",
      " 32/134 [======>.......................] - ETA: 5s - loss: 0.0121Epoch 35/100\n",
      " 84/134 [=================>............] - ETA: 2s - loss: 0.0109Epoch 37/50\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0120...........] - ETA: 8s - loss: 0.011\n",
      " 87/134 [==================>...........] - ETA: 2s - loss: 0.0109Epoch 42/50\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0158.015 loss: 0.011ETA: 0s - loss: 0.015.....] - ETA: 4s - loss: 0.011- ETA: 3s - loss: 0.014\n",
      "110/134 [=======================>......] - ETA: 1s - loss: 0.0107Epoch 35/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 0.0121==============>..] - ETA: 0s - loss: 0.0\n",
      " 84/134 [=================>............] - ETA: 2s - loss: 0.0115Epoch 42/100\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0148 loss: 0.015=>..........] - ETA: 2s - loss: 0.0\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0108\n",
      " 56/134 [===========>..................] - ETA: 3s - loss: 0.0122Epoch 38/504\n",
      " 17/134 [==>...........................] - ETA: 5s - loss: 0.0126Epoch 42/100\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0145======>................] - ETA: 3s - loss: 0.012........] - ETA: 2s - loss: 0.012===================>.....] - ETA: 1s - loss: 0.\n",
      "20/67 [=======>......................] - ETA: 4s - loss: 0.0148Epoch 38/50\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0115s - loss: 0.012\n",
      " 96/134 [====================>.........] - ETA: 1s - loss: 0.0119Epoch 43/50\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0157\n",
      "Epoch 36/100\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 0.0155\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.0113Epoch 36/100\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0150\n",
      " 6/67 [=>............................] - ETA: 5s - loss: 0.0151Epoch 38/50\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0124\n",
      "16/67 [======>.......................] - ETA: 4s - loss: 0.0143Epoch 43/50 - ETA: 3s - loss: 0.012\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 0.0111...........] - ETA: 2s - loss: 0.014\n",
      "24/67 [=========>....................] - ETA: 4s - loss: 0.0139Epoch 43/100\n",
      "134/134 [==============================] - 7s 53ms/step - loss: 0.0119\n",
      " 79/134 [================>.............] - ETA: 3s - loss: 0.0107Epoch 43/50\n",
      "67/67 [==============================] - 7s 99ms/step - loss: 0.0156.......................] - ETA: 5s - loss: 0.01\n",
      " 93/134 [===================>..........] - ETA: 2s - loss: 0.0108Epoch 36/100\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0147...........] - ETA: 3s - loss: 0.015 [=============>................] - ETA: 3s - loss: 0.0157 [====================>.........] - ETA: 1s - loss: 0.014\n",
      "40/67 [================>.............] - ETA: 2s - loss: 0.0154Epoch 39/50\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0120ETA: 14s - loss: 0.013====>.] - ETA: 0s - loss: 0.012\n",
      " 85/134 [==================>...........] - ETA: 2s - loss: 0.0114Epoch 43/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0107\n",
      "24/67 [=========>....................] - ETA: 3s - loss: 0.0154Epoch 43/100\n",
      "67/67 [==============================] - 7s 100ms/step - loss: 0.0144\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.0146Epoch 39/50\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0155...........] - ETA: 2s - loss: 0.011\n",
      "106/134 [======================>.......] - ETA: 1s - loss: 0.0125Epoch 37/100=================>...] - ETA: 0s - loss: 0.011\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0148\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0153\n",
      "31/67 [============>.................] - ETA: 3s - loss: 0.0146Epoch 39/50\n",
      "111/134 [=======================>......] - ETA: 1s - loss: 0.0126Epoch 37/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0113: 0.013.] - ETA: 5s - loss: 0.010\n",
      "49/67 [====================>.........] - ETA: 1s - loss: 0.0154Epoch 44/50\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0124\n",
      "113/134 [========================>.....] - ETA: 1s - loss: 0.0118Epoch 44/50\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0154...........] - ETA: 5s - loss: 0.\n",
      " 34/134 [======>.......................] - ETA: 5s - loss: 0.0107Epoch 37/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0118\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0110\n",
      "62/67 [==========================>...] - ETA: 0s - loss: 0.0145Epoch 44/50\n",
      " 40/134 [=======>......................] - ETA: 5s - loss: 0.0108Epoch 44/100\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 0.0146\n",
      "47/67 [====================>.........] - ETA: 1s - loss: 0.0144Epoch 40/50...] - ETA: 5s - loss: 0.009\n",
      "67/67 [==============================] - 6s 85ms/step - loss: 0.01420.010 0.\n",
      "56/67 [========================>.....] - ETA: 0s - loss: 0.0147Epoch 40/50\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0120\n",
      " 73/134 [===============>..............] - ETA: 3s - loss: 0.0125Epoch 44/100\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 0.0154 ETA: 4s - loss: 0.010\n",
      " 98/134 [====================>.........] - ETA: 1s - loss: 0.0112Epoch 38/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0106015\n",
      " 81/134 [=================>............] - ETA: 2s - loss: 0.0125Epoch 44/100\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0151\n",
      " 65/134 [=============>................] - ETA: 3s - loss: 0.0123Epoch 38/100\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0147\n",
      " 66/134 [=============>................] - ETA: 3s - loss: 0.0123Epoch 40/501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 7s 53ms/step - loss: 0.01105\n",
      " 90/134 [===================>..........] - ETA: 2s - loss: 0.0112Epoch 45/50: 0.011\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0152\n",
      "27/67 [===========>..................] - ETA: 3s - loss: 0.0151Epoch 38/100\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 0.0123\n",
      "41/67 [=================>............] - ETA: 2s - loss: 0.0140Epoch 45/50\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0145] - ETA: 0s - loss: 0.0140.011: 5s - loss: 0.011\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.0109Epoch 41/50\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0109\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0117>..........] - ETA: 1s - loss: 0.015\n",
      " 81/134 [=================>............] - ETA: 3s - loss: 0.0103Epoch 45/50\n",
      "67/67 [==============================] - 6s 97ms/step - loss: 0.0141 loss: 0\n",
      "109/134 [=======================>......] - ETA: 1s - loss: 0.0119Epoch 41/50\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0152\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.0119Epoch 39/100\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0149=======>...] - ETA: 0s - loss: 0.011........................] - ETA: 6s - loss: 0.014\n",
      "14/67 [=====>........................] - ETA: 4s - loss: 0.0144Epoch 39/100\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0145 0.012\n",
      "42/67 [=================>............] - ETA: 2s - loss: 0.0153Epoch 41/50\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0119======================>.] - ETA: 0s - loss: 0.011\n",
      " 96/134 [====================>.........] - ETA: 2s - loss: 0.0107Epoch 45/100\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 0.0105TA: 3s - loss: 0.012\n",
      " 82/134 [=================>............] - ETA: 2s - loss: 0.0124Epoch 45/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0109s: 0.015loss: 0.014.012==========>.........] - ETA: 1s - loss: 0.014=======>.............] - ETA: 2s - loss: 0.010==================>...........] - ETA: 2s - loss: 0.010\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0151\n",
      "30/67 [============>.................] - ETA: 3s - loss: 0.0144Epoch 46/50\n",
      " 92/134 [===================>..........] - ETA: 2s - loss: 0.0107Epoch 39/100\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0144s: 0.014: 2s - loss: 0.01434 [=========>....................] - ETA: 4s - loss: 0.010\n",
      "109/134 [=======================>......] - ETA: 1s - loss: 0.0106Epoch 42/50\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.01220.011\n",
      "103/134 [======================>.......] - ETA: 1s - loss: 0.0117Epoch 46/50\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0108loss: 0.011>............................] - ETA: 5s - loss: 0.012===============>..............] - ETA: 3s - loss: 0.011....] - ETA: 5s - loss: 0.010\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.0116Epoch 46/100\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0140\n",
      "28/67 [===========>..................] - ETA: 3s - loss: 0.0148Epoch 42/500s - loss: 0.014\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0116............] - ETA: 5s - loss: 0.010\n",
      "  8/134 [>.............................] - ETA: 5s - loss: 0.0095Epoch 46/50\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 0.0150\n",
      " 87/134 [==================>...........] - ETA: 2s - loss: 0.0103Epoch 40/100\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0147\n",
      "104/134 [======================>.......] - ETA: 1s - loss: 0.0116Epoch 40/100\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0144\n",
      " 48/134 [=========>....................] - ETA: 4s - loss: 0.0125Epoch 42/50\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0118.................] - ETA: 5s - loss: 0.016=>......................] - ETA: 4s - loss: 0.0144 [=======>......................] - ETA: 4s - loss: \n",
      " 49/134 [=========>....................] - ETA: 4s - loss: 0.0114Epoch 46/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0104\n",
      " 97/134 [====================>.........] - ETA: 2s - loss: 0.0107Epoch 46/100\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0150\n",
      "28/67 [===========>..................] - ETA: 3s - loss: 0.0146Epoch 40/100\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0143==============>.....] - ETA: 0s - loss: 0.\n",
      " 83/134 [=================>............] - ETA: 2s - loss: 0.0113Epoch 43/50=====>........] - ETA: 1s - loss: 0.013\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0107\n",
      " 38/134 [=======>......................] - ETA: 5s - loss: 0.0104Epoch 47/50\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0120\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0139\n",
      "Epoch 47/50\n",
      "67/67 [==============================] - 6s 86ms/step - loss: 0.0148\n",
      "  3/134 [..............................] - ETA: 4s - loss: 0.0112Epoch 41/100\n",
      "56/67 [========================>.....] - ETA: 1s - loss: 0.0144Epoch 43/50\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0107\n",
      "28/67 [===========>..................] - ETA: 3s - loss: 0.0147Epoch 47/100A: 4s - loss: 0.010\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0146\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0143\n",
      " 41/134 [========>.....................] - ETA: 4s - loss: 0.0110Epoch 41/100\n",
      "36/67 [===============>..............] - ETA: 3s - loss: 0.0149Epoch 43/50\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0114..............] - ETA: 4s - loss: 0.013.....................] - ETA: 7s - loss: 0.011\n",
      "18/67 [=======>......................] - ETA: 4s - loss: 0.0146Epoch 47/50\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0117 0.014>.......................] - ETA: 6s - loss: 0.0124 [============>.................] - ETA: 3s - loss\n",
      "32/67 [=============>................] - ETA: 3s - loss: 0.0145Epoch 47/100\n",
      "67/67 [==============================] - 7s 99ms/step - loss: 0.0149\n",
      "43/67 [==================>...........] - ETA: 2s - loss: 0.0146Epoch 41/100\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0142................] - ETA: 3s - loss: 0.014\n",
      "39/67 [================>.............] - ETA: 2s - loss: 0.0147Epoch 44/50\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 0.0103loss: 0.010 0.013\n",
      " 5/67 [=>............................] - ETA: 5s - loss: 0.0133Epoch 47/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0106\n",
      "65/67 [============================>.] - ETA: 0s - loss: 0.0138Epoch 48/50\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0138\n",
      "18/67 [=======>......................] - ETA: 4s - loss: 0.0145Epoch 44/50\n",
      "67/67 [==============================] - 7s 99ms/step - loss: 0.0147=============>.....] - ETA: 1s - loss: 0.01\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.0119Epoch 42/100\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0144\n",
      "11/67 [===>..........................] - ETA: 5s - loss: 0.0129Epoch 42/100\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0142\n",
      " 50/134 [==========>...................] - ETA: 4s - loss: 0.0100Epoch 44/50\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0119\n",
      " 32/134 [======>.......................] - ETA: 5s - loss: 0.0106Epoch 48/50\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0107======>...................] - ETA: 4s - loss: 0.0\n",
      " 40/134 [=======>......................] - ETA: 5s - loss: 0.0109Epoch 48/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0112 [=>............................] - ETA: 7s - loss: 0.0\n",
      "31/67 [============>.................] - ETA: 3s - loss: 0.0140Epoch 48/50\n",
      "67/67 [==============================] - 7s 100ms/step - loss: 0.01480 0.010\n",
      "37/67 [===============>..............] - ETA: 3s - loss: 0.0142Epoch 42/100\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84/134 [=================>............] - ETA: 3s - loss: 0.0105Epoch 45/50A: 1s - loss: 0.010\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 0.01170.011\n",
      "103/134 [======================>.......] - ETA: 1s - loss: 0.0104Epoch 48/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0102\n",
      " 61/134 [============>.................] - ETA: 4s - loss: 0.0111Epoch 48/100\n",
      "67/67 [==============================] - 7s 101ms/step - loss: 0.0137\n",
      "67/67 [==============================] - 6s 97ms/step - loss: 0.0145\n",
      "21/67 [========>.....................] - ETA: 4s - loss: 0.0147Epoch 43/100\n",
      " 66/134 [=============>................] - ETA: 3s - loss: 0.0110Epoch 45/50=======>...] - ETA: 0s - loss: 0.010\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0105......] - ETA: 1s - loss: 0.011\n",
      " 7/67 [==>...........................] - ETA: 6s - loss: 0.0158Epoch 49/50\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0141\n",
      "67/67 [==============================] - 7s 100ms/step - loss: 0.0143\n",
      "10/67 [===>..........................] - ETA: 4s - loss: 0.0129Epoch 43/100\n",
      "100/134 [=====================>........] - ETA: 1s - loss: 0.0105Epoch 45/50\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0118.........................] - ETA: 5s - loss: 0.015....] - ETA: 1s - loss: 0.010.........] - ETA: 6s - loss: 0.0=======>...........] - ETA: 2s - loss: 0.014/134 [=====================>........] - ETA: 1s - loss: 0.011\n",
      "Epoch 49/50\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0106- loss: 0.0\n",
      " 64/134 [=============>................] - ETA: 4s - loss: 0.0117Epoch 49/100\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0109\n",
      " 91/134 [===================>..........] - ETA: 2s - loss: 0.0114Epoch 49/50\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0147\n",
      "63/67 [===========================>..] - ETA: 0s - loss: 0.0141Epoch 43/100\n",
      "67/67 [==============================] - 7s 98ms/step - loss: 0.0140.............] - ETA: 8s - loss: 0.0103\n",
      "50/67 [=====================>........] - ETA: 1s - loss: 0.0137Epoch 46/50\n",
      "67/67 [==============================] - 6s 97ms/step - loss: 0.0144.................] - ETA: 4s - loss: 0.010>.........] - ETA: 1s - loss: 0.014>..................] - ETA: 3s - loss: \n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0136\n",
      "20/67 [=======>......................] - ETA: 4s - loss: 0.0143Epoch 44/100\n",
      "66/67 [============================>.] - ETA: 0s - loss: 0.0141Epoch 46/50\n",
      "67/67 [==============================] - 6s 88ms/step - loss: 0.0140\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0116\n",
      " 46/134 [=========>....................] - ETA: 5s - loss: 0.0108Epoch 49/100\n",
      "  1/134 [..............................] - ETA: 2s - loss: 0.0108Epoch 46/50\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0142\n",
      " 81/134 [=================>............] - ETA: 2s - loss: 0.0100Epoch 44/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0102=================>............] - ETA: 2s - loss: 0.\n",
      "16/67 [======>.......................] - ETA: 4s - loss: 0.0143Epoch 49/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0104\n",
      "18/67 [=======>......................] - ETA: 4s - loss: 0.0140Epoch 50/50\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0116======================>...] - ETA: 0s - loss: 0.011============>................] - ETA: 3s - loss: 0.013..............] - ETA: 2s - loss: 0.014\n",
      "Epoch 50/50\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0105\n",
      "105/134 [======================>.......] - ETA: 1s - loss: 0.0108Epoch 50/100\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0146\n",
      "107/134 [======================>.......] - ETA: 1s - loss: 0.0108Epoch 44/100\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0140ss: 0.010\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.0108Epoch 47/50.............] - ETA: 3s - loss: 0.010\n",
      "134/134 [===================>........] - ETA: 1s - loss: 0.01410: 2s - loss: 0.011==============>...............] - ETA: 3s - loss: 0.010===========================] - 8s 57ms/step - loss: 0.0108\n",
      " 29/134 [=====>........................] - ETA: 5s - loss: 0.0105Epoch 50/50\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0143==>......................] - ETA: 5s - loss: 0.01067 [========>.....................] - ETA: 4s - loss: 0.014\n",
      " 52/134 [==========>...................] - ETA: 4s - loss: 0.0108Epoch 45/100\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0135A: 3s - loss: 0.014\n",
      " 54/134 [===========>..................] - ETA: 4s - loss: 0.0107Epoch 47/50\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0140\n",
      " 24/134 [====>.........................] - ETA: 6s - loss: 0.0114Epoch 47/50\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0141\n",
      "24/67 [=========>....................] - ETA: 4s - loss: 0.0138Epoch 45/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0115A: 4s - loss: 0.014.] - ETA: 4s - loss: 0.\n",
      "20/67 [=======>......................] - ETA: 4s - loss: 0.0138Epoch 50/100...........] - ETA: 3s - loss: 0.010\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0101.....] - ETA: 5s - loss: 0.011\n",
      "22/67 [========>.....................] - ETA: 4s - loss: 0.0139Epoch 50/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0103\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0145\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.0104Epoch 45/100\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0139.........] - ETA: 2s - loss: 0.01334 [===========================>..] - ETA: 0s - loss: 0.011\n",
      "48/67 [====================>.........] - ETA: 1s - loss: 0.0136Epoch 48/50\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0113\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0105\n",
      " 56/134 [===========>..................] - ETA: 4s - loss: 0.0115Epoch 51/100\n",
      "67/67 [==============================] - 6s 84ms/step - loss: 0.0139======================>.....] - ETA: 0s - loss: 0.013=================>...] - ETA: 0s - loss: 0.0\n",
      " 79/134 [================>.............] - ETA: 2s - loss: 0.0114Epoch 48/50\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0141\n",
      " 82/134 [=================>............] - ETA: 2s - loss: 0.0115Epoch 46/100............] - ETA: 4s - loss: 0.009\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0134\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.0106Epoch 48/50\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0106\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0139\n",
      "Epoch 46/100\n",
      "67/67 [==============================] - 4s 26ms/step - loss: 0.0107...........] - ETA: 3s - loss: 0.010- ETA: 2s - loss: 0.01\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 0.01140.01\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.0100Epoch 51/100\n",
      "67/67 [==============================] - 4s 27ms/step - loss: 0.0114\n",
      "67/67 [==============================] - 5s 82ms/step - loss: 0.0143.013\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 0.0101\n",
      "37/67 [===============>..............] - ETA: 2s - loss: 0.0131Epoch 46/100\n",
      " 1/67 [..............................] - ETA: 3s - loss: 0.0149Epoch 51/100\n",
      "67/67 [==============================] - 5s 78ms/step - loss: 0.0138A: 1s - loss: 0.014\n",
      "43/67 [==================>...........] - ETA: 1s - loss: 0.0133Epoch 49/50\n",
      "67/67 [==============================] - 3s 26ms/step - loss: 0.0107 ETA: 0s - loss: 0.0104 [================>.............] - ETA: 1s - loss: 0.010\n",
      "134/134 [==============================] - 6s 45ms/step - loss: 0.0104[====================>.........] - ETA: 1s - loss: 0.0\n",
      "53/67 [======================>.......] - ETA: 1s - loss: 0.0139Epoch 52/100\n",
      "67/67 [==============================] - 5s 78ms/step - loss: 0.0140.....................] - ETA: 11s - loss: 0.010\n",
      " 62/134 [============>.................] - ETA: 3s - loss: 0.0118Epoch 47/100\n",
      "67/67 [==============================] - 5s 81ms/step - loss: 0.0138===============>...] - ETA: 0s - loss: 0.013\n",
      " 66/134 [=============>................] - ETA: 3s - loss: 0.0119Epoch 49/50\n",
      "134/134 [==============================] - 4s 28ms/step - loss: 0.0103\n",
      "67/67 [==============================] - 6s 85ms/step - loss: 0.0133- loss: 0.014\n",
      "67/67 [==============================] - 5s 80ms/step - loss: 0.0138\n",
      "Epoch 49/50\n",
      " 50/134 [==========>...................] - ETA: 4s - loss: 0.0099Epoch 47/100\n",
      "134/134 [==============================] - 4s 30ms/step - loss: 0.0113===>.....................] - ETA: 3s - loss: 0.010TA: 2s - loss: 0.013ETA: 1s - loss: 0.014.....] - ETA: 3s - loss: 0.] - ETA: 3s - loss: 0.010=>...] - ETA: 0s - loss: 0.011\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 0.0113\n",
      "Epoch 52/100\n",
      "67/67 [==============================] - 5s 76ms/step - loss: 0.0143\n",
      "134/134 [==============================] - 4s 26ms/step - loss: 0.0105\n",
      "Epoch 47/100\n",
      "67/67 [==============================] - 5s 78ms/step - loss: 0.0137oss: 0.014..........] - ETA: 1s - loss: 0.013\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.0100Epoch 50/50\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 0.0100============>...........] - ETA: 1s - loss: 0.014=>.....] - ETA: 0s - loss: 0.013\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.0138Epoch 52/100\n",
      "67/67 [==============================] - 5s 76ms/step - loss: 0.01372s - loss: 0.013\n",
      "Epoch 50/50\n",
      "67/67 [==============================] - 5s 80ms/step - loss: 0.0139\n",
      "134/134 [==============================] - 6s 43ms/step - loss: 0.0104\n",
      "25/67 [==========>...................] - ETA: 2s - loss: 0.0136Epoch 48/100\n",
      " 1/67 [..............................] - ETA: 3s - loss: 0.0136Epoch 53/100\n",
      "67/67 [==============================] - 5s 73ms/step - loss: 0.0132\n",
      " 7/67 [==>...........................] - ETA: 3s - loss: 0.0133Epoch 50/50\n",
      "67/67 [==============================] - 5s 75ms/step - loss: 0.0137......] - ETA: 2s - loss: 0.013\n",
      " 65/134 [=============>................] - ETA: 2s - loss: 0.0112Epoch 48/100\n",
      "67/67 [==============================] - 5s 75ms/step - loss: 0.0142................] - ETA: 4s - loss: 0.010s: 0.01/134 [=====>........................] - ETA: 4s - loss: 0.01===========>..................] - ETA: 2s - loss: 0.013s: 0.0\n",
      "35/67 [==============>...............] - ETA: 2s - loss: 0.0129Epoch 48/100\n",
      "67/67 [==============================] - 5s 68ms/step - loss: 0.0136 0.013\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.0111......................] - ETA: 2s - loss: 0.014\n",
      "Epoch 53/100\n",
      "101/134 [=====================>........] - ETA: 1s - loss: 0.0104Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "103/134 [======================>.......] - ETA: 1s - loss: 0.0104       Output Shape              Param #   \n",
      "=================================================================\n",
      " Input Layer (InputLayer)    [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 13, 32)        896       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                46100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,492\n",
      "Trainable params: 65,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "67/67 [==============================] - 4s 65ms/step - loss: 0.0136\n",
      " 25/134 [====>.........................] - ETA: 4s - loss: 0.0118           Param #   \n",
      "=================================================================\n",
      "105/134 [======================>.......] - ETA: 1s - loss: 0.0104(InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1568)              32928     \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 14, 14, 64)       18496     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 28, 28, 3)        867       \n",
      "62/67 [==========================>...] - ETA: 0s - loss: 0.0137                                             loss: 0.010\n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 5s 68ms/step - loss: 0.0138\n",
      "112/134 [========================>.....] - ETA: 0s - loss: 0.0103Epoch 49/100\n",
      "67/67 [==============================] - 4s 63ms/step - loss: 0.0136\n",
      "65/67 [============================>.] - ETA: 0s - loss: 0.0131Epoch 49/100\n",
      "67/67 [==============================] - 4s 67ms/step - loss: 0.0131\n",
      "134/134 [==============================] - 6s 42ms/step - loss: 0.0100.................] - ETA: 3s - loss: 0.013\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.0103Epoch 53/100\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.0103....] - ETA: 3s - loss: 0.01\n",
      "14/67 [=====>........................] - ETA: 3s - loss: 0.0135Epoch 54/100\n",
      "34/34 [==============================] - 3s 26ms/step - loss: 0.0138............] - ETA: 3s - loss: 0.0\n",
      " 72/134 [===============>..............] - ETA: 2s - loss: 0.0108Model: \"encoder\"....................] - ETA: 4s - loss: 0.010\n",
      "_________________________________________________________________\n",
      " 78/134 [================>.............] - ETA: 2s - loss: 0.0108ayer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input Layer (InputLayer)    [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 13, 32)        896       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                46100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,492\n",
      "Trainable params: 65,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 20)]              0         \n",
      " 80/134 [================>.............] - ETA: 1s - loss: 0.0109         \n",
      " dense_3 (Dense)             (None, 1568)              32928     \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 14, 14, 64)       18496     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 28, 28, 3)        867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/67 [===>..........................] - ETA: 3s - loss: 0.0132Model: \"encoder\"....] - ETA: 2:38 - loss: 0.3919............] - ETA: 1s - loss: 0.010\n",
      "_________________________________________________________________\n",
      "12/67 [====>.........................] - ETA: 3s - loss: 0.0133            Param #   \n",
      "=================================================================\n",
      " 90/134 [===================>..........] - ETA: 1s - loss: 0.0109tLayer)    [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 13, 32)        896       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                46100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,492\n",
      "Trainable params: 65,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1568)              32928     \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 14, 14, 64)       18496     \n",
      " ranspose)                                                       \n",
      " 51/134 [==========>...................] - ETA: 3s - loss: 0.0100                                         \n",
      "15/67 [=====>........................] - ETA: 3s - loss: 0.0130    ===>.......................] - ETA: 4s - loss: 0.010\n",
      " ranspose)                                                       \n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0141                                     \n",
      " conv2d_transpose_5 (Conv2DT  (None, 28, 28, 3)        867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "67/67 [==============================] - 4s 62ms/step - loss: 0.0141\n",
      "25/34 [=====================>........] - ETA: 1s - loss: 0.4407Epoch 49/100\n",
      "34/34 [==============================] - 3s 44ms/step - loss: 0.0132.........................] - ETA: 7s - loss: 0.40\n",
      "34/34 [==============================] - 10s 123ms/step - loss: 0.4381....] - ETA: 3s - loss: 0.0\n",
      "12/34 [=========>....................] - ETA: 3s - loss: 0.4396Epoch 2/10\n",
      "67/67 [==============================] - 3s 40ms/step - loss: 0.0136\n",
      "134/134 [==============================] - 5s 40ms/step - loss: 0.0109\n",
      " 4/34 [==>...........................] - ETA: 3s - loss: 0.4243Epoch 54/100\n",
      "67/67 [==============================] - 5s 71ms/step - loss: 0.01370.43\n",
      "18/34 [==============>...............] - ETA: 2s - loss: 0.4382Epoch 50/100\n",
      "67/67 [==============================] - 5s 73ms/step - loss: 0.0136loss: 0.010\n",
      " 93/134 [===================>..........] - ETA: 1s - loss: 0.0104Epoch 50/100\n",
      "67/67 [==============================] - 3s 30ms/step - loss: 0.0130==========>.......] - ETA: 1s - loss: 0.009...] - ETA: 4s - loss: 0.\n",
      "34/34 [==============================] - 9s 138ms/step - loss: 0.4291\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.0099Epoch 2/10\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 0.0099\n",
      " 41/134 [========>.....................] - ETA: 5s - loss: 0.0108Epoch 54/100\n",
      "34/34 [==============================] - 10s 141ms/step - loss: 0.43421s - loss: 0.391\n",
      "134/134 [==============================] - 6s 46ms/step - loss: 0.0103\n",
      "Epoch 55/100\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.0138Epoch 2/10\n",
      "67/67 [==============================] - 5s 76ms/step - loss: 0.0140\n",
      " 5/34 [===>..........................] - ETA: 3s - loss: 0.4074Epoch 50/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.362100.3=============================] - 4s 127ms/step - loss: 0.3626\n",
      "12/67 [====>.........................] - ETA: 3s - loss: 0.0144Epoch 3/10\n",
      "67/67 [==============================] - 5s 79ms/step - loss: 0.0136.................] - ETA: 3s - loss: 0.ss: 0.0\n",
      "67/67 [==============================] - 5s 75ms/step - loss: 0.0134\n",
      " 80/134 [================>.............] - ETA: 2s - loss: 0.0099Epoch 51/100\n",
      " 73/134 [===============>..............] - ETA: 2s - loss: 0.0104Epoch 51/100\n",
      "34/34 [==============================] - 4s 123ms/step - loss: 0.3447\n",
      "130/134 [============================>.] - ETA: 0s - loss: 0.0107Epoch 3/10\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 0.0107s - loss: 0.208\n",
      " 91/134 [===================>..........] - ETA: 1s - loss: 0.0099Epoch 55/100\n",
      "34/34 [==============================] - 4s 117ms/step - loss: 0.3388\n",
      "13/67 [====>.........................] - ETA: 3s - loss: 0.0130Epoch 3/10\n",
      "34/34 [==============================] - 4s 118ms/step - loss: 0.1335=>.........................] - ETA: 4s - loss: 0.010........] - ETA: 2s - loss: 0.0\n",
      "12/34 [=========>....................] - ETA: 2s - loss: 0.1545Epoch 4/10\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 0.0099\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.0102Epoch 55/100\n",
      "67/67 [==============================] - 5s 75ms/step - loss: 0.0139\n",
      "Epoch 51/100\n",
      " 10/134 [=>............................] - ETA: 3s - loss: 0.0096der\" \"enc\n",
      "_________________________________________________________________\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.0102put Shape              Param #   \n",
      "=================================================================\n",
      " Input Layer (InputLayer)    [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 13, 13, 32)        896       \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 20)                46100     \n",
      "38/67 [================>.............] - ETA: 2s - loss: 0.0135                 \n",
      "=================================================================\n",
      "Total params: 65,492\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.0102ainable params: 65,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1568)              32928     \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_6 (Conv2DT  (None, 14, 14, 64)       18496     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_7 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_8 (Conv2DT  (None, 28, 28, 3)        867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 0.0102\n",
      " 49/134 [=========>....................] - ETA: 3s - loss: 0.0103Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/67 [======================>.......] - ETA: 1s - loss: 0.0136Model: \"encoder\"....] - ETA: 3s - loss: 0..........] - ETA: 2s - loss: 0.066\n",
      "53/67 [======================>.......] - ETA: 1s - loss: 0.0136______________======>..] - ETA: 0s - loss: 0.120\n",
      " Layer (type)                Output Shape              Param #   \n",
      " 44/134 [========>.....................] - ETA: 4s - loss: 0.0099=======================================\n",
      " Input Layer (InputLayer)    [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 13, 13, 32)        896       \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.0135            46100     \n",
      "                                                                 \n",
      " 31/134 [=====>........................] - ETA: 5s - loss: 0.0105===============================================\n",
      "Total params: 65,492\n",
      "Trainable params: 65,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1568)              32928     \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_6 (Conv2DT  (None, 14, 14, 64)       18496     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_7 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_8 (Conv2DT  (None, 28, 28, 3)        867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 4s 128ms/step - loss309............................] - ETA: 2:40 - loss: 0.456: 0.1185\n",
      "56/67 [========================>.....] - ETA: 0s - loss: 0.0137Epoch 4/10\n",
      "67/67 [==============================] - 5s 79ms/step - loss: 0.0134.....................] - ETA: 5s - loss: 0.010......] - ETA: 4s - loss: 0.449\n",
      "34/67 [==============>...............] - ETA: 2s - loss: 0.0138Epoch 52/100\n",
      "34/34 [==============================] - 5s 134ms/step - loss: 0.1129\n",
      " 63/134 [=============>................] - ETA: 3s - loss: 0.0099Epoch 4/10\n",
      "67/67 [==============================] - 6s 86ms/step - loss: 0.0135\n",
      "11/34 [========>.....................] - ETA: 3s - loss: 0.4434Epoch 52/100\n",
      "34/34 [==============================] - 5s 140ms/step - loss: 0.0583=========>.......] - ETA: 1s - loss: 0.010TA: 2s - loss: 0.43\n",
      "14/67 [=====>........................] - ETA: 4s - loss: 0.0133Epoch 5/10\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0104 - ETA: 4s - loss: 0.013ETA: 2s - loss: 0.010\n",
      "104/134 [======================>.......] - ETA: 1s - loss: 0.0098Epoch 56/100\n",
      "34/34 [==============================] - 10s 149ms/step - loss: 0.4416\n",
      "30/67 [============>.................] - ETA: 2s - loss: 0.0135Epoch 2/50\n",
      "67/67 [==============================] - 6s 87ms/step - loss: 0.0138\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.0098Epoch 52/100\n",
      "34/34 [==============================] - 10s 148ms/step - loss: 0.4319..] - ETA: 3s - loss: 0.0\n",
      "134/134 [==============================] - 7s 51ms/step - loss: 0.0098\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.0102Epoch 56/100 loss: 0.051\n",
      "49/67 [====================>.........] - ETA: 1s - loss: 0.0133Epoch 2/50\n",
      "34/34 [==============================] - 5s 153ms/step - loss: 0.0539.........] - ETA: 2s - loss: 0.427\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0508Epoch 5/10\n",
      "34/34 [==============================] - 5s 137ms/step - loss: 0.0507\n",
      "22/34 [==================>...........] - ETA: 1s - loss: 0.0438Epoch 5/10\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0102\n",
      " 17/134 [==>...........................] - ETA: 7s - loss: 0.0097Epoch 57/100\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 0.0133s: 0.41\n",
      " 35/134 [======>.......................] - ETA: 5s - loss: 0.0097Epoch 53/100\n",
      "34/34 [==============================] - 5s 148ms/step - loss: 0.0421\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0134- loss: 0.408\n",
      " 46/134 [=========>....................] - ETA: 5s - loss: 0.0096Epoch 53/100\n",
      " 80/134 [================>.............] - ETA: 3s - loss: 0.0102Epoch 6/10\n",
      "34/34 [==============================] - 3s 48ms/step - loss: 0.0135\n",
      "34/34 [==============================] - 5s 150ms/step - loss: 0.4007 loss: 0.01\n",
      " 7/67 [==>...........................] - ETA: 6s - loss: 0.0130Epoch 3/50\n",
      "34/34 [==============================] - 5s 153ms/step - loss: 0.3730s - loss: 0.013 [======>.......................] - ETA: 4s - loss: 0.038 0.311: 0.3...............] - ETA: 3s - loss: 0.01\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.0103Epoch 3/50\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0137: 0s - loss: 0.013\n",
      " 2/34 [>.............................] - ETA: 3s - loss: 0.2631Epoch 53/100\n",
      "34/34 [==============================] - 5s 147ms/step - loss: 0.0410========================>.] - ETA: 0s - loss: 0.010\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0102\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 5s 148ms/step - loss: 0.0394\n",
      "Epoch 57/100\n",
      " 6/67 [=>............................] - ETA: 5s - loss: 0.0133Epoch 6/10\n",
      "67/67 [==============================] - 3s 43ms/step - loss: 0.0135\n",
      "34/34 [==============================] - 5s 154mss - loss: 0.009====>........] - ETA: 1s - loss: 0.013A: 1s - loss: 0.2...................] - ETA: 6s - loss: 0.010/step - loss: 0.0357\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0098\n",
      "Epoch 57/100\n",
      "15/34 [============>.................] - ETA: 2s - loss: 0.0360Epoch 7/10\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0132\n",
      " 36/134 [=======>......................] - ETA: 6s - loss: 0.0106Epoch 54/100\n",
      "34/34 [==============================] - 5s 152ms/step - loss: 0.1791==========>....] - ETA: 0s - loss: 0.013\n",
      " 6/34 [====>.........................] - ETA: 4s - loss: 0.0330Epoch 4/50.010\n",
      "134/134 [=========================>..] - ETA: 0s - loss: 0.01310============] - 8s 58ms/step - loss: 0.0101\n",
      "Epoch 58/100\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0133\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 5s 148ms/step - loss: 0.14301s - loss: 0.03 [===================>..........] - ETA: 1s - loss: 0.013.....] - ETA: 0s - loss: 0.035\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0344Epoch 4/50\n",
      "34/34 [==============================] - 5s 144ms/step - loss: 0.0353........] - ETA: 5s - loss: 0.069\n",
      "34/34 [==============================] - 5s 143ms/step - loss: 0.0345\n",
      "19/67 [=======>......................] - ETA: 4s - loss: 0.0138Epoch 7/10\n",
      "27/67 [===========>..................] - ETA: 4s - loss: 0.0136Epoch 7/10\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0136.] - ETA: 3s - loss: 0.013\n",
      " 48/134 [=========>....................] - ETA: 5s - loss: 0.0100Epoch 54/100\n",
      "34/34 [==============================] - 5s 138ms/step - loss: 0.0318 - loss: 0.059\n",
      "48/67 [====================>.........] - ETA: 1s - loss: 0.0132Epoch 8/10\n",
      "34/34 [==============================] - 4s 132ms/step - loss: 0.0575......] - ETA: 3s - loss: 0.010\n",
      "21/34 [=================>............] - ETA: 1s - loss: 0.0581Epoch 5/50\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 0.0100=>...........] - ETA: 2s - loss: 0.010\n",
      "21/67 [========>.....................] - ETA: 4s - loss: 0.0134Epoch 58/100\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0131.................] - ETA: 13s - loss: 0.010\n",
      "Epoch 55/100\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0315Model: \"encoder\">................] - ETA: 2s - loss: 0.03\n",
      "_________________________________________________________________\n",
      "34/34 [==============================] - 5s 144ms/step - loss: 0.0538\n",
      "129/134 [===========================>..] - ETA: 0s - loss: 0.0098             Param #   \n",
      "=================================================================\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0132\n",
      " Layer (InputLayer)    [(None, 28, 28, 3)]       0         \n",
      "                                         Epoch 5/50\n",
      "39/67 [================>.............] - ETA: 2s - loss: 0.0131                        \n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0318Epoch 55/100\n",
      " 24/134 [====>.........................] - ETA: 6s - loss: 0.0099nv2d_4 (Conv2D)           (None, 13, 13, 32)        896       \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 20)                46100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,492\n",
      "Trainable params: 65,492\n",
      "Non-trainable params: 0\n",
      " 2/34 [>.............................] - ETA: 5s - loss: 0.0437_____________________________________________________________\n",
      "Model: \"decoder\"\n",
      "34/34 [==============================] - 5s 143ms/step - loss: 0.0317\n",
      " 25/134 [==========================>.] - ETA: 0s - loss: 0.031===>.........................] - ETA: 7s - loss: 0.0097_________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1568)              32928     \n",
      "                                                                 \n",
      "22/34 [==================>...........] - ETA: 1s - loss: 0.03012)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_6 (Conv2DT  (None, 14, 14, 64)       18496     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_7 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_8 (Conv2DT  (None, 28, 28, 3)        867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "18/34 [==============>...............] - ETA: 2s - loss: 0.0441Epoch 8/10\n",
      "16/67 [======>.......................] - ETA: 4s - loss: 0.0124======\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 5s 144ms/step - loss: 0.0314\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0098\n",
      "17/67 [======>.......................] - ETA: 4s - loss: 0.0124Epoch 58/100\n",
      " 5/67 [=>............................] - ETA: 7s - loss: 0.0133Epoch 8/10\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0101=====================>...] - ETA: 0s - loss: 0.010- loss: 0.0\n",
      "26/67 [==========>...................] - ETA: 3s - loss: 0.0125Epoch 59/100\n",
      "34/34 [==============================] - 5s 142ms/step - loss: 0.0291\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.0135Epoch 9/10\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.01350.4\n",
      "34/34 [==============================] - 5s 149ms/step - loss: 0.0422\n",
      "29/67 [===========>..................] - ETA: 3s - loss: 0.0133Epoch 6/50\n",
      "22/34 [==================>...........] - ETA: 1s - loss: 0.0414Epoch 55/100\n",
      "34/34 [==============================] - 5s 145ms/step - loss: 0.0400=====>............] - ETA: 2s - loss: 0.029ss: 0.0.............] - ETA: 3s - loss: 0.\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0293Epoch 6/50.........] - ETA: 2s - loss: 0.028\n",
      "34/34 [==============================] - 10s 157ms/step - loss: 0.4405\n",
      "17/34 [==============>...............] - ETA: 2s - loss: 0.0382Epoch 2/50\n",
      "34/34 [==============================] - 5s 160ms/step - loss: 0.0291======================>......] - ETA: 1s - loss: 0.009 - ETA: 2s - loss: 0.038\n",
      "115/134 [========================>.....] - ETA: 1s - loss: 0.0099Epoch 9/10\n",
      "34/34 [==============================] - 5s 158ms/step - loss: 0.0291\n",
      " 7/34 [=====>........................] - ETA: 3s - loss: 0.0359Epoch 9/10\n",
      "67/67 [==============================] - 7s 104ms/step - loss: 0.0131\n",
      "30/67 [============>.................] - ETA: 3s - loss: 0.0134Epoch 56/100\n",
      "67/67 [==============================] - 7s 105ms/step - loss: 0.0131.] - ETA: 0s - loss: 0.0>..] - ETA: 0s - loss: 0.01\n",
      "132/134 [============================>.] - ETA: 0s - loss: 0.0098Epoch 56/100\n",
      "34/34 [==============================] - 5s 151ms/step - loss: 0.0272\n",
      "134/134 [==============================] - 9s 65ms/step - loss: 0.0099\n",
      "109/134 [=======================>......] - ETA: 1s - loss: 0.0096Epoch 59/100\n",
      "43/67 [==================>...........] - ETA: 2s - loss: 0.0133Epoch 10/10\n",
      "34/34 [==============================] - 5s 147ms/step - loss: 0.0368\n",
      " 4/34 [==>...........................] - ETA: 5s - loss: 0.0262Epoch 7/50\n",
      "134/134 [==============================] - 8s 61ms/step - loss: 0.0097.................] - ETA: 4s - loss: 0.025............] - ETA: 4s - loss: 0.013\n",
      "11/34 [========>.....................] - ETA: 2s - loss: 0.0257Epoch 59/100\n",
      "67/67 [==============================] - 7s 97ms/step - loss: 0.0134ss: 0.009\n",
      "43/67 [==================>...........] - ETA: 2s - loss: 0.0131Epoch 56/100\n",
      "134/134 [==============================] - 8s 63ms/step - loss: 0.0100\n",
      "31/67 [============>.................] - ETA: 3s - loss: 0.0133Epoch 60/100\n",
      "34/34 [==============================] - 5s 155ms/step - loss: 0.0348.............] - ETA: 3s - loss: 0.013\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0272Epoch 7/50\n",
      "34/34 [==============================] - 5s 154ms/step - loss: 0.3995\n",
      " 2/34 [>.............................] - ETA: 4s - loss: 0.0334Epoch 3/50\n",
      "34/34 [==============================] - 5s 146ms/step - loss: 0.0272\n",
      " 59/134 [============>.................] - ETA: 4s - loss: 0.0095Epoch 10/10 2s - loss: 0.313\n",
      "34/34 [==============================] - 5s 149ms/step - loss: 0.0273\n",
      "14/67 [=====>........................] - ETA: 4s - loss: 0.0127Epoch 10/10\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0130 loss: 0.011......................] - ETA: 3s - loss: 0.0\n",
      "14/34 [===========>..................] - ETA: 3s - loss: 0.0316Epoch 57/100\n",
      "34/34 [==============================] - 5s 158ms/step - loss: 0.0257\n",
      "34/34 [==============================] - 5s 154ms/step - loss: 0.0332\n",
      "64/67 [===========================>..] - ETA: 0s - loss: 0.0130Epoch 8/50TA: 4s - loss: 0.010\n",
      "67/67 [==============================] - 7s 99ms/step - loss: 0.0130\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 5s 153ms/step - loss: 0.0313ETA: 5s - loss: 0.01s: 0.02\n",
      "34/34 [==============================] - 5s 149ms/step - loss: 0.1902\n",
      "17/17 [==============================] - 3s 73ms/step - loss: 0.0245\n",
      "Epoch 4/50\n",
      "17/34 [==============>...............] - ETA: 2s - loss: 0.0311Epoch 8/50\n",
      "34/34 [==============================] - 5s 148ms/step - loss: 0.0257\n",
      "134/134 [==============================] - 8s 63ms/step - loss: 0.0098\n",
      "33/67 [=============>................] - ETA: 3s - loss: 0.0129Epoch 60/100\n",
      "34/34 [==============================] - 5s 149ms/step - loss: 0.0259\n",
      "67/67 [==============================] - 7s 100ms/step - loss: 0.0133.....] - ETA: 3s - loss: 0.012 ETA: 2s - loss: 0.013\n",
      " 8/34 [======>.......................] - ETA: 3s - loss: 0.0297Epoch 57/100\n",
      "134/134 [==============================] - 8s 61ms/step - loss: 0.0097 ETA: 4s - loss: 0.01\n",
      "10/34 [=======>......................] - ETA: 1s - loss: 0.0241Epoch 60/100\n",
      "34/34 [==============================] - 2s 44ms/step - loss: 0.0250>.....] - ETA: 1s - loss: 0.010TA: 1s - loss: 0.0100.010\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0100..................] - ETA: 4s - loss: 0.010\n",
      "34/34 [==============================] - 5s 141ms/step - loss: 0.0304\n",
      " 27/134 [=====>........................] - ETA: 4s - loss: 0.0104Epoch 61/100\n",
      "  1/134 [..............................] - ETA: 8s - loss: 0.0109Epoch 9/50\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0129.012\n",
      " 7/17 [===========>..................] - ETA: 0s - loss: 0.0256Epoch 58/100\n",
      "17/17 [==============================] - 3s 55ms/step - loss: 0.0260\n",
      "67/67 [==============================] - 5s 80ms/step - loss: 0.0129\n",
      "17/17 [==============================] - 3s 70ms/step - loss: 0.0251\n",
      "34/67 [==============>...............] - ETA: 2s - loss: 0.0131Epoch 58/100\n",
      "34/34 [==============================] - 4s 127ms/step - loss: 0.0621\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0289Epoch 5/50\n",
      "34/34 [==============================] - 4s 133ms/step - loss: 0.0289\n",
      " 2/34 [>.............................] - ETA: 4s - loss: 0.0467Epoch 9/50 - loss: 0.024\n",
      "34/34 [==============================] - 2s 52ms/step - loss: 0.0252..................] - ETA: 1s - loss: 0.02........] - ETA: 3s - loss: 0.\n",
      "34/34 [==============================] - 2s 57ms/step - loss: 0.0251\n",
      "67/67 [==============================] - 5s 82ms/step - loss: 0.0132- ETA: 2s - loss: 0.0\n",
      "108/134 [=======================>......] - ETA: 1s - loss: 0.0097Epoch 58/100\n",
      "134/134 [==============================] - 6s 48ms/step - loss: 0.0097: 2s - loss: 0.009\n",
      " 91/134 [===================>..........] - ETA: 1s - loss: 0.0098Epoch 61/100\n",
      "34/34 [==============================] - 4s 134ms/step - loss: 0.0281 ETA: 1s - loss: 0.012\n",
      "102/134 [=====================>........] - ETA: 1s - loss: 0.0098Epoch 10/50\n",
      "134/134 [==============================] - 6s 47ms/step - loss: 0.0097.....] - ETA: 4s - loss: 0.013\n",
      "24/34 [====================>.........] - ETA: 1s - loss: 0.0424Epoch 61/100\n",
      "67/67 [==============================] - 5s 78ms/step - loss: 0.0129\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0271Epoch 59/100\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 0.0100.........] - ETA: 5s - loss: 0.009\n",
      " 18/134 [===>..........................] - ETA: 6s - loss: 0.0097Epoch 62/100\n",
      "67/67 [==============================] - 5s 76ms/step - loss: 0.0128\n",
      "10/67 [===>..........................] - ETA: 3s - loss: 0.0125Epoch 59/100\n",
      "34/34 [==============================] - 5s 132ms/step - loss: 0.0419\n",
      "34/34 [==============================] - 4s 128ms/step - loss: 0.0270\n",
      "Epoch 10/50\n",
      "12/67 [====>.........................] - ETA: 3s - loss: 0.0128Epoch 6/50\n",
      " 77/134 [================>.............] - ETA: 2s - loss: 0.0095Model: \"encoder\".............] - ETA: 3s - loss: 0.009ss: 0.0=>...........] - ETA: 1s - loss: 0.026\n",
      "49/67 [====================>.........] - ETA: 1s - loss: 0.0130__________________________________________________________\n",
      " 59/134 [============>.................] - ETA: 3s - loss: 0.0096           Param #   \n",
      "=================================================================\n",
      " Input Layer (InputLayer)    [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 13, 13, 32)        896       \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 20)                46100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,492\n",
      "Trainable params: 65,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1568)              32928     \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_6 (Conv2DT  (None, 14, 14, 64)       18496     \n",
      " ranspose)                                                       \n",
      " 60/134 [============>.................] - ETA: 3s - loss: 0.0096                \n",
      " conv2d_transpose_7 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_8 (Conv2DT  (None, 28, 28, 3)        867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      " 79/134 [================>.............] - ETA: 2s - loss: 0.0095ams: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "34/34 [==============================] - 4s 127ms/step - loss: 0.0264..............] - ETA: 2s - loss: 0.00\n",
      "67/67 [==============================] - 5s 75ms/step - loss: 0.0131[=============>................] - ETA: 3s - loss: 0.009\n",
      " 64/134 [=============>................] - ETA: 3s - loss: 0.0099Epoch 59/100\n",
      " 1/67 [..............................] - ETA: 1s - loss: 0.0125Epoch 11/50\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.0097\"encoder\"======>...............] - ETA: 2s - loss: 0.009: 4s - loss: 0.01================>.....] - ETA: 0s - loss: 0.012===============>..] - ETA: 0s - loss: 0.036\n",
      "_________________________________________________________________\n",
      "109/134 [=======================>......] - ETA: 1s - loss: 0.0097tput Shape              Param #   \n",
      "62/67 [==========================>...] - ETA: 0s - loss: 0.0128=\n",
      " Input Layer (InputLayer)    [(None, 28, 28, 3)]       0         \n",
      "24/34 [====================>.........] - ETA: 1s - loss: 0.4409Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input Layer (InputLayer)    [(None, 28, 28, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 13, 13, 32)        896       \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      "49/67 [====================>.........] - ETA: 1s - loss: 0.0129nse_4 (Dense)             (None, 20)                46100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,492\n",
      "Trainable params: 65,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1568)              32928     \n",
      "                                                                 \n",
      "21/67 [========>.....................] - ETA: 3s - loss: 0.0134  \n",
      "                                                                 \n",
      " conv2d_transpose_6 (Conv2DT  (None, 14, 14, 64)       18496     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_7 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_8 (Conv2DT  (None, 28, 28, 3)        867       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      " 94/134 [====================>.........] - ETA: 1s - loss: 0.0098                              \n",
      "34/34 [==============================] - 4s 125ms/step - loss: 0.0360\n",
      "onv2d_4 (Conv2D)           (None, 13, 13, 32)        896       \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 20)                46100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,492\n",
      "Trainable params: 65,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "110/134 [=======================>......] - ETA: 1s - loss: 0.0097oder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1568)              32928     \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_6 (Conv2DT  (None, 14, 14, 64)       18496     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_7 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0255Epoch 7/50\n",
      "51/67 [=====================>........] - ETA: 1s - loss: 0.0129pose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_8 (Conv2DT  (None, 28, 28, 3)        867       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 0.0096====>.....] - ETA: 0s - loss: 0.009\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 5s 137ms/step - loss: 0.0254\n",
      "54/67 [=======================>......] - ETA: 1s - loss: 0.0128Epoch 11/50\n",
      "67/67 [==============================] - 5s 81ms/step - loss: 0.0128\n",
      "102/134 [=====================>........] - ETA: 1s - loss: 0.0099Epoch 60/100...................] - ETA: 5s - loss: 0.034\n",
      "34/34 [==============================] - 8s 128ms/step - loss: 0.4401....................] - ETA: 4s - loss: 0.033\n",
      "10/34 [=======>......................] - ETA: 4s - loss: 0.4466Epoch 2/100\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 0.0096\n",
      "115/134 [========================>.....] - ETA: 1s - loss: 0.0100Epoch 62/100\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0127\n",
      " 9/34 [======>.......................] - ETA: 4s - loss: 0.0250Epoch 60/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0099: 0.\n",
      " 9/67 [===>..........................] - ETA: 6s - loss: 0.0131Epoch 63/100\n",
      "34/34 [==============================] - 5s 134ms/step - loss: 0.0251\n",
      " 26/134 [====>.........................] - ETA: 6s - loss: 0.0095Epoch 12/50\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0130...] - ETA: 1s - loss: 0=======>...............] - ETA: 3s - loss: 0.012ETA: 0s - loss: 0.436\n",
      "34/34 [==============================] - 9s 149ms/step - loss: 0.4360\n",
      " 53/134 [==========>...................] - ETA: 4s - loss: 0.0095Epoch 60/100\n",
      "42/67 [=================>............] - ETA: 2s - loss: 0.0127Epoch 2/100\n",
      "34/34 [==============================] - 10s 165ms/step - loss: 0.4399\n",
      "34/34 [==============================] - 5s 154ms/step - loss: 0.0326\n",
      " 74/134 [===============>..............] - ETA: 4s - loss: 0.0095Epoch 2/100\n",
      " 41/134 [========>.....................] - ETA: 6s - loss: 0.0099Epoch 8/50\n",
      "34/34 [==============================] - 5s 154ms/step - loss: 0.0243loss: 0.009\n",
      "49/67 [====================>.........] - ETA: 1s - loss: 0.0126Epoch 12/50\n",
      "34/34 [==============================] - 5s 155ms/step - loss: 0.3854.....] - ETA: 3s - loss: 0.009.012\n",
      " 81/134 [=================>............] - ETA: 3s - loss: 0.0095Epoch 3/100\n",
      "67/67 [==============================] - 7s 105ms/step - loss: 0.01279\n",
      " 97/134 [====================>.........] - ETA: 2s - loss: 0.0096Epoch 61/100\n",
      "34/34 [==============================] - 5s 149ms/step - loss: 0.0240\n",
      " 88/134 [==================>...........] - ETA: 2s - loss: 0.0098Epoch 13/50\n",
      "67/67 [==============================] - 7s 106ms/step - loss: 0.0126========>..........] - ETA: 1s - loss: 0.030\n",
      "14/67 [=====>........................] - ETA: 5s - loss: 0.0127Epoch 61/100\n",
      "134/134 [==============================] - 9s 64ms/step - loss: 0.0096\n",
      "102/134 [=====================>........] - ETA: 2s - loss: 0.0098Epoch 63/100\n",
      "34/34 [==============================] - 5s 152ms/step - loss: 0.4109] - ETA: 0s - loss: 0.0[========================>.....] - ETA: 0s - loss: 0.030\n",
      "134/134 [==============================] - 8s 63ms/step - loss: 0.0096\n",
      "51/67 [=====================>........] - ETA: 1s - loss: 0.0129Epoch 3/100\n",
      "25/34 [=====================>........] - ETA: 1s - loss: 0.1866Epoch 63/100\n",
      "34/34 [==============================] - 5s 147ms/step - loss: 0.3886\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0234Epoch 3/100\n",
      "34/34 [==============================] - 5s 155ms/step - loss: 0.0300\n",
      " 28/134 [=====>........................] - ETA: 6s - loss: 0.0095Epoch 9/50\n",
      "34/34 [==============================] - 5s 152ms/step - loss: 0.0233\n",
      "33/67 [=============>................] - ETA: 3s - loss: 0.0126Epoch 13/50\n",
      "134/134 [==============================] - 8s 62ms/step - loss: 0.0099\n",
      "26/67 [==========>...................] - ETA: 3s - loss: 0.0127Epoch 64/100\n",
      "34/34 [==============================] - 5s 146ms/step - loss: 0.1628........] - ETA: 1s - loss: 0.023\n",
      "10/34 [=======>......................] - ETA: 3s - loss: 0.2557Epoch 4/100\n",
      "67/67 [==============================] - 7s 102ms/step - loss: 0.0129\n",
      " 46/134 [=========>....................] - ETA: 5s - loss: 0.0092Epoch 61/100\n",
      "34/34 [==============================] - 5s 148ms/step - loss: 0.0232s: 0.0080.\n",
      " 60/134 [============>.................] - ETA: 4s - loss: 0.0095Epoch 14/50\n",
      "67/67 [==============================] - 7s 99ms/step - loss: 0.0127===>......................] - ETA: 4s - loss: 0.012.01\n",
      "23/34 [===================>..........] - ETA: 1s - loss: 0.0229Epoch 62/100\n",
      "67/67 [==============================] - 6s 95ms/stloss: 0.15509loss: 0.1.............] - ETA: 3s - loss: 0.011ep - loss: 0.0125\n",
      " 87/134 [==================>...........] - ETA: 2s - loss: 0.0093Epoch 62/100\n",
      "34/34 [==============================] - 5s 149ms/step - loss: 0.1543\n",
      "34/34 [==============================] - 5s 159ms/step - loss: 0.2314\n",
      " 91/134 [===================>..........] - ETA: 2s - loss: 0.0092Epoch 4/100\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0227Epoch 4/100...] - ETA: 5s - loss: 0.012\n",
      "34/34 [==============================] - 5s 153ms/step - loss: 0.0281\n",
      "15/67 [=====>........................] - ETA: 5s - loss: 0.0126Epoch 10/50\n",
      "34/34 [==============================] - 5s 147ms/step - loss: 0.0226\n",
      "45/67 [===================>..........] - ETA: 2s - loss: 0.0126Epoch 14/50\n",
      "34/34 [==============================] - 5s 153ms/step - loss: 0.0604loss: 0.061\n",
      "12/34 [=========>....................] - ETA: 2s - loss: 0.0977Epoch 5/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 0.0095\n",
      "21/67 [========>.....................] - ETA: 4s - loss: 0.0127Epoch 64/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 0.0096\n",
      " 19/134 [===>..........................] - ETA: 6s - loss: 0.0092Epoch 64/100\n",
      "67/67 [==============================] - 6s 98ms/step - loss: 0.0128\n",
      "18/34 [==============>...............] - ETA: 2s - loss: 0.0268Epoch 62/100\n",
      "34/34 [==============================] - 5s 149ms/step - loss: 0.0225\n",
      "22/34 [==================>...........] - ETA: 1s - loss: 0.0859Epoch 15/50\n",
      "134/134 [==============================] - 9s 66ms/step - loss: 0.0098=>...............] - ETA: 2s - loss: 0......................] - ETA: 3s - loss: 0.021..] - ETA: 0s - loss: 0.026\n",
      " 53/134 [==========>...................] - ETA: 4s - loss: 0.0100Epoch 65/100\n",
      "34/34 [==============================] - 5s 150ms/step - loss: 0.05436\n",
      "34/34 [==============================] - 5s 151ms/step - loss: 0.0762\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0220Epoch 5/100\n",
      " 1/34 [..............................] - ETA: 4s - loss: 0.0429Epoch 5/100\n",
      "34/34 [==============================] - 5s 143ms/step - loss: 0.0264\n",
      " 60/134 [============>.................] - ETA: 4s - loss: 0.0099Epoch 11/50\n",
      "67/67 [==============================] - 7s 100ms/step - loss: 0.0126ss: 0.012\n",
      " 14/134 [==>...........................] - ETA: 7s - loss: 0.0095Epoch 63/100\n",
      "34/34 [==============================] - 5s 153ms/step - loss: 0.0220===================>.] - ETA: 0s - loss: 0.022\n",
      "30/67 [============>.................] - ETA: 3s - loss: 0.0128Epoch 15/50\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0124\n",
      " 21/134 [===>..........................] - ETA: 7s - loss: 0.0099Epoch 63/100ETA: 5s - loss: 0.021\n",
      "34/34 [==============================] - 5s 149ms/step - loss: 0.0423\n",
      "36/67 [===============>..............] - ETA: 3s - loss: 0.0126Epoch 6/100\n",
      "34/34 [==============================] - 5s 161ms/step - loss: 0.0219........] - ETA: 4s - loss: 0.025ss: 0.0===============>.........] - ETA: 2s - loss: 0.009: 0.05\n",
      "56/67 [========================>.....] - ETA: 1s - loss: 0.0126Epoch 16/50\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0095\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0127Epoch 65/100\n",
      "67/67 [==============================] - 7s 101ms/step - loss: 0.0127.......] - ETA: 2s - loss: 0.036\n",
      " 77/134 [================>.............] - ETA: 3s - loss: 0.0100Epoch 63/100\n",
      "34/34 [==============================] - 5s 148ms/step - loss: 0.0251==================>..] - ETA: 0s - loss: 0.041\n",
      "34/34 [==============================] - 5s 152ms/step - loss: 0.0432\n",
      "43/67 [==================>...........] - ETA: 2s - loss: 0.0120Epoch 6/100\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.0095Epoch 12/50\n",
      "34/34 [==============================] - 5s 159ms/step - loss: 0.0416.......] - ETA: 4s - loss: 0.036\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0213Epoch 6/100\n",
      "134/134 [==============================] - 8s 61ms/step - loss: 0.0095\n",
      " 22/134 [===>..........................] - ETA: 6s - loss: 0.0094Epoch 65/100\n",
      "34/34 [==============================] - 5s 162ms/step - loss: 0.0216====================>...] - ETA: 0s - loss: 0.035\n",
      "52/67 [======================>.......] - ETA: 1s - loss: 0.0120Epoch 16/50\n",
      "34/34 [==============================] - 5s 158ms/step - loss: 0.0356=>......] - ETA: 1s - loss: 0.011\n",
      " 9/34 [======>.......................] - ETA: 4s - loss: 0.0387Epoch 7/100\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0125\n",
      "15/34 [============>.................] - ETA: 2s - loss: 0.0237Epoch 64/100\n",
      "67/67 [==============================] - 7s 102ms/step - loss: 0.0122 0.00==>...............] - ETA: 2s - loss: 0.035\n",
      " 8/34 [======>.......................] - ETA: 3s - loss: 0.0327Epoch 64/100\n",
      "134/134 [==============================] - 8s 63ms/step - loss: 0.0098\n",
      "40/67 [================>.............] - ETA: 2s - loss: 0.0126Epoch 66/100\n",
      "34/34 [==============================] - 5s 153ms/step - loss: 0.0214 0.01\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 5s 134ms/step - loss: 0.0241.......] - ETA: 1s - loss: 0.037\n",
      " 89/134 [==================>...........] - ETA: 2s - loss: 0.0095Epoch 13/50\n",
      "34/34 [==============================] - 5s 143ms/step - loss: 0.0352\n",
      "21/34 [=================>............] - ETA: 2s - loss: 0.0321Epoch 7/100\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0125\n",
      " 86/134 [==================>...........] - ETA: 2s - loss: 0.0095Epoch 64/1004s - loss: 0.010\n",
      "34/34 [==============================] - 5s 161ms/step - loss: 0.0367\n",
      " 90/134 [===================>..........] - ETA: 2s - loss: 0.0095Epoch 7/100\n",
      "34/34 [==============================] - 5s 156ms/step - loss: 0.0212\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0318Epoch 17/50\n",
      "34/34 [==============================] - 5s 156ms/step - loss: 0.0315 loss: 0.009\n",
      "56/67 [========================>.....] - ETA: 1s - loss: 0.0126Epoch 8/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 0.0094 loss: 0.021\n",
      "Epoch 66/100\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0124- loss: 0.0\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 0.0095.] - ETA: 1s - loss: 0.012\n",
      "Epoch 65/100\n",
      "29/67 [===========>..................] - ETA: 3s - loss: 0.0126Epoch 66/100\n",
      "34/34 [==============================] - 5s 155ms/step - loss: 0.0210 1s - loss: 0.023\n",
      "34/67 [==============>...............] - ETA: 3s - loss: 0.0124Epoch 18/50\n",
      "67/67 [==============================] - 7s 101ms/step - loss: 0.0121- ETA: 0s - loss: 0.012 5s - loss: 0.009\n",
      "13/67 [====>.........................] - ETA: 5s - loss: 0.0122Epoch 65/100\n",
      "34/34 [==============================] - 5s 161ms/step - loss: 0.0232==>..............] - ETA: 2s - loss: 0.028\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0098\n",
      " 34/134 [======>.......................] - ETA: 5s - loss: 0.0096Epoch 67/100\n",
      "  1/134 [..............................] - ETA: 2s - loss: 0.0061Epoch 14/50\n",
      "34/34 [==============================] - 5s 159ms/step - loss: 0.0310.....] - ETA: 3s - loss: 0.021\n",
      "27/34 [======================>.......] - ETA: 1s - loss: 0.0207Epoch 8/100\n",
      "34/34 [==============================] - 5s 154ms/step - loss: 0.0334=======>........] - ETA: 1s - loss: 0.028\n",
      " 62/134 [============>.................] - ETA: 4s - loss: 0.0089Epoch 8/100\n",
      "34/34 [==============================] - 5s 146ms/step - loss: 0.0209\n",
      " 17/134 [==>...........................] - ETA: 9s - loss: 0.0104Epoch 18/50\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0124A: 0s - loss: 0.0\n",
      "26/67 [==========>...................] - ETA: 4s - loss: 0.0115Epoch 65/100\n",
      "34/34 [==============================] - 5s 148ms/step - loss: 0.02861\n",
      " 80/134 [================>.............] - ETA: 3s - loss: 0.0090Epoch 9/100\n",
      "34/34 [==============================] - 5s 157ms/step - loss: 0.0207....................] - ETA: 5s - loss: 0.010..........] - ETA: 2s - loss: 0.011s: 0.012\n",
      "49/67 [====================>.........] - ETA: 1s - loss: 0.0119Epoch 19/50\n",
      "67/67 [==============================] - 7s 103ms/step - loss: 0.0123====================>......] - ETA: 0s - loss: 0.\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0094\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.0119Epoch 67/100\n",
      "  1/134 [..............................] - ETA: 2s - loss: 0.0101Epoch 66/100\n",
      "34/34 [==============================] - 5s 151ms/step - loss: 0.0226\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0312Epoch 15/50\n",
      "34/34 [==============================] - 5s 153ms/step - loss: 0.0283s - loss: 0.026\n",
      "26/34 [=====================>........] - ETA: 1s - loss: 0.0206Epoch 9/100\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0119\n",
      " 14/134 [==>...........................] - ETA: 6s - loss: 0.0089Epoch 66/100.............] - ETA: 5s - loss: 0.008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0095\n",
      " 19/134 [===>..........................] - ETA: 7s - loss: 0.0098Epoch 67/100\n",
      "34/34 [==============================] - 5s 158ms/step - loss: 0.0308\n",
      "107/134 [======================>.......] - ETA: 1s - loss: 0.0098Epoch 9/100\n",
      "34/34 [==============================] - 5s 156ms/step - loss: 0.0206\n",
      "111/134 [=======================>......] - ETA: 1s - loss: 0.0097Epoch 19/50\n",
      "34/34 [==============================] - 5s 159ms/step - loss: 0.0266.0\n",
      " 6/34 [====>.........................] - ETA: 3s - loss: 0.0213Epoch 10/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0098\n",
      " 5/34 [===>..........................] - ETA: 4s - loss: 0.0249Epoch 68/100\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0122\n",
      " 6/34 [====>.........................] - ETA: 4s - loss: 0.0248Epoch 66/100\n",
      "34/34 [==============================] - 5s 156ms/step - loss: 0.0204......................] - ETA: 5s - loss: 0.00] - ETA: 3s - loss: 0.0\n",
      "26/34 [=====================>........] - ETA: 1s - loss: 0.0222Epoch 20/50\n",
      "34/34 [==============================] - 5s 158ms/step - loss: 0.0220\n",
      " 77/134 [================>.............] - ETA: 3s - loss: 0.0097Epoch 16/50: 0s - loss: 0.028\n",
      "34/34 [==============================] - 5s 158ms/step - loss: 0.0263\n",
      " 53/134 [==========>...................] - ETA: 4s - loss: 0.0095Epoch 10/100\n",
      "34/34 [==============================] - 5s 142ms/step - loss: 0.0288\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0122\n",
      "Epoch 67/100\n",
      " 6/34 [====>.........................] - ETA: 4s - loss: 0.0230Epoch 10/100\n",
      "34/34 [==============================] - 5s 157ms/step - loss: 0.0204=======================>.....] - ETA: 0s - loss: 0.025 loss: 0.026\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0117\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.0093Epoch 20/50\n",
      "19/34 [===============>..............] - ETA: 2s - loss: 0.0201Epoch 67/100\n",
      "34/34 [==============================] - 5s 149ms/step - loss: 0.0250loss: 0.026\n",
      "13/34 [==========>...................] - ETA: 3s - loss: 0.0221Epoch 11/100\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 0.0093====>...........] - ETA: 1s - loss: 0.020\n",
      " 78/134 [================>.............] - ETA: 3s - loss: 0.0096Epoch 68/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0095oss: 0.02=>..........] - ETA: 1s - loss: 0.021\n",
      "21/34 [=================>............] - ETA: 2s - loss: 0.0255Epoch 68/100\n",
      "34/34 [==============================] - 5s 159ms/step - loss: 0.0202\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0120\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0217Epoch 67/100\n",
      " 1/67 [..............................] - ETA: 3s - loss: 0.0111Epoch 21/50\n",
      "34/34 [==============================] - 5s 142ms/step - loss: 0.0216ETA: 6s - loss: 0.009loss: 0.011\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0097\n",
      "45/67 [===================>..........] - ETA: 2s - loss: 0.0121Epoch 69/100\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0273Epoch 17/50\n",
      "34/34 [==============================] - 5s 152ms/step - loss: 0.0248\n",
      " 3/34 [=>............................] - ETA: 3s - loss: 0.0212Epoch 11/100\n",
      "34/34 [==============================] - 5s 151ms/step - loss: 0.0272\n",
      " 4/34 [==>...........................] - ETA: 4s - loss: 0.0255Epoch 11/100\n",
      "34/34 [==============================] - 5s 152ms/step - loss: 0.0202- ETA: 3s - loss: 0.01\n",
      "32/67 [=============>................] - ETA: 3s - loss: 0.0120Epoch 21/50\n",
      "34/34 [==============================] - 5s 152ms/step - loss: 0.0239.................] - ETA: 3s - loss: 0.024\n",
      "67/67 [==============================] - 6s 98ms/step - loss: 0.0121\n",
      " 91/134 [===================>..........] - ETA: 2s - loss: 0.0092Epoch 12/100\n",
      "21/34 [=================>............] - ETA: 2s - loss: 0.0193Epoch 68/100\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0116s - loss: 0.026\n",
      "13/34 [==========>...................] - ETA: 3s - loss: 0.0264Epoch 68/100\n",
      "34/34 [==============================] - 5s 161ms/step - loss: 0.0200============>........] - ETA: 1s - loss: 0.019s: 0.00....] - ETA: 4s - loss: 0.011 - loss: 0.010\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.0121Epoch 22/50\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0093\n",
      "26/67 [==========>...................] - ETA: 4s - loss: 0.0115Epoch 69/100 - loss: 0.021\n",
      "34/34 [==============================] - 5s 151ms/step - loss: 0.0212s: 0.019\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0119\n",
      "24/34 [====================>.........] - ETA: 1s - loss: 0.0202Epoch 68/100\n",
      " 1/67 [..............................] - ETA: 6s - loss: 0.0099Epoch 18/50\n",
      "34/34 [==============================] - 5s 152ms/step - loss: 0.0237\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.0094Epoch 12/100A: 2s - loss: 0.009\n",
      "34/34 [==============================] - 5s 160ms/step - loss: 0.0259................] - ETA: 3s - loss: 0.02\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0094\n",
      "42/67 [=================>............] - ETA: 2s - loss: 0.0120Epoch 12/100\n",
      "10/67 [===>..........................] - ETA: 5s - loss: 0.0113Epoch 69/100\n",
      "34/34 [==============================] - 5s 145ms/step - loss: 0.0230======================>.......] - ETA: 1s - loss: 0.00 - ETA: 6s - loss: 0.009\n",
      "34/34 [==============================] - 5s 157ms/step - loss: 0.0200\n",
      "116/134 [========================>.....] - ETA: 1s - loss: 0.0096Epoch 22/50\n",
      " 6/34 [====>.........................] - ETA: 4s - loss: 0.0247Epoch 13/100\n",
      "134/134 [==============================] - 8s 61ms/step - loss: 0.0097================>..........] - ETA: 2s - loss: 0.01..................] - ETA: 5s - loss: 0.024\n",
      "Epoch 70/100\n",
      "67/67 [==============================] - 6s 98ms/step - loss: 0.0120.....] - ETA: 1s - loss: 0.021\n",
      "57/67 [========================>.....] - ETA: 1s - loss: 0.0115Epoch 69/100\n",
      "34/34 [==============================] - 5s 145ms/step - loss: 0.0198=>...................] - ETA: 4s - loss: 0.009\n",
      "21/34 [=================>............] - ETA: 2s - loss: 0.01209..........] - ETA: 1s - loss: 0.0250Epoch 23/50\n",
      "67/67 [==============================] - 7s 102ms/step - loss: 0.0114\n",
      "45/67 [===================>..........] - ETA: 2s - loss: 0.0119Epoch 69/100\n",
      "34/34 [==============================] - 5s 150ms/step - loss: 0.0209\n",
      "34/34 [==============================] - 5s 142ms/step - loss: 0.0229] - ETA: 6s - loss: 0.012\n",
      " 8/34 [======>.......................] - ETA: 4s - loss: 0.0194Epoch 19/50\n",
      " 8/67 [==>...........................] - ETA: 6s - loss: 0.0124Epoch 13/100\n",
      "34/34 [==============================] - 5s 153ms/step - loss: 0.0247\n",
      " 93/134 [===================>..........] - ETA: 2s - loss: 0.0093Epoch 13/100\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0117loss: 0.020\n",
      "112/134 [========================>.....] - ETA: 1s - loss: 0.0093Epoch 69/100\n",
      "34/34 [==============================] - 5s 153ms/step - loss: 0.0198\n",
      " 64/134 [=============>................] - ETA: 4s - loss: 0.0094Epoch 23/50\n",
      "34/34 [==============================] - 5s 159ms/step - loss: 0.0223\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.0092Epoch 14/100\n",
      "134/134 [==============================] - 9s 67ms/step - loss: 0.0093 - loss: 0.02==================>.....] - ETA: 1s - loss: 0.\n",
      "126/134 [===========================>..] - ETA: 0s - loss: 0.0093Epoch 70/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0094 0s - loss: 0.0\n",
      "15/34 [============>.................] - ETA: 2s - loss: 0.0222Epoch 70/100TA: 4s - loss: 0.011\n",
      "34/34 [==============================] - 5s 152ms/step - loss: 0.0196\n",
      "16/34 [=============>................] - ETA: 2s - loss: 0.0220Epoch 24/50\n",
      "67/67 [==============================] - 6s 92ms/step - loss: 0.0118.............] - ETA: 7s - loss: 0.008\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0224Epoch 70/100\n",
      "34/34 [==============================] - 5s 156ms/step - loss: 0.0206...] - ETA: 2s - loss: 0.0\n",
      "34/34 [==============================] - 5s 156ms/step - loss: 0.0222\n",
      "10/67 [===>..........................] - ETA: 6s - loss: 0.0120Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/34 [====================>.........] - ETA: 1s - loss: 0.0201Epoch 20/50\n",
      "34/34 [==============================] - 5s 145ms/step - loss: 0.0238......] - ETA: 1s - loss: 0.020\n",
      "134/134 [==============================] - 8s 63ms/step - loss: 0.0097\n",
      " 5/34 [===>..........................] - ETA: 5s - loss: 0.022215Epoch 14/100\n",
      " 37/134 [=======>......................] - ETA: 5s - loss: 0.0096Epoch 71/100\n",
      "67/67 [==============================] - 7s 103ms/step - loss: 0.0113\n",
      "  2/134 [..............................] - ETA: 19s - loss: 0.0124Epoch 70/100\n",
      "34/34 [==============================] - 5s 149ms/step - loss: 0.0218========================>...] - ETA: 0s - loss: 0.019\n",
      " 17/134 [==>...........................] - ETA: 7s - loss: 0.0096Epoch 15/100\n",
      "34/34 [==============================] - 5s 162ms/step - loss: 0.0197===========>.....] - ETA: 0s - loss: 0.011\n",
      " 63/134 [=============>................] - ETA: 4s - loss: 0.0092Epoch 24/50\n",
      "67/67 [==============================] - 7s 100ms/step - loss: 0.0115..............] - ETA: 4s - loss: 0.009] - ETA: 2s - loss: 0.022\n",
      " 69/134 [==============>...............] - ETA: 4s - loss: 0.0094Epoch 70/100\n",
      "34/34 [==============================] - 5s 160ms/step - loss: 0.0195======>.....................] - ETA: 4s - loss: 0.011loss: 0.0=>.................] - ETA: 2s - loss: 0.02\n",
      " 90/134 [===================>..........] - ETA: 2s - loss: 0.0094Epoch 25/50\n",
      "34/34 [==============================] - 5s 153ms/step - loss: 0.0217 - ETA: 4s - loss: 0.============>.....] - ETA: 1s - loss: 0.009\n",
      "34/34 [==============================] - 5s 157ms/step - loss: 0.0203\n",
      "27/34 [======================>.......] - ETA: 1s - loss: 0.0233Epoch 21/50\n",
      "25/34 [=====================>........] - ETA: 1s - loss: 0.0217Epoch 15/100\n",
      "67/67 [==============================] - 7s 99ms/step - loss: 0.0117\n",
      "119/134 [=========================>....] - ETA: 0s - loss: 0.0093Epoch 71/100\n",
      "134/134 [==============================] - 8s 63ms/step - loss: 0.0092===>..] - ETA: 0s - loss: 0.023 ETA: 0s - loss: 0.023\n",
      "34/34 [==============================] - 6s 166ms/step - loss: 0.0230\n",
      "Epoch 71/100\n",
      "37/67 [===============>..............] - ETA: 2s - loss: 0.0117Epoch 15/100\n",
      "134/134 [==============================] - 8s 6 2s - loss: 0.0070ms/step - loss: 0.0094\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0196Epoch 71/100\n",
      "34/34 [==============================] - 5s 150ms/step - loss: 0.0196\n",
      " 10/134 [=>............................] - ETA: 7s - loss: 0.0085Epoch 25/50\n",
      "34/34 [==============================] - 5s 159ms/step - loss: 0.0214\n",
      "45/67 [===================>..........] - ETA: 3s - loss: 0.02209.....] - ETA: 2s - loss: 0.0116Epoch 16/100\n",
      "67/67 [==============================] - 7s 98ms/step - loss: 0.0112=====>.........] - ETA: 1s - loss: 0.011\n",
      "24/34 [====================>.........] - ETA: 1s - loss: 0.0194Epoch 71/100\n",
      "134/134 [==============================] - 8s 63ms/step - loss: 0.0096 ETA: 3s - loss: 0.0110.0\n",
      " 40/134 [=======>......................] - ETA: 6s - loss: 0.0091Epoch 72/100\n",
      "67/67 [==============================] - 6s 97ms/step - loss: 0.0114\n",
      "15/34 [============>.................] - ETA: 2s - loss: 0.0213Epoch 71/100\n",
      "34/34 [==============================] - 5s 158ms/step - loss: 0.0194\n",
      "17/34 [==============>...............] - ETA: 2s - loss: 0.0184Epoch 26/50\n",
      "34/34 [==============================] - 5s 151ms/step - loss: 0.0201=========================>....] - ETA: 0s - loss: 0.021ss: 0.0\n",
      "34/34 [==============================] - 5s 149ms/step - loss: 0.0212\n",
      "13/67 [====>.........................] - ETA: 5s - loss: 0.0113Epoch 16/100\n",
      "55/67 [=======================>......] - ETA: 1s - loss: 0.0115Epoch 22/50\n",
      "34/34 [==============================] - 5s 157ms/step - loss: 0.02234 [==============>...............] - ETA: 4s - loss: 0.009.01\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0115Epoch 16/100\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0115\n",
      "10/34 [=======>......................] - ETA: 3s - loss: 0.0209Epoch 72/100\n",
      "34/34 [==============================] - 5s 150ms/step - loss: 0.0210.............] - ETA: 3s - loss: 0.009\n",
      " 95/134 [====================>.........] - ETA: 2s - loss: 0.0093Epoch 17/100\n",
      "34/34 [==============================] - 5s 162ms/step - loss: 0.0195\n",
      "12/34 [=========>....................] - ETA: 3s - loss: 0.0213Epoch 26/50\n",
      "67/67 [==============================] - 6s 94ms/step - loss: 0.0110: 4s - loss: 0.01=============>....] - ETA: 0s - loss: 0.0\n",
      " 89/134 [==================>...........] - ETA: 2s - loss: 0.0096Epoch 72/100\n",
      "34/34 [==============================] - 5s 148ms/step - loss: 0.0193- loss: 0.01\n",
      "58/67 [========================>.....] - ETA: 0s - loss: 0.0114Epoch 27/50\n",
      "134/134 [==============================] - 8s 62ms/step - loss: 0.0092\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.0113Epoch 72/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 0.0093\n",
      "19/34 [===============>..............] - ETA: 2s - loss: 0.0203Epoch 72/100 0.022\n",
      "34/34 [==============================] - 5s 136ms/step - loss: 0.0200\n",
      "24/34 [====================>.........] - ETA: 1s - loss: 0.0216Epoch 23/50\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0113\n",
      "34/34 [==============================] - 5s 155ms/step - loss: 0.0209\n",
      "40/67 [================>.............] - ETA: 2s - loss: 0.0115Epoch 72/100\n",
      "27/34 [======================>.......] - ETA: 1s - loss: 0.0217Epoch 17/100\n",
      "34/34 [==============================] - 5s 152ms/step - loss: 0.0217................] - ETA: 3s - loss: 0.01\n",
      " 8/34 [======>.......................] - ETA: 4s - loss: 0.0207Epoch 17/100\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.0096\n",
      " 34/134 [======>.......................] - ETA: 6s - loss: 0.0093Epoch 73/100\n",
      "34/34 [==============================] - 5s 150ms/step - loss: 0.0207\n",
      " 41/134 [========>.....................] - ETA: 6s - loss: 0.0098Epoch 18/100\n",
      "34/34 [==============================] - 5s 157ms/step - loss: 0.0194s - loss: 0.009\n",
      " 47/134 [=========>....................] - ETA: 6s - loss: 0.0098Epoch 27/50\n",
      "67/67 [==============================] - 7s 102ms/step - loss: 0.0113 loss: 0.0oss: 0.009\n",
      " 61/134 [============>.................] - ETA: 4s - loss: 0.0095Epoch 73/100\n",
      "34/34 [==============================] - 5s 148ms/step - loss: 0.0192\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 5s 155ms/step - loss: 0.0198 - loss: 0.0======================>..] - ETA: 0s - loss: 0.019\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0109\n",
      "48/67 [=======.......................] - ETA: 5s - loss: 0.011=============>.........] - ETA: 1s - loss: 0.0113Epoch 24/50\n",
      " 2/34 [>.............................] - ETA: 3s - loss: 0.0221Epoch 73/100\n",
      "34/34 [==============================] - 5s 156ms/step - loss: 0.0206TA: 8s - loss: 0.010\n",
      " 6/67 [=>............................] - ETA: 5s - loss: 0.0106Epoch 18/100\n",
      "34/34 [==============================] - 5s 144ms/step - loss: 0.020400....] - ETA: 1s - loss: 0.0\n",
      "12/34 [=========>....................] - ETA: 3s - loss: 0.0197Epoch 19/100\n",
      "34/34 [==============================] - 5s 164ms/step - loss: 0.0213=========>.] - ETA: 0s - loss: 0.021\n",
      " 3/34 [=>............................] - ETA: 2s - loss: 0.0215Epoch 18/100\n",
      "67/67 [==============================] - 7s 103ms/step - loss: 0.0112\n",
      "21/67 [========>.....................] - ETA: 4s - loss: 0.0108Epoch 73/100\n",
      "134/134 [==============================] - 8s 61ms/step - loss: 0.0092\n",
      "Epoch 73/100\n",
      "134/134 [==============================] - 8s 62ms/step - loss: 0.0093\n",
      "34/34 [==============================] - 5s 164ms/step - loss: 0.0193\n",
      "47/67 [====================>.........] - ETA: 1s - loss: 0.0111Epoch 73/100\n",
      "17/34 [==============>...............] - ETA: 2s - loss: 0.0207Epoch 28/50\n",
      "34/34 [==============================] - 5s 155ms/step - loss: 0.0191.............] - ETA: 6s - loss: 0.....] - ETA: 7s - loss: 0.009\n",
      "10/34 [=======>......................] - ETA: 3s - loss: 0.0200Epoch 29/50......] - ETA: 2s - loss: 0.019\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0096\n",
      "11/34 [========>.....................] - ETA: 3s - loss: 0.0199Epoch 74/100\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0112\n",
      "50/67 [=====================>........] - ETA: 1s - loss: 0.0107Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 5s 158ms/step - loss: 0.0197TA: 2s - loss: 0.021\n",
      " 49/134 [=========>....................] - ETA: 5s - loss: 0.0094Epoch 25/50\n",
      "34/34 [==============================] - 5s 150ms/step - loss: 0.0204...] - ETA: 5s - loss: 0.010\n",
      "19/34 [===============>..............] - ETA: 2s - loss: 0.0198Epoch 19/100\n",
      "67/67 [==============================] - 7s 98ms/step - loss: 0.0108 2s - loss: 0.\n",
      "16/34 [=============>................] - ETA: 2s - loss: 0.0185Epoch 74/100\n",
      "34/34 [==============================] - 5s 147ms/step - loss: 0.0202\n",
      "17/34 [==============>...............] - ETA: 2s - loss: 0.0187Epoch 20/100\n",
      "34/34 [==============================] - 5s 159ms/step - loss: 0.0209oss: 0.009\n",
      " 4/34 [==>...........................] - ETA: 5s - loss: 0.0211Epoch 19/100\n",
      "34/34 [==============================] - 5s 152ms/step - loss: 0.0193 loss: 0.00819\n",
      " 5/34 [===>..........................] - ETA: 5s - loss: 0.0223Epoch 29/50\n",
      "67/67 [==============================] - 6s 97ms/step - loss: 0.0110===================>.........] - ETA: 2s - loss: 0.00\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0189Epoch 74/100\n",
      "34/34 [==============================] - 5s 154ms/step - loss: 0.0190.....] - ETA: 4s - loss: 0.0=================>.........] - ETA: 1s - loss: 0.019\n",
      "14/34 [===========>..................] - ETA: 3s - loss: 0.0213Epoch 30/50\n",
      "34/34 [==============================] - 5s 147ms/step - loss: 0.0196[=========================>....] - ETA: 0s - loss: 0.009==========>......] - ETA: 1s - loss: 0.011\n",
      " 6/34 [====>.........................] - ETA: 4s - loss: 0.0189Epoch 26/50\n",
      "34/34 [==============================] - 5s 152ms/step - loss: 0.0202\n",
      " 9/34 [======>.......................] - ETA: 3s - loss: 0.0188Epoch 20/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 0.0093\n",
      "132/134 [=========================.....] - ETA: 1s - loss: 0.009===>.] - ETA: 0s - loss: 0.0091Epoch 74/100\n",
      "134/134 [==============================] - 9s 64ms/step - loss: 0.0092\n",
      " 6/34 [====>.........................] - ETA: 3s - loss: 0.0192Epoch 74/100\n",
      "67/67 [==============================] - 7s 102ms/step - loss: 0.01100\n",
      " 14/134 [==>...........................] - ETA: 6s - loss: 0.0086Epoch 75/100\n",
      "34/34 [==============================] - 5s 158ms/step - loss: 0.0200009[=>............................] - ETA: 2s - loss: 0.011\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.0095Epoch 21/100] - ETA: 0s - loss: 0.020\n",
      "34/34 [==============================] - 5s 163ms/step - loss: 0.0206oss: 0.009\n",
      "134/134 [==============================] - 8s 62ms/step - loss: 0.0095\n",
      "Epoch 75/100\n",
      " 35/134 [======>.......................] - ETA: 5s - loss: 0.0093Epoch 20/100\n",
      "34/34 [==============================] - 5s 150ms/step - loss: 0.0192- ETA: 4s - loss: 0.011\n",
      " 9/34 [======>.......................] - ETA: 3s - loss: 0.0194Epoch 30/50\n",
      "67/67 [==============================] - 7s 103ms/step - loss: 0.0107 - loss: 0.008\n",
      "Epoch 75/100\n",
      "67/67 [==============================] - 6s 95ms/step - loss: 0.0110...................] - ETA: 5s - loss: 0.0090.0.....] - ETA: 1s - loss: 0.02\n",
      "34/34 [==============================] - 5s 159ms/step - loss: 0.0190\n",
      "Epoch 75/100\n",
      " 3/67 [>.............................] - ETA: 1s - loss: 0.0102Epoch 31/5019\n",
      "34/34 [==============================] - 5s 153ms/step - loss: 0.0195.........] - ETA: 3s - loss: 0.0\n",
      " 9/67 [===>..........................] - ETA: 4s - loss: 0.0110Epoch 27/50\n",
      "34/34 [==============================] - 5s 160ms/step - loss: 0.0200[=======================>......] - ETA: 0s - loss: 0.019\n",
      " 8/34 [======>.......................] - ETA: 4s - loss: 0.0189Epoch 21/100\n",
      "34/34 [==============================] - 5s 146ms/step - loss: 0.0198\n",
      "27/34 [======================>.......] - ETA: 1s - loss: 0.0192Epoch 22/100\n",
      "34/34 [==============================] - 5s 157ms/step - loss: 0.0204.................] - ETA: 3s - loss: 0.010 0.02=========================>....] - ETA: 0s - loss: 0.009\n",
      "67/67 [==============================] - 6s 97ms/step - loss: 0.0109\n",
      "34/34 [==============================] - 5s 151ms/step - loss: 0.0191\n",
      "Epoch 21/100\n",
      "118/134 [=========================>....] - ETA: 0s - loss: 0.0092Epoch 31/50\n",
      " 1/34 [..............................] - ETA: 2s - loss: 0.0242Epoch 76/100\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0093\n",
      "103/134 [======================>.......] - ETA: 1s - loss: 0.0095Epoch 75/100\n",
      "134/134 [==============================] - 8s 63ms/step - loss: 0.0091..........................] - ETA: 2s - loss: 0.009419\n",
      "112/134 [========================>.....] - ETA: 1s - loss: 0.0096Epoch 75/100\n",
      "67/67 [==============================] - 6s 97ms/step - loss: 0.0106- loss: 0.010\n",
      "121/134 [==========================>...] - ETA: 0s - loss: 0.0096Epoch 76/100\n",
      "34/34 [==============================] - 5s 163ms/step - loss: 0.0189=========>..] - ETA: 0s - loss: 0.019\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.0095Epoch 32/50\n",
      "134/134 [==============================] - 8s 59ms/step - loss: 0.0095\n",
      " 24/134 [====>.........................] - ETA: 6s - loss: 0.0095Epoch 76/100\n",
      "34/34 [==============================] - 5s 160ms/step - loss: 0.0194\n",
      "18/34 [==============>...............] - ETA: 2s - loss: 0.0190Epoch 28/50\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0109\n",
      "28/67 [===========>..................] - ETA: 4s - loss: 0.0104Epoch 76/100\n",
      "34/34 [==============================] - 5s 159ms/step - loss: 0.0198\n",
      " 6/67 [=>............................] - ETA: 5s - loss: 0.0108Epoch 22/100\n",
      "34/34 [==============================] - 5s 156ms/step - loss: 0.0197 - loss: 0.0\n",
      "16/67 [======>.......................] - ETA: 4s - loss: 0.0105Epoch 23/100\n",
      "34/34 [==============================] - 5s 150ms/step - loss: 0.0201 4s - loss: 0.00=====>....................] - ETA: 3s - loss: 0.019\n",
      " 9/34 [======>.......................] - ETA: 2s - loss: 0.0207Epoch 22/100\n",
      "34/34 [==============================] - 5s 160ms/step - loss: 0.0191\n",
      " 78/134 [================>.............] - ETA: 3s - loss: 0.0091Epoch 32/50: 1s - loss: 0.018\n",
      "67/67 [==============================] - 7s 101ms/step - loss: 0.0108....] - ETA: 3s - loss: 0.\n",
      "107/134 [======================>.......] - ETA: 1s - loss: 0.0092Epoch 77/100\n",
      "34/34 [==============================] - 5s 145ms/step - loss: 0.0188oss: 0.0\n",
      "55/67 [=======================>......] - ETA: 1s - loss: 0.0106Epoch 33/50\n",
      "34/34 [==============================] - 5s 151ms/step - loss: 0.0193\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.0091Epoch 29/50\n",
      "134/134 [==============================] - 8s 58ms/step - loss: 0.00920\n",
      "Epoch 76/100\n",
      "67/67 [==============================] - 7s 100ms/step - loss: 0.0105\n",
      "21/34 [=================>............] - ETA: 1s - loss: 0.0185Epoch 77/100\n",
      "34/34 [==============================] - 5s 156ms/step - loss: 0.0197\n",
      "19/67 [=======>......................] - ETA: 4s - loss: 0.0104Epoch 23/100\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0091.....] - ETA: 3s - loss: 0.019\n",
      "117/134 [=========================>....] - ETA: 0s - loss: 0.0095Epoch 76/100\n",
      "67/67 [==============================] - 6s 93ms/step - loss: 0.0108\n",
      "13/34 [==========>...................] - ETA: 3s - loss: 0.0194Epoch 77/100\n",
      "34/34 [==============================] - 5s 154ms/step - loss: 0.0195.....................] - ETA: 3s - loss: 0.0\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.0095Epoch 24/100\n",
      "134/134 [==============================] - 7s 55ms/step - loss: 0.0095..] - ETA: 3s - loss: 0.0\n",
      "34/34 [==============================] - 5s 146ms/step - loss: 0.0200\n",
      " 15/134 [==>...........................] - ETA: 8s - loss: 0.0088Epoch 77/100\n",
      "14/34 [===========>..................] - ETA: 3s - loss: 0.0187Epoch 23/100\n",
      "34/34 [==============================] - 5s 149ms/step - loss: 0.0190\n",
      " 32/134 [======>.......................] - ETA: 6s - loss: 0.0096Epoch 33/50\n",
      "34/34 [==============================] - 5s 156ms/step - loss: 0.0188.....] - ETA: 2s - loss: 0.018 loss: 0.\n",
      "13/34 [==========>...................] - ETA: 3s - loss: 0.0192Epoch 34/50\n",
      "67/67 [==============================] - 6s 91ms/step - loss: 0.0107\n",
      " 78/134 [================>.............] - ETA: 3s - loss: 0.0093Epoch 78/100\n",
      "34/34 [==============================] - 6s 170ms/step - loss: 0.0192loss: 0.019\n",
      " 59/134 [============>.................] - ETA: 4s - loss: 0.0097Epoch 30/50\n",
      "34/34 [==============================] - 5s 164ms/step - loss: 0.0196====>.........] - ETA: 2s - loss: 0.010\n",
      "50/67 [=====================>........] - ETA: 1s - loss: 0.0105Epoch 24/100\n",
      "34/34 [==============================] - 5s 153ms/step - loss: 0.0194\n",
      "15/34 [============>.................] - ETA: 2s - loss: 0.0187Epoch 25/100\n",
      "67/67 [==============================] - 6s 98ms/step - loss: 0.0104s: 0.010\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0194Epoch 78/100\n",
      "34/34 [==============================] - 5s 162ms/step - loss: 0.0198..........] - ETA: 4s - loss: 0.019- loss: 0.008\n",
      "100/134 [=====================>........] - ETA: 2s - loss: 0.0089Epoch 24/100\n",
      "67/67 [==============================] - 6s 98ms/step - loss: 0.0107\n",
      "123/134 [==========================>...] - ETA: 0s - loss: 0.0092Epoch 78/100\n",
      "34/34 [==============================] - 5s 160ms/step - loss: 0.0189\n",
      "30/67 [============>.................] - ETA: 3s - loss: 0.0108Epoch 34/50\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 0.0092\n",
      "105/134 [======================>.......] - ETA: 1s - loss: 0.0096Epoch 77/100\n",
      "34/34 [==============================] - 5s 154ms/step - loss: 0.0187\n",
      "134/134 [==============================] - 9s 65ms/step - loss: 0.0091\n",
      "Epoch 35/50\n",
      "29/67 [===========>..................] - ETA: 3s - loss: 0.0104Epoch 77/100\n",
      "134/134 [==============================] - 8s 62ms/step - loss: 0.0095\n",
      "26/34 [=====================>........] - ETA: 1s - loss: 0.0192Epoch 78/100\n",
      "34/34 [==============================] - 5s 150ms/step - loss: 0.0192\n",
      "22/34 [==================>...........] - ETA: 1s - loss: 0.0194Epoch 31/50\n",
      "34/34 [==============================] - 5s 162ms/step - loss: 0.0195\n",
      "34/34 [==============================] - 5s 154ms/step - loss: 0.0193\n",
      " 31/134 [=====>........................] - ETA: 7s - loss: 0.0089Epoch 25/100\n",
      " 5/34 [===>..........................] - ETA: 6s - loss: 0.0182Epoch 26/100\n",
      "67/67 [==============================] - 7s 105ms/step - loss: 0.0106\n",
      " 27/134 [=====>........................] - ETA: 7s - loss: 0.0094Epoch 79/100\n",
      "34/34 [==============================] - 5s 155ms/step - loss: 0.0197\n",
      "34/34 [==============================] - 5s 147ms/step - loss: 0.0189\n",
      "12/34 [=========>....................] - ETA: 4s - loss: 0.0187Epoch 35/50\n",
      " 9/67 [===>..........................] - ETA: 5s - loss: 0.0100Epoch 25/100\n",
      "67/67 [==============================] - 7s 106ms/step - loss: 0.0104\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 5s 154ms/step - loss: 0.0187\n",
      "67/67 [==============================] - 7s 106ms/step - loss: 0.0106\n",
      "12/34 [=========>....................] - ETA: 3s - loss: 0.0191Epoch 36/50\n",
      " 75/134 [===============>..............] - ETA: 3s - loss: 0.0095Epoch 79/100\n",
      "34/34 [==============================] - 5s 160ms/step - loss: 0.0191: 0s - loss: 0.018\n",
      "10/34 [=======>......................] - ETA: 4s - loss: 0.0190Epoch 32/50\n",
      "34/34 [==============================] - 5s 153ms/step - loss: 0.0194\n",
      "25/67 [==========>...................] - ETA: 3s - loss: 0.0107Epoch 26/100\n",
      "134/134 [==============================] - 8s 63ms/step - loss: 0.0092\n",
      "24/34 [====================>.........] - ETA: 1s - loss: 0.0184Epoch 78/100\n",
      "134/134 [==============================] - 7s 56ms/step - loss: 0.0090\n",
      "122/134 [==========================>...] - ETA: 0s - loss: 0.0094Epoch 78/100\n",
      "34/34 [==============================] - 6s 164ms/step - loss: 0.0192\n",
      " 5/34 [===>..........................] - ETA: 6s - loss: 0.0190Epoch 27/100\n",
      "134/134 [==============================] - 7s 54ms/step - loss: 0.0094===>.] - ETA: 0s - loss: 0.009\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.0104Epoch 79/100\n",
      "67/67 [==============================] - 6s 89ms/step - loss: 0.0105\n",
      "19/34 [===============>..............] - ETA: 2s - loss: 0.0188Epoch 80/100 - ETA: 2s - loss: 0.010\n",
      "34/34 [==============================] - 6s 166ms/step - loss: 0.0195>..........] - ETA: 1s - loss: 0.010\n",
      "44/67 [==================>...........] - ETA: 1s - loss: 0.0108Epoch 26/100\n",
      "34/34 [==============================] - 6s 170ms/step - loss: 0.0188\n",
      " 22/134 [===>..........................] - ETA: 5s - loss: 0.0096Epoch 36/50\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0103: \n",
      "34/34 [==============================] - 5s 158ms/step - loss: 0.0186\n",
      "63/67 [===========================>..] - ETA: 0s - loss: 0.0105Epoch 80/100\n",
      "67/67 [==============================] - 5s 80ms/step - loss: 0.0105\n",
      "18/34 [==============>...............] - ETA: 2s - loss: 0.0193Epoch 37/50\n",
      " 55/134 [===========>..................] - ETA: 4s - loss: 0.0089Epoch 80/100\n",
      "34/34 [==============================] - 6s 163ms/step - loss: 0.0190...................] - ETA: 7s - loss: 0.010......] - ETA: 9s - loss: 0.A: 1s - loss: 0.010\n",
      "24/34 [====================>.........] - ETA: 1s - loss: 0.0193Epoch 33/50\n",
      "34/34 [==============================] - 5s 162ms/step - loss: 0.0193\n",
      "16/34 [=============>................] - ETA: 2s - loss: 0.0178Epoch 27/100\n",
      "34/34 [==============================] - 5s 161ms/step - loss: 0.0191\n",
      "33/67 [=============>................] - ETA: 2s - loss: 0.0102Epoch 28/100\n",
      "34/34 [==============================] - 5s 157ms/step - loss: 0.0194: 0s - loss: 0.\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0187Epoch 27/100\n",
      "34/34 [==============================] - 5s 160ms/step - loss: 0.0187\n",
      "44/67 [==================>...........] - ETA: 2s - loss: 0.0102Epoch 37/50\n",
      "67/67 [==============================] - 6s 90ms/step - loss: 0.0104.........] - ETA: 3s - loss: 0.018\n",
      "134/134 [==============================] - 8s 56ms/step - loss: 0.0092\n",
      "124/134 [==========================>...] - ETA: 0s - loss: 0.0090Epoch 81/100\n",
      "127/134 [===========================>..] - ETA: 0s - loss: 0.0091Epoch 79/100\n",
      "34/34 [==============================] - 5s 149ms/step - loss: 0.0186\n",
      "134/134 [==============================] - 8s 61ms/step - loss: 0.0090\n",
      "21/34 [=================>............] - ETA: 1s - loss: 0.0194Epoch 38/50\n",
      "  9/134 [=>............................] - ETA: 11s - loss: 0.0092Epoch 79/100\n",
      "134/134 [==============================] - 8s 61ms/step - loss: 0.0094...] - ETA: 1s - loss: 0.0\n",
      "  9/134 [=>............................] - ETA: 7s - loss: 0.0106Epoch 80/100\n",
      "67/67 [==============================] - 6s 96ms/step - loss: 0.0102] - ETA: 10s - loss: 0.009s: 0.008\n",
      " 29/134 [=====>........................] - ETA: 5s - loss: 0.0093Epoch 81/100\n",
      "67/67 [==============================] - 7s 105ms/step - loss: 0.0105\n",
      "34/34 [==============================] - 5s 149ms/step - loss: 0.0192\n",
      "34/34 [==============================] - 5s 159ms/step - loss: 0.0190\n",
      " 37/134 [=======>......................] - ETA: 5s - loss: 0.0093Epoch 81/100\n",
      " 8/67 [==>...........................] - ETA: 5s - loss: 0.0101Epoch 28/100\n",
      " 38/134 [=======>......................] - ETA: 7s - loss: 0.0087Epoch 34/50\n",
      "34/34 [==============================] - 5s 152ms/step - loss: 0.0190\n",
      " 4/34 [==>...........................] - ETA: 3s - loss: 0.0207Epoch 29/100\n",
      "34/34 [==============================] - 5s 142ms/step - loss: 0.0193TA: 3s - loss: 0.020 0.010\n",
      " 59/134 [============>.................] - ETA: 5s - loss: 0.0090Epoch 28/100\n",
      "34/34 [==============================] - 5s 149ms/step - loss: 0.0187\n",
      " 64/134 [=============>................] - ETA: 4s - loss: 0.0090Epoch 38/50\n",
      "34/34 [==============================] - 5s 151ms/step - loss: 0.0185..............] - ETA: 3s - loss: 0.01=>..................] - ETA: 3s - loss: 0.\n",
      "20/34 [================>.............] - ETA: 2s - loss: 0.0181Epoch 39/50.....] - ETA: 3s - loss: 0.019\n",
      "67/67 [==============================] - 7s 102ms/step - loss: 0.0104...] - ETA: 1s - loss: 0.018\n",
      "48/67 [====================>.........] - ETA: 1s - loss: 0.0102Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 5s 145ms/step - loss: 0.0191 [=====================>........] - ETA: 1s - loss: 0.008loss: 0.010\n",
      "47/67 [====================>.........] - ETA: 2s - loss: 0.0102Epoch 29/100\n",
      "34/34 [==============================] - 5s 154ms/step - loss: 0.0189======>....] - ETA: 0s - loss: 0.018\n",
      "17/67 [======>.......................] - ETA: 4s - loss: 0.0099Epoch 35/50A: 0s - loss: 0.019\n",
      "34/34 [==============================] - 5s 157ms/step - loss: 0.0190========================>...] - ETA: 0s - loss: 0.009\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.0102Epoch 30/100\n",
      "67/67 [==============================] - 7s 98ms/step - loss: 0.0102\n",
      " 3/34 [=>............................] - ETA: 1s - loss: 0.0207Epoch 82/100\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 0.0090\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 0.0094\n",
      "134/134 [==============================] - 9s 66ms/step - loss: 0.0091\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.0104Epoch 80/100\n",
      "  1/134 [..............................] - ETA: 5s - loss: 0.0134Epoch 81/100\n",
      "  1/134 [..............................] - ETA: 2s - loss: 0.0086Epoch 80/100\n",
      "34/34 [==============================] - 5s 153ms/step - loss: 0.01920s - loss: 0.0\n",
      " 7/67 [==>...........................] - ETA: 5s - loss: 0.0098Epoch 29/100\n",
      "67/67 [==============================] - 7s 101ms/step - loss: 0.0104\n",
      "34/34 [==============================] - 5s 150ms/step - loss: 0.0186\n",
      " 10/134 [=>............................] - ETA: 8s - loss: 0.0095Epoch 82/100\n",
      " 10/134 [=>............................] - ETA: 6s - loss: 0.0087Epoch 39/50\n",
      "34/34 [==============================] - 5s 147ms/step - loss: 0.0185..........] - ETA: 3s - loss: 0.01.............] - ETA: 2s - loss: 0.019\n",
      "20/67 [=======>......................] - ETA: 5s - loss: 0.0096Epoch 40/50 loss: 0.010\n",
      "34/34 [==============================] - 5s 139ms/step - loss: 0.0189.............] - ETA: 6s - loss: 0.=====================>......] - ETA: 0s - loss: 0.s - loss: 0.010\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0190Epoch 36/50\n",
      "34/34 [==============================] - 5s 160ms/step - loss: 0.0190\n",
      " 71/134 [==============>...............] - ETA: 3s - loss: 0.0092Epoch 30/100\n",
      "67/67 [==============================] - 7s 100ms/step - loss: 0.0103\n",
      " 79/134 [================>.............] - ETA: 3s - loss: 0.0089Epoch 83/100\n",
      "34/34 [==============================] - 5s 160ms/step - loss: 0.0189ETA: 4s - loss: 0.017\n",
      "42/67 [=================>............] - ETA: 2s - loss: 0.0103Epoch 31/100\n",
      "34/34 [==============================] - 5s 152ms/step - loss: 0.0192\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0186Epoch 30/100\n",
      "34/34 [==============================] - 5s 161ms/step - loss: 0.0185\n",
      "16/67 [======>.......................] - ETA: 5s - loss: 0.0105Epoch 40/50\n",
      "67/67 [==============================] - 7s 100ms/step - loss: 0.01019\n",
      " 8/34 [======>.......................] - ETA: 3s - loss: 0.0193Epoch 83/100\n",
      "34/34 [==============================] - 5s 155ms/step - loss: 0.0184==========================>.] - ETA: 0s - loss: 0.010\n",
      "27/67 [===========>..................] - ETA: 4s - loss: 0.0102Epoch 41/50\n",
      "67/67 [==============================] - 7s 104ms/step - loss: 0.0104\n",
      "128/134 [===========================>..] - ETA: 0s - loss: 0.0093Epoch 83/100\n",
      "134/134 [==============================] - 8s 61ms/step - loss: 0.0094oss: 0.018\n",
      "134/134 [==============================] - 8s 60ms/step - loss: 0.0091\n",
      "134/134 [==============================] - 8s 62ms/step - loss: 0.0090\n",
      "Epoch 82/100\n",
      "  1/134 [..............................] - ETA: 2s - loss: 0.0108Epoch 81/100\n",
      "  1/134 [..............................] - ETA: 2s - loss: 0.0051Epoch 81/100\n",
      "34/34 [==============================] - 5s 143ms/step - loss: 0.0190========>........] - ETA: 1s - loss: 0.0\n",
      "25/67 [==========>...................] - ETA: 4s - loss: 0.0103Epoch 31/100\n",
      "34/34 [==============================] - 5s 155ms/step - loss: 0.0188.......] - ETA: 4s - loss: 0.010\n",
      " 3/34 [=>............................] - ETA: 5s - loss: 0.0185Epoch 37/50\n",
      "34/34 [==============================] - 5s 152ms/step - loss: 0.0188 1s - loss: 0.01\n",
      "57/67 [========================>.....] - ETA: 1s - loss: 0.0103Epoch 32/100\n",
      "34/34 [==============================] - 5s 161ms/step - loss: 0.0191=>.....................] - ETA: 5s - loss: 0.009\n",
      "67/67 [==============================] - 6s 97ms/step - loss: 0.0103\n",
      "45/67 [===================>..........] - ETA: 2s - loss: 0.0101Epoch 31/100\n",
      " 50/134 [==========>...................] - ETA: 4s - loss: 0.0089Epoch 84/100\n",
      "34/34 [==============================] - 5s 157ms/step - loss: 0.0184\n",
      "48/67 [====================>.........] - ETA: 1s - loss: 0.0101Epoch 41/50\n",
      "34/34 [==============================] - 5s 151ms/step - loss: 0.0184\n",
      " 71/134 [==============>...............] - ETA: 3s - loss: 0.0089Epoch 42/50\n",
      "67/67 [==============================] - 7s 102ms/step - loss: 0.0101\n",
      " 82/134 [=================>............] - ETA: 3s - loss: 0.0091Epoch 84/100\n",
      "67/67 [==============================] - 6s 98ms/step - loss: 0.0103\n",
      "34/34 [==============================] - 5s 154ms/step - loss: 0.0189\n",
      "100/134 [=====================>........] - ETA: 2s - loss: 0.0092Epoch 84/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0188Epoch 32/100\n",
      "34/34 [==============================] - 5s 153ms/step - loss: 0.0188\n",
      "104/134 [======================>.......] - ETA: 1s - loss: 0.0093Epoch 38/50\n",
      "34/34 [==============================] - 5s 154ms/step - loss: 0.0187\n",
      "113/134 [========================>.....] - ETA: 1s - loss: 0.0090Epoch 33/100\n",
      "34/34 [==============================] - 5s 152ms/step - loss: 0.0190 ETA: 1s - loss: 0.009\n",
      "20/67 [=======>......................] - ETA: 4s - loss: 0.0100Epoch 32/100\n",
      "34/34 [==============================] - 5s 151ms/step - loss: 0.0183\n",
      "131/134 [============================>.] - ETA: 0s - loss: 0.0089Epoch 42/50\n",
      "134/134 [==============================] - 9s 64ms/step - loss: 0.0093\n",
      "134/134 [==============================] - 9s 64ms/step - loss: 0.0089\n",
      "Epoch 83/100\n",
      "33/67 [=============>................] - ETA: 3s - loss: 0.01005"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m KerasRegressor(build_fn\u001b[38;5;241m=\u001b[39mcreate_convolutional_autoencoder, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m grid \u001b[38;5;241m=\u001b[39m HalvingGridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m grid_result \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/computer_vision/lib/python3.10/site-packages/sklearn/model_selection/_search_successive_halving.py:262\u001b[0m, in \u001b[0;36mBaseSuccessiveHalving.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_input_parameters(\n\u001b[1;32m    255\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    256\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    257\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[1;32m    258\u001b[0m )\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_samples_orig \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# Set best_score_: BaseSearchCV does not set it, as refit is a callable\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_score_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv_results_[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_test_score\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_index_]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/computer_vision/lib/python3.10/site-packages/sklearn/model_selection/_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    887\u001b[0m     )\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/computer_vision/lib/python3.10/site-packages/sklearn/model_selection/_search_successive_halving.py:367\u001b[0m, in \u001b[0;36mBaseSuccessiveHalving._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m    360\u001b[0m     cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checked_cv_orig\n\u001b[1;32m    362\u001b[0m more_results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miter\u001b[39m\u001b[38;5;124m\"\u001b[39m: [itr] \u001b[38;5;241m*\u001b[39m n_candidates,\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_resources\u001b[39m\u001b[38;5;124m\"\u001b[39m: [n_resources] \u001b[38;5;241m*\u001b[39m n_candidates,\n\u001b[1;32m    365\u001b[0m }\n\u001b[0;32m--> 367\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmore_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmore_results\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m n_candidates_to_keep \u001b[38;5;241m=\u001b[39m ceil(n_candidates \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfactor)\n\u001b[1;32m    372\u001b[0m candidate_params \u001b[38;5;241m=\u001b[39m _top_k(results, n_candidates_to_keep, itr)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/computer_vision/lib/python3.10/site-packages/sklearn/model_selection/_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    835\u001b[0m         )\n\u001b[1;32m    836\u001b[0m     )\n\u001b[0;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    860\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/computer_vision/lib/python3.10/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/computer_vision/lib/python3.10/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/computer_vision/lib/python3.10/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/computer_vision/lib/python3.10/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/computer_vision/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = [10, 50, 100]\n",
    "batch_size = [10, 20, 40, 60, 80, 100, 200, 500, 1000]\n",
    "optimizer = ['SGD', 'Adam']\n",
    "learning_rate = [1e-1, 0.5e-1, 1e-2, 0.5e-2, 1e-3, 0.5e-3, 1e-4, 0.5e-4, 1e-5, 0.5e-5, 1e-6, 0.5e-6, 1e-7, 0.5e-7]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs, optimizer=optimizer, learning_rate=learning_rate)\n",
    "\n",
    "model = KerasRegressor(build_fn=create_convolutional_autoencoder, verbose=1)\n",
    "grid = HalvingGridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(x_train, x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae75c8df",
   "metadata": {},
   "source": [
    "## Training Model & Classifying Encoded Images <a class=\"anchor\" id=\"section_2_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ebdd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.0390 - val_loss: 0.0179\n",
      "Epoch 2/100\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.0161 - val_loss: 0.0143\n",
      "Epoch 3/100\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.0132 - val_loss: 0.0117\n",
      "Epoch 4/100\n",
      "1800/1800 [==============================] - 17s 10ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 5/100\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.0099 - val_loss: 0.0095\n",
      "Epoch 6/100\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.0094 - val_loss: 0.0092\n",
      "Epoch 7/100\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.0092 - val_loss: 0.0090\n",
      "Epoch 8/100\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.0089 - val_loss: 0.0088\n",
      "Epoch 9/100\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.0088 - val_loss: 0.0087\n",
      "Epoch 10/100\n",
      "1800/1800 [==============================] - 20s 11ms/step - loss: 0.0087 - val_loss: 0.0086\n",
      "Epoch 11/100\n",
      "1800/1800 [==============================] - 19s 11ms/step - loss: 0.0086 - val_loss: 0.0085\n",
      "Epoch 12/100\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.0086 - val_loss: 0.0085\n",
      "Epoch 13/100\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.0085 - val_loss: 0.0085\n",
      "Epoch 14/100\n",
      "1800/1800 [==============================] - 19s 10ms/step - loss: 0.0085 - val_loss: 0.0085\n",
      "Epoch 15/100\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.0085 - val_loss: 0.0084\n",
      "Epoch 16/100\n",
      "1800/1800 [==============================] - 19s 11ms/step - loss: 0.0085 - val_loss: 0.0084\n",
      "Epoch 17/100\n",
      "1800/1800 [==============================] - 21s 12ms/step - loss: 0.0084 - val_loss: 0.0084\n",
      "Epoch 18/100\n",
      "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0084 - val_loss: 0.0084\n",
      "Epoch 19/100\n",
      "1800/1800 [==============================] - 20s 11ms/step - loss: 0.0084 - val_loss: 0.0084\n",
      "Epoch 20/100\n",
      "1800/1800 [==============================] - 20s 11ms/step - loss: 0.0084 - val_loss: 0.0084\n",
      "Epoch 21/100\n",
      "1800/1800 [==============================] - 19s 10ms/step - loss: 0.0084 - val_loss: 0.0084\n",
      "Epoch 22/100\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 23/100\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 24/100\n",
      "1800/1800 [==============================] - 19s 10ms/step - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 25/100\n",
      "1800/1800 [==============================] - 19s 10ms/step - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 26/100\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 27/100\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 28/100\n",
      "1800/1800 [==============================] - 19s 11ms/step - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 29/100\n",
      "1800/1800 [==============================] - 19s 10ms/step - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 30/100\n",
      "1800/1800 [==============================] - 20s 11ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 31/100\n",
      "1800/1800 [==============================] - 20s 11ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 32/100\n",
      "1800/1800 [==============================] - 20s 11ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 33/100\n",
      "1800/1800 [==============================] - 19s 11ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 34/100\n",
      "1800/1800 [==============================] - 21s 12ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 35/100\n",
      "1800/1800 [==============================] - 22s 12ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 36/100\n",
      "1800/1800 [==============================] - 21s 12ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 37/100\n",
      "1800/1800 [==============================] - 23s 13ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 38/100\n",
      "1800/1800 [==============================] - 24s 13ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 39/100\n",
      "1800/1800 [==============================] - 24s 14ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 40/100\n",
      "1800/1800 [==============================] - 25s 14ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 41/100\n",
      "1800/1800 [==============================] - 25s 14ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 42/100\n",
      "1800/1800 [==============================] - 25s 14ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 43/100\n",
      "1800/1800 [==============================] - 24s 14ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 44/100\n",
      "1800/1800 [==============================] - 22s 12ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 45/100\n",
      "1800/1800 [==============================] - 21s 11ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 46/100\n",
      "1800/1800 [==============================] - 20s 11ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 47/100\n",
      "1800/1800 [==============================] - 20s 11ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 48/100\n",
      "1800/1800 [==============================] - 20s 11ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 49/100\n",
      " 850/1800 [=============>................] - ETA: 9s - loss: 0.0083"
     ]
    }
   ],
   "source": [
    "# run the data through the model\n",
    "reconstruction_metrics = convolutional_autoencoder.fit(training_data, training_data, epochs=conv_autoencoder_epochs, \n",
    "                                                       batch_size=conv_autoencoder_batch, verbose=1, shuffle=True, validation_data=(validation_data, validation_data))\n",
    "encoded_training_set = encoder.predict(training_data)\n",
    "encoded_test_set = encoder.predict(test_data)\n",
    "encoded_full_set = encoder.predict(full_data)\n",
    "classification_metrics = downstream_classifier.fit(encoded_training_set, y_train, epochs=classifier_epochs, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f4fb84",
   "metadata": {},
   "source": [
    "<h1><center> Plot Training Metrics + Downstream Classification Results <a class=\"anchor\" id=\"third-bullet\"></a> </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf784d7",
   "metadata": {},
   "source": [
    "## Plotting Autoencoder Train/Val Loss & Classifier Loss/Acc <a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439313ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training and validation loss metrics \n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(30, 12))\n",
    "\n",
    "# plot the image reconstruction loss \n",
    "ax1.plot(range(len(reconstruction_metrics.history['loss'])), reconstruction_metrics.history['loss'], label='Training Loss', linewidth=5, color='dodgerblue')\n",
    "ax1.plot(range(len(reconstruction_metrics.history['val_loss'])), reconstruction_metrics.history['val_loss'], label='Validation Loss', linewidth=5, color='red')\n",
    "ax1.legend(fontsize=14), ax1.set_xlabel('Epochs', fontsize=14), ax1.set_ylabel('Mean Squared Error (MSE)', fontsize=14)\n",
    "ax1.set_title('Image Reconstruction Loss', fontsize=16)\n",
    "\n",
    "# plot the classification metrics \n",
    "ax2.plot(range(len(classification_metrics.history['loss'])), classification_metrics.history['loss'], label='Training Loss', linewidth=5, color='dodgerblue')\n",
    "ax3.plot(range(len(classification_metrics.history['accuracy'])), classification_metrics.history['accuracy'], label='Training Accuracy', linewidth=5, color='green')\n",
    "ax2.legend(fontsize=14), ax2.set_xlabel('Epochs', fontsize=14), ax2.set_ylabel('Categorical Cross Entropy', fontsize=14)\n",
    "ax3.legend(fontsize=14), ax3.set_xlabel('Epochs', fontsize=14), ax3.set_ylabel('Accuracy', fontsize=14)\n",
    "ax2.set_title('Classification Loss On Encoded Images', fontsize=16)\n",
    "ax3.set_title('Classification Accuracy on Encoded Images', fontsize=16)\n",
    "\n",
    "plt.suptitle('Metrics From Autoencoder and Classifier', fontsize=22, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537fd3e7",
   "metadata": {},
   "source": [
    "## Plotting Confusion Matrices <a class=\"anchor\" id=\"section_3_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b21347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix of the classification results \n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8), sharey=True)\n",
    "\n",
    "train_predictions = downstream_classifier.predict(encoded_training_set)\n",
    "train_predicted_labels = [np.where(train_predictions[x] == np.max(train_predictions[x]))[0][0] for x in range(np.shape(train_predictions)[0])]\n",
    "train_norm_matrix = confusion_matrix(y_train, train_predicted_labels, normalize='true')\n",
    "sns.heatmap(train_norm_matrix, ax=axes[0], annot=True, yticklabels=labels, xticklabels=labels)\n",
    "axes[0].set_title('Encoded Training Data', fontsize=16)\n",
    "\n",
    "test_predictions = downstream_classifier.predict(encoded_test_set)\n",
    "test_predicted_labels = [np.where(test_predictions[x] == np.max(test_predictions[x]))[0][0] for x in range(np.shape(test_predictions)[0])]\n",
    "test_norm_matrix = confusion_matrix(y_test, test_predicted_labels, normalize='true')\n",
    "sns.heatmap(test_norm_matrix, ax=axes[1], annot=True, yticklabels=labels, xticklabels=labels)\n",
    "axes[1].set_title('Encoded Test Data', fontsize=16)\n",
    "\n",
    "plt.suptitle('Confusion Matrices From Encoded Training/Test Data', fontweight='bold', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5068d7",
   "metadata": {},
   "source": [
    "<h1><center> Visualizing Decoded Images + Compressed Latent Space <a class=\"anchor\" id=\"fourth-bullet\"></a> </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3bcb3c",
   "metadata": {},
   "source": [
    "## Plotting Decoded Images For Train/Test <a class=\"anchor\" id=\"section_4_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f3c62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilize the encoder to generate latent representations on training set and test set \n",
    "test_decoded = convolutional_autoencoder.predict(test_data)\n",
    "train_decoded = convolutional_autoencoder.predict(training_data)\n",
    "random_image = np.random.randint(0, np.shape(test_decoded)[0]-1)\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10, 10))\n",
    "ax1.imshow((train_decoded[random_image]* 255).astype(np.uint8))\n",
    "ax2.imshow((training_data[random_image]* 255).astype(np.uint8))\n",
    "ax3.imshow((test_decoded[random_image]* 255).astype(np.uint8))\n",
    "ax4.imshow((test_data[random_image]* 255).astype(np.uint8))\n",
    "ax1.set_title('Training Decoded'), ax2.set_title('Original Training'), ax3.set_title('Test Decoded'), ax4.set_title('Original Test')\n",
    "plt.suptitle('Decoded Images For Training & Test', fontweight='bold', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdc0b61",
   "metadata": {},
   "source": [
    "## Plotting Train/Test Latent [TSNE & Isomap] <a class=\"anchor\" id=\"section_4_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7dae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the latent space \n",
    "\n",
    "if latent_dim == 2 or latent_dim == 3:\n",
    "    if latent_dim == 3:\n",
    "        fig = plt.figure(figsize=(20, 10))\n",
    "        ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "        ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "    elif latent_dim == 2:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    colors = ['blue', 'red', 'green', 'yellow', 'black', 'orange']\n",
    "    for num in np.unique(y_train):\n",
    "        train_indices = np.where(y_train == num)[0]\n",
    "        test_indices = np.where(y_test == num)[0]\n",
    "        if latent_dim == 3:\n",
    "            ax1.scatter3D(encoded_training_set[train_indices, 0], encoded_training_set[train_indices, 1], encoded_training_set[train_indices, 2], alpha=0.5, color=colors[num])\n",
    "            ax2.scatter3D(encoded_test_set[test_indices, 0], encoded_test_set[test_indices, 1], encoded_test_set[test_indices, 2], alpha=0.5, color=colors[num])\n",
    "        elif latent_dim == 2:\n",
    "            ax1.scatter(encoded_training_set[train_indices, 0], encoded_training_set[train_indices, 1], alpha=0.5, color=colors[num])\n",
    "            ax2.scatter(encoded_test_set[test_indices, 0], encoded_test_set[test_indices, 1], alpha=0.5, color=colors[num])\n",
    "    ax1.set_title('Training Data'), ax2.set_title('Test Data')\n",
    "    if latent_dim >= 2:\n",
    "        ax1.set_xlabel('Latent 1'), ax1.set_ylabel('Latent 2'), ax2.set_xlabel('Latent 1'), ax2.set_ylabel('Latent 2')\n",
    "    elif latent_dim >= 3:\n",
    "        ax1.set_zlabel('Latent 3'), ax2.set_zlabel('Latent 3')\n",
    "    plt.suptitle(str(latent_dim) + 'D Latent Space', fontsize=16, fontweight='bold')\n",
    "elif latent_dim > 3: \n",
    "    # using t-SNE and Isomap on high dimensional latent space for visualization\n",
    "    # for training data \n",
    "    TSNE_model = TSNE(n_components=2, verbose=1, random_state=123)\n",
    "    isomap_model = Isomap(n_components=2)\n",
    "    tsne_training = TSNE_model.fit_transform(encoded_training_set)\n",
    "    isomap_training = isomap_model.fit_transform(encoded_training_set)\n",
    "    # for test data\n",
    "    TSNE_model = TSNE(n_components=2, verbose=1, random_state=123)\n",
    "    isomap_model = Isomap(n_components=2)\n",
    "    tsne_test = TSNE_model.fit_transform(encoded_test_set)\n",
    "    isomap_test = isomap_model.fit_transform(encoded_test_set)\n",
    "    # plotting t-sne and isomap results for training and test datasets \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 20))\n",
    "    colors = ['blue', 'red', 'green', 'yellow', 'black', 'orange']\n",
    "    for x in np.unique(y_train):\n",
    "        training_indices = np.where(y_train == x)[0]\n",
    "        test_indices = np.where(y_test == x)[0]\n",
    "        ax1.scatter(tsne_training[training_indices, 0], tsne_training[training_indices, 1], color=colors[x], label=str(x))\n",
    "        ax2.scatter(isomap_training[training_indices, 0], isomap_training[training_indices, 1], color=colors[x], label=str(x))\n",
    "        ax3.scatter(tsne_test[test_indices, 0], tsne_test[test_indices, 1], color=colors[x], label=str(x))\n",
    "        ax4.scatter(isomap_test[test_indices, 0], isomap_test[test_indices, 1], color=colors[x], label=str(x))\n",
    "\n",
    "    titles = ['TSNE [Training Data]', 'Isomap [Training Data]', 'TSNE [Test Data]', 'Isomap [Test Data]']\n",
    "    axes = [ax1, ax2, ax3, ax4]\n",
    "    for axis in range(len(axes)):\n",
    "        axes[axis].set_xlabel('Latent 1', fontsize=16), axes[axis].set_ylabel('Latent 2', fontsize=16), axes[axis].legend(fontsize=14), axes[axis].set_title(titles[axis], fontsize=20)\n",
    "    plt.suptitle('Manifold Learning On Convolutional Autoencoder Latent Space', fontsize=22, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39277974",
   "metadata": {},
   "source": [
    "<h1><center> Finding Similar Images Based On Input <a class=\"anchor\" id=\"fifth-bullet\"></a> </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1bc709",
   "metadata": {},
   "source": [
    "## Computing KNN & Cosine Similarity In Latent Space <a class=\"anchor\" id=\"section_5_1\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796620a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate cosine similarity analysis and KNN for full dataset encoding \n",
    "image_input_index = np.random.randint(0, len(encoded_full_set))\n",
    "top_similar_images = 20\n",
    "if top_similar_images+1 > 6:\n",
    "    top_images_for_plotting = 5\n",
    "else:\n",
    "    top_images_for_plotting = top_similar_images+1\n",
    "\n",
    "# KNN \n",
    "X = np.array(encoded_full_set)\n",
    "nbrs = NearestNeighbors(n_neighbors=top_similar_images+1).fit(X)\n",
    "distances, indices = nbrs.kneighbors(X)\n",
    "knn_indices = indices[image_input_index, :]\n",
    "\n",
    "# cosine similarity\n",
    "encoded_full_df = pd.DataFrame(data=encoded_full_set)\n",
    "cosine_vals = cosine_similarity(encoded_full_df, dense_output=True)\n",
    "cosine_indices = np.argpartition(cosine_vals[image_input_index, :], -1*top_similar_images-1)[-1*top_similar_images-1:]\n",
    "cosine_indices = list(cosine_indices)\n",
    "cosine_indices.pop(cosine_indices.index(image_input_index))\n",
    "cosine_indices.insert(0, image_input_index)\n",
    "\n",
    "# overlap \n",
    "overlap_indices = list(set(cosine_indices)&set(knn_indices))\n",
    "overlap_indices.pop(overlap_indices.index(image_input_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5798de26",
   "metadata": {},
   "source": [
    "## Plotting Similar Images <a class=\"anchor\" id=\"section_5_2\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea9e3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the plots \n",
    "fig, axes1 = plt.subplots(1, top_images_for_plotting, figsize=(25, 5))\n",
    "plt.suptitle('Nearest Neighbors With Minkowski Distance', fontweight='bold', fontsize=20)\n",
    "fig2, axes2 = plt.subplots(1, top_images_for_plotting, figsize=(25, 5))\n",
    "plt.suptitle('Cosine Metric', fontweight='bold', fontsize=20)\n",
    "\n",
    "# figure for overlap between the two sets ---> images with strong similarity\n",
    "if overlap_indices:\n",
    "    fig3, axes3 = plt.subplots(1, top_images_for_plotting, figsize=(25, 5))\n",
    "    plt.suptitle('KNN and Cosine Overlap', fontweight='bold', fontsize=20)\n",
    "    iterations = 3\n",
    "else:\n",
    "    iterations = 2\n",
    "\n",
    "for x in range(iterations):\n",
    "    if x == 0:\n",
    "        index_list = knn_indices[:top_images_for_plotting]\n",
    "        axes = axes1 \n",
    "    elif x == 1:\n",
    "        index_list = cosine_indices[:top_images_for_plotting]\n",
    "        axes = axes2\n",
    "    elif x == 2:\n",
    "        index_list = overlap_indices[:top_images_for_plotting]\n",
    "        axes = axes3\n",
    "    for index in range(len(index_list)):\n",
    "        axes[index].imshow(full_data[index_list[index]])\n",
    "        if x == 0 or x == 1:\n",
    "            if index == 0:\n",
    "                axes[index].set_title('Input Image [' + str(index_list[index]) + ']')\n",
    "            else:\n",
    "                axes[index].set_title(str(index_list[index]))\n",
    "        elif x == 2:\n",
    "            for _ in range(len(overlap_indices), top_images_for_plotting):\n",
    "                axes3[_].set_axis_off()\n",
    "            axes[index].set_title(str(index_list[index]))\n",
    "plt.show()\n",
    "print('# Of Similar Image Overlap Between NN and Cosine = ' + str(len(overlap_indices)) + '/' + str(top_similar_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c722126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
